# This one 11.18.2025 - Added proper hedge metric tracking (missed_hedge_band, missed_hedge_cap, missed_hedge_kelly)
from typing import Optional, List, Dict, Any, Iterable
import math
import json
import uuid
import requests
import csv
import time
import re
from datetime import datetime, timedelta
from cryptography.hazmat.primitives import serialization, hashes
from dateutil import parser
import os
import base64
import smtplib
from email.message import EmailMessage
from cryptography.hazmat.primitives.asymmetric import padding
from cryptography.hazmat.backends import default_backend
from dotenv import load_dotenv
load_dotenv()

BASE_DIR = os.path.dirname(os.path.abspath(__file__))
# default; may be overridden later after checking repo-level file
POSITIONS_FILE = os.path.join(BASE_DIR, "positions.json")

from sourcing.team_map import TEAM_MAP as team_map

# Reuse TCP/TLS sessions to speed API calls
SESSION = requests.Session()
SESSION.headers.update({
    "Accept": "application/json",
    "Cache-Control": "no-cache, no-store, must-revalidate",
    "Pragma": "no-cache",
    "Expires": "0"
})

try:
    from datetime import UTC
except ImportError:
    from datetime import timezone as _tz
    UTC = _tz.utc

def now_utc():
    return datetime.now(UTC)

def parse_iso_utc(s: str):
    dt = datetime.fromisoformat(s)
    return dt if dt.tzinfo else dt.replace(tzinfo=UTC)


PLACE_LIVE_KALSHI_ORDERS = "YES"   # "YES" = live trading, "NO" = simulation
PRESERVE_MANUAL_POSITIONS = False  # Set True only when manually editing positions.json
SHOW_HEDGE_BAND_PREVIEW = True     # Print q_low/q_high guidance whenever hedging logic runs

KALSHI_BASE_URL = "https://api.elections.kalshi.com"
API_BET_API = os.getenv("API_BET_API")
API_KEY_ID = os.getenv("API_KEY_ID")


# Convert relative path to absolute path:
# Use environment variable if set, otherwise default to private_key.pem in the same directory
private_key_filename = os.getenv("KALSHI_PRIVATE_KEY") or "private_key.pem"
PRIVATE_KEY_PATH = os.path.join(os.path.dirname(__file__), private_key_filename)

from sourcing.email_config import (
    SEND_EMAIL_TURN_ON,
    EMAIL_RECIPIENT,
    EMAIL_SENDER,
    EMAIL_APP_PASSWORD,
    EMAIL_SMTP_HOST,
    EMAIL_SMTP_PORT,
    EMAIL_INTERVAL_SECS,
)

# --- Aggressive pricing knobs ---
BID_POST_A = 0.15            # aggressiveness level where we post at bid
TAKER_A      = 0.90           # aggressiveness level where we allow crossing the ask
ALLOW_TAKER  = True           # set False if you never want to cross the ask

def _clip01(x): 
    return 0.0 if x < 0.0 else (1.0 if x > 1.0 else x)

def _prev_tick(x):
    """Quantize to the tick below x using your existing _q; epsilon ensures we don't round up."""
    return _q(x - 1e-6) if x is not None else None

# === Vulture Finisher Strategy Helper Functions ===
def safe_float(value, default=None):
    """Safely convert value to float, handling None and NaN."""
    try:
        if value is None:
            return default
        if isinstance(value, (int, float)):
            # Check for NaN
            if value != value:  # NaN check
                return default
            return float(value)
        return float(value) if value else default
    except (ValueError, TypeError):
        return default

def extract_event_id(ticker: str) -> str:
    """Extract event ID from ticker (everything except last part)."""
    if not ticker or '-' not in ticker:
        return ''
    return '-'.join(ticker.split('-')[:-1])

EVENT_LOCKED_TILL_HEDGE = set()
EVENT_STOP_LOSSED = {}  # Dict: {event_key: {"timestamp": ..., "entry_price": ...}} - tracks stop-lossed events with timestamps and original entry prices (allows re-entry if price recovers)
EVENT_7PCT_EXITED = set()  # Set of event keys that have had a 7% exit - permanently blocks new entries
EVENT_7PCT_EXITED_SIDE = {}  # Dict: {event_key: market_ticker} - tracks which market ticker exited at 7% to disable stop loss on other side

# === Vulture Finisher Strategy Global State ===
from collections import defaultdict
_game_state: Dict[str, Dict] = defaultdict(lambda: {
    'high_water_mark': -1.0,
    'high_water_time': None,
    'plateau_start_time': None,
    'plateau_base_price': None,  # Track base price for plateau tolerance check
    'last_price': -1.0,
    'start_price': None,
    'game_start_time': None
})
_active_positions: Dict[str, Dict] = {}  # Track entry data: {market_ticker: {'price': float, 'time': datetime}}
_traded_games: set = set()  # Track event IDs that have been traded (one-shot rule)
_exit_orders_pending: set = set()  # Track tickers with pending exit orders

SNAPSHOT_MIN_INTERVAL_SECS = 1  # write snapshots at least 1s apart
VERBOSE = True                  # master switch for prints
PRINT_MARKET_TABLE = False       # show/hide the pretty market table
WRITE_EVALS_TRADE_ONLY = False   # if True, only write evals when we actually enter a trade
SNAPSHOT_EVERY_N_SCANS = 1       # write 1 of every N snapshot scans (increase to throttle)
BALANCE_CACHE_SECS = 60          # cache live balance for 60s
# === CSV/JSON Logging Switches (set to False to disable CSV writing for storage optimization) ===
WRITE_SNAPSHOTS = True    # marwket_snapshots_for_duke_basketball.csv
WRITE_EVALS = False        # market_evals_basketball.csv
WRITE_BOT_LOG = False      # bot_log_basketball.csv (entry/exit/snapshot rows)
WRITE_TRADES_CSV = False   # trades_basketball.csv (raw trade events)
WRITE_SESSION_METRICS = False  # session_metrics_basketball.csv
WRITE_TRADE_METRICS = False    # trade_metrics_basketball.csv
WRITE_BACKTEST_FEED = False    # backtest_feed_basketball.csv
# === Entry EV thresholds ===
CAPITAL_SIM = 40.00

# === Entry / Hedging Policy (Add or confirm these) ===
HEDGING_ENABLED = True  # Set to False to disable hedging entirely
FIRST_ENTRY_EV_THRESHOLD = 0.05     # 5% EV for first entry
HEDGE_ENTRY_EV_THRESHOLD = -0.02    # 0.5% EV for hedge
MIN_HEDGE_RETURN = 0.035             # +3.5% ROI on total locked capital in BOTH outcomes
FIRST_ENTRY_PRICE_MAX = 0.55        # first entry must be < 50% price (odds probability check)
FIRST_ENTRY_PRICE_MIN = 0.75        # first entry must be > 25% price (odds probability check)
FIRST_ENTRY_KALSHI_PRICE_MIN = 0.53  # Minimum Kalshi execution price for first entries (won't enter below this)
FIRST_ENTRY_KALSHI_PRICE_MAX = 0.75  # Maximum Kalshi execution price for first entries (actual order price cap)

FIRST_ENTRY_MIN_QTY = 1              # require at least 2 contracts on virgin entries
FIRST_ENTRY_MIN_CAPITAL = 40.0       # baseline capital used for minimum quantity scaling

HEDGE_PRICE_MIN = 0.15                  # only consider hedge if opp ask >= 15%
HEDGE_PRICE_MAX = 0.85                  # ...and <= 85%

# === Stop-Loss Policy ===
STOP_LOSS_THRESHOLD = 0.35              # If first trade (one-sided, not hedged) loses this %, sell immediately (if sportsbook agrees)
STOP_LOSS_THRESHOLD_NO_EV = 0.35        # Hard stop loss at 35% regardless of sportsbook odds (emergency exit)
STOP_LOSS_ODDS_DIFF_THRESHOLD = 0.05    # Allow stop loss if sportsbook/Kalshi probability absolute difference <= 5% (block if > 5%)
MIN_LOCKOUT_PERIOD = 180.0               # Lockout period in MINUTES after stop-loss (3 hours)
ALLOW_STOP_LOSS_PRICE_RECOVERY = False    # If True, allow re-entry when price recovers past original entry price (overrides time cooldown)
FIRST_TRADE_WINDOW_MINUTES = 70.0        # First trade allowed within X minutes of first detection

# === Post-Hedge Profit Protection ===
PROFIT_PROTECTION_ENABLED = True
MAX_PROFIT_DETECTION_ENABLED = True
MAX_PROFIT_THRESHOLD = 0.90  # Take profit if within 90% of theoretical max
PROFIT_PROTECTION_MIN_TIME_REMAINING = 1800.0  # Minimum seconds remaining before allowing profit protection exit (30 minutes)

TRAILING_STOP_ENABLED = True
TRAILING_STOP_PCT = 0.25  # Unified trailing stop percentage (25%)
TRAILING_STOP_INITIAL_PCT = 0.10  # 10% trail initially (deprecated, use TRAILING_STOP_PCT)
TRAILING_STOP_TIGHTEN_THRESHOLD = 0.15  # Tighten after 15% profit
TRAILING_STOP_TIGHTENED_PCT = 0.05  # 5% trail when tightened (deprecated, use TRAILING_STOP_PCT)
MIN_PROFIT_FOR_TRAILING_STOP = 0.03  # Activate after 3% profit

# === Profit Protection Safeguards ===
PROFIT_PROTECTION_MIN_HOLD_SECONDS = 300  # Wait 300 seconds after hedge
PROFIT_PROTECTION_PYRAMIDING_WINDOW = 300  # Check for pyramiding in last 300 seconds
PROFIT_PROTECTION_MIN_MARGIN_ABOVE_SETTLEMENT = 0.015  # Require 3% above settlement

# === Vulture Finisher Strategy Configuration ===
DROP_TRIGGER = 0.20          # $0.20 drop from start
PLATEAU_TOLERANCE = 0.02     # Â±2c tolerance for plateau
PLATEAU_DURATION_MIN = 3.0   # 3 minutes plateau duration
PROFIT_TARGET = 0.16         # +16c profit target
STOP_LOSS_AMT = 0.20         # -20c stop loss
TIME_STOP_ENABLED = True
TIME_STOP_MINUTES = 25.0     # 25 min time stop
min_hold_minutes = 5.0       # 5 min grace period
SETTLEMENT_HOLD_THRESHOLD = 0.88  # Hold to settlement if > 88c
MIN_PROFIT_PCT_TO_SELL = 0.05    # Min 5% profit to exit
POSITION_SIZE_PCT = 0.15     # 15% of cash per position
CF_MIN_START_PRICE = 0.25    # Coin flip range: 25%-75%
CF_MAX_START_PRICE = 0.75
UNIVERSE_MIN_PRICE = 0.25    # Universe price range: 25%-88%
UNIVERSE_MAX_PRICE = 0.88
MAX_POSITIONS = 5            # Max concurrent positions
MAX_GAME_TIME_ELAPSED_MIN = 50.0  # Only trade first 50 mins
PROFIT_PROTECTION_MIN_ABSOLUTE_PROFIT = 0.08  # Require 8% profit minimum
PROFIT_PROTECTION_REQUIRE_NO_RECENT_GROWTH = True  # Block triggers if positions growing
MIN_HOLD_BEFORE_SELL_UNHEDGED_SECONDS = 300  # Wait 5 minutes before selling unhedged positions

# === Odds Feed Aggressive Exit Rule ===
ODDS_FEED_AGGRESSIVE_EXIT_ENABLED = True  # If True, exit all hedged positions when averaged BetsAPI odds â‰¤ threshold
ODDS_FEED_EXIT_THRESHOLD = 0.10  # Exit if Kalshi best bid is 7% or lower (configurable) - ABSOLUTE EXIT, bypasses all other checks
ODDS_FEED_EXIT_TIME_MINUTES = 4.0  # Minutes remaining in final period to allow aggressive exit (men's: 2nd half, women's: 4th quarter)
ODDS_FEED_EXIT_THRESHOLD_MIN = 0.05  # Minimum bid price to allow exit (don't sell below 5% - avoids fee trap, keeps lottery ticket)

# === Sizing Policy: first bet larger, hedge smaller ===
KELLY_FRACTION = 0.9  # Scale Kelly sizing to 90% of full Kelly
HEDGE_TRADE_FRACTIONAL_KELLY = 0.37607   # conservative on hedge
KELLY_HARD_CAP = 0.05248   # absolute ceiling on Kelly fraction (safety)

# === Dynamic EV ===
DYNAMIC_EV_ENABLED = True  # Adjust EV threshold based on market conditions

# === Time-Based Exits ===
TIME_BASED_EXITS_ENABLED = False  # Exit positions after TIME_EXIT_THRESHOLD_MINUTES
TIME_EXIT_THRESHOLD_MINUTES = 5.0  # Minutes after entry to trigger time-based exit

USE_CONSERVATIVE_EV = False   # True = use cons_ev (bid reality), False = use fair_ev (odds-feed-based)

# === Volatility cutoffs ===
SCALP_VOL_SPREAD = 0.07        # lower â†’ scalp mode triggers more
SCALP_VOL_JUMP   = 0.03        # smaller jump triggers faster response

TICK = 0.01  # already suggested earlier; keep here if not defined

# How much edge (%) it takes to justify moving from mid â†’ near ask
EDGE_FOR_ASK = 2.0 * max(FIRST_ENTRY_EV_THRESHOLD, 0.5*SCALP_VOL_SPREAD)  # need stronger edge to chase ask

PYRAMIDING_ENABLED = True  # Master switch for pyramiding
ALLOW_PYRAMID_AFTER_HEDGE = False     # allow scaling once both sides are open (with ROI validation)
ALLOW_PYRAMID_BEFORE_HEDGE = True    # default: no pyramiding before hedge
ALLOW_PYRAMID_ON_WINNERS = True       # allow pyramiding before hedge if price increased (averaging up on winners)
PYRAMID_ON_WINNERS_MIN_INCREASE = 0.04  # minimum price increase required (4 cents) before allowing pyramiding on winners
# Spread dampener: when spread is wide, be less aggressive
SPREAD_TIGHT = 0.04       # â‰¤4Â¢ considered 'tight'
MAX_SPREAD = 0.15         # Maximum allowed spread (15%) before blocking orders

# === Trading Volume Filter ===
MIN_TRADING_VOLUME_PER_EVENT = 20000  # Minimum total trading volume across all markets for an event

# === Correlation Awareness ===
CORRELATION_AWARENESS_ENABLED = False  # Reduce position sizes when correlated positions exist

def _q(p: float) -> float:
    return max(0.0, min(1.0, round(p / TICK) * TICK))


# === Risk sizing & Kelly ===
MAX_STAKE_PCT = 0.10            # allow up to 10% of balance per position (first entries)
HEDGE_MAX_STAKE_PCT = 0.18990      # allow up to 18.99% per hedge order (example)
MAX_TOTAL_EXPOSURE_PCT = MAX_STAKE_PCT              # before hedging
MAX_TOTAL_EXPOSURE_HEDGE_PCT = 0.14568         # when hedging (example)
MAX_EXPOSURE_PER_GAME_PCT = 0.95  # Maximum 95% of total capital per event

REFRESH_ACTIVE = 10             # faster cycle â†’ quicker fills (per odds refresh cadence)
REFRESH_IDLE = 10               # ok to rest slower when no positions
NO_OVERLAP_SLEEP_SECS = 5 * 60  # pause 5 minutes when no overlaps exist

ORDER_FILL_TIME = 15
MIN_KELLY = 0.00793     # require at least 3.5% Kelly strength to enter

# === GLOBAL STATE ===
capital_sim = CAPITAL_SIM
positions = []
closed_trades = []
wins = 0
losses = 0
realized_pnl = 0.0
_snapshot_scan_counter = 0

ODDS_FEED_MAX_RETRIES = 3
ODDS_FEED_RETRY_SLEEP = 0.75  # seconds between retries
ODDS_FEED_CACHE_TTL   = 0.0  # seconds to reuse cached odds
ODDS_FEED_STALE_MAX_AGE = 20  # seconds; skip trades if odds stale

# === Profit Protection State ===
# (Peak profit tracking removed - no longer needed without profit-based early selling)

BETSAPI_BASE = "https://api.b365api.com"
BETSAPI_EVENTS_INPLAY_PATH = "/v3/events/inplay"
BETSAPI_EVENT_ODDS_PATH = "/v2/event/odds"
BASKETBALL_SPORT_ID = 18
BASKETBALL_MONEYLINE_KEY = f"{BASKETBALL_SPORT_ID}_1"
EVENT_ODDS_SLEEP = 0.25  # short pause between odds pulls

ODDS_FEED_DELTA_PATH = os.path.join(BASE_DIR, "odds_feed_last_snapshot.json")

# === Profit Protection State ===
_PEAK_PROFITS: Dict[str, dict] = {}  # Track peak profits per event

# === Odds Update Tracking ===
# Track the last processed odds values and timestamp per event to ensure trades only happen when odds are updated
# Format: {event_key: {"timestamp": float, "home_prob": float, "away_prob": float}}
_LAST_PROCESSED_ODDS: Dict[str, Dict[str, float]] = {}  # {event_key: {"timestamp": ..., "home_prob": ..., "away_prob": ...}}
ODDS_CHANGE_TOLERANCE = 0.0001  # Tolerance for floating point comparison (0.01% change)
REQUIRE_ODDS_UPDATE_FOR_TRADES = True  # Set to True to require odds to change before allowing new trades

NCAA_TOURNAMENT = {
    "name": "NCAA",
    "slug": "basketball-usa-ncaa",
}

_last_snapshot_write_per_match = {}

_odds_cache_events = []
_odds_cache_ts = 0.0
_odds_session = requests.Session()
_last_odds_request_ts = 0.0
_odds_prev_snapshot: Dict[str, Dict[str, Dict[str, float]]] = {}
_odds_snapshot_loaded = False
BOOK_WEIGHT_DEFAULT = 0.10
BOOK_WEIGHT_OVERRIDES = {
    "BET365": 0.20,
    "BETFAIR_EXCH": 0.25,
    "BET_IN_ASIA": 0.15,
    "888_SPORT": 0.12,
    "1XBET": 0.10,
    "BETCRIS": 0.14,
    "PINNACLE": 0.22,
    "WILLIAMHILL": 0.12,
}


def _betsapi_request(path: str, params: Dict[str, Any]) -> Dict[str, Any]:
    """
    BetsAPI request wrapper with retry handling.
    Uses API_BET_API token from environment.
    Always fetches fresh data (no caching).
    """
    token = API_BET_API
    if not token:
        print("âš ï¸ API_BET_API missing from .env - returning empty result")
        return {}
    
    url = f"{BETSAPI_BASE}{path}"
    payload_params = dict(params)
    payload_params["token"] = token
    # Add cache-busting parameter to ensure fresh data every request
    payload_params["_t"] = int(time.time() * 1000)  # milliseconds timestamp
    
    last_err = None
    for attempt in range(1, ODDS_FEED_MAX_RETRIES + 1):
        try:
            # Create fresh request each time to avoid any session-level caching
            headers = {
                "Accept": "application/json",
                "Cache-Control": "no-cache, no-store, must-revalidate",
                "Pragma": "no-cache",
                "Expires": "0"
            }
            resp = SESSION.get(url, params=payload_params, headers=headers, timeout=10)
            if resp.status_code == 200:
                data = resp.json()
                if data.get("success") == 1:
                    return data
                last_err = data.get("error") or "BetsAPI error"
            else:
                last_err = f"HTTP {resp.status_code}: {resp.text[:200]}"
        except Exception as exc:
            last_err = str(exc)
        time.sleep(ODDS_FEED_RETRY_SLEEP)
    raise RuntimeError(last_err or "BetsAPI request failed")


def _load_odds_snapshot() -> None:
    """
    Load the last odds snapshot from disk so we can detect book updates.
    NOTE: This is ONLY used for change detection, NEVER for returning cached odds.
    All odds are always fetched fresh from the API.
    """
    global _odds_prev_snapshot, _odds_snapshot_loaded
    if _odds_snapshot_loaded:
        return
    try:
        with open(ODDS_FEED_DELTA_PATH, "r", encoding="utf-8") as fh:
            _odds_prev_snapshot = json.load(fh)
            _odds_snapshot_loaded = True
    except FileNotFoundError:
        _odds_prev_snapshot = {}
        _odds_snapshot_loaded = False
    except Exception as exc:
        print(f"âš ï¸ Failed to load odds snapshot cache: {exc}")
        _odds_prev_snapshot = {}
        _odds_snapshot_loaded = False


def _save_odds_snapshot(snapshot: Dict[str, Dict[str, Dict[str, float]]]) -> None:
    """
    Persist the latest odds snapshot for next run's delta comparison.
    NOTE: This is ONLY used for change detection, NEVER for returning cached odds.
    All odds are always fetched fresh from the API.
    """
    global _odds_prev_snapshot, _odds_snapshot_loaded
    _odds_prev_snapshot = snapshot
    try:
        with open(ODDS_FEED_DELTA_PATH, "w", encoding="utf-8") as fh:
            json.dump(snapshot, fh, indent=2, sort_keys=True)
        _odds_snapshot_loaded = True
    except Exception as exc:
        print(f"âš ï¸ Failed to write odds snapshot cache: {exc}")


def _book_weight(label: str) -> float:
    if not label:
        return BOOK_WEIGHT_DEFAULT
    key = label.replace(" ", "").upper()
    return BOOK_WEIGHT_OVERRIDES.get(key, BOOK_WEIGHT_DEFAULT)

# === LOGGING / METRICS ===
INITIAL_CAPITAL = CAPITAL_SIM      # lock baseline so ROI is consistent
LOG_FILE = "bot_log_basketball.csv"
LOG_FIELDS = [
    "ts", "event", "match", "ticker",
    "side", "market_ticker",
    "yes_bid", "yes_ask",
    "odds_feed_home_prob", "odds_feed_away_prob",
    "entry_price", "exit_price",
    "exit_fee",         # âœ… NEW
    "total_fees",       # âœ… NEW
    "qty", "pnl", "entry_fee",        # âœ… add here
    "realized_pnl", "unrealized_pnl", "equity",
    "roi_pct", "note"
]

# ---- Session metrics (counters to drive tuning) ----
METRICS = {
    # trade counters
    "orders_placed": 0,
    "orders_filled": 0,
    "orders_timeout_cancel": 0,

    # average slippage tracker
    "avg_slippage_bps_sum": 0.0,
    "avg_slippage_bps_n": 0,

    # hedge diagnostics
    "missed_hedge_band": 0,
    "missed_hedge_cap": 0,
    "missed_hedge_kelly": 0,
    "missed_wide_spread": 0,

    # other skip reasons
    "skip_counts": {}
}


def _bump_fill(kind: str):
    # kind âˆˆ {"placed","filled","timeout_cancel"}
    if kind == "placed":
        METRICS["orders_placed"] += 1
    elif kind == "filled":
        METRICS["orders_filled"] += 1
    elif kind == "timeout_cancel":
        METRICS["orders_timeout_cancel"] += 1

def _metrics_flush_periodic():
    """
    Writes a lightweight snapshot to session_metrics.csv every call (cheap).
    Call this at end of main loop.
    """
    if not WRITE_SESSION_METRICS:
        return
    
    path = "session_metrics_basketball.csv"
    # compute aggregates
    placed = METRICS["orders_placed"] or 1
    fill_rate = METRICS["orders_filled"] / placed
    avg_slip = (METRICS["avg_slippage_bps_sum"] / METRICS["avg_slippage_bps_n"]) if METRICS["avg_slippage_bps_n"] else 0.0

    row = {
        "ts": now_utc().isoformat(),
        "orders_placed": METRICS["orders_placed"],
        "orders_filled": METRICS["orders_filled"],
        "orders_timeout_cancel": METRICS["orders_timeout_cancel"],
        "fill_rate": round(fill_rate, 4),
        "avg_slippage_bps": round(avg_slip, 2),
        "missed_hedge_band": METRICS["missed_hedge_band"],
        "missed_hedge_cap": METRICS["missed_hedge_cap"],
        "missed_hedge_kelly": METRICS["missed_hedge_kelly"],
        # flatten top-5 skip reasons for quick scans
        **{f"skip_{k}": v for k, v in list(METRICS["skip_counts"].items())[:5]},
    }
    _append_csv(path, row, fixed_fields=list(row.keys()))

import unicodedata

def normalize_name(name: str) -> str:
    """Lowercase, strip punctuation/accents, return last name only for safer matching."""
    if not name:
        return ""
    # Remove accents (Ã© â†’ e, Ã± â†’ n, etc.)
    name = unicodedata.normalize("NFKD", name).encode("ascii", "ignore").decode("utf-8")
    parts = re.sub(r"[^a-zA-Z ]", "", name).strip().lower().split()
    return parts[-1] if parts else name.lower()

def kalshi_key3(name: str) -> list:
    """
    Return a list of possible 3-letter Kalshi keys for a player's name.
    Tries multiple positions (last, second-last, first) for safety.
    Example: 'Tomas Martin Etcheverry' â†’ ['ETC', 'MAR', 'TOM']
    """
    if not name:
        return []

    name = unicodedata.normalize("NFKD", name).encode("ascii", "ignore").decode("utf-8")
    tokens = re.sub(r"[^A-Za-z ]", " ", name).strip().split()
    if not tokens:
        return []

    # Build candidates from several likely positions
    candidates = []
    if len(tokens) >= 1:
        candidates.append(tokens[-1][:3].upper())       # last name
    if len(tokens) >= 2:
        candidates.append(tokens[-2][:3].upper())       # second-to-last
        candidates.append(tokens[0][:3].upper())        # first name
    # Deduplicate while preserving order
    seen = set()
    return [x for x in candidates if not (x in seen or seen.add(x))]


def get_kalshi_markets(event_ticker, force_live: bool = False):
    """
    Kalshi market fetch with rate limiting support.
    - bypasses cache if force_live=True
    - low timeout (1.5s)
    - handles 429 errors with backoff
    - filters only active markets
    """
    url = f"{KALSHI_BASE_URL}/trade-api/v2/markets?event_ticker={event_ticker}"

    try:
        res = SESSION.get(url, timeout=1.5)  # âš¡ faster timeout
        if res.status_code == 200:
            markets = res.json().get("markets", [])
            # keep only active markets with visible quotes
            markets = [
                m for m in markets
                if m.get("status") == "active" and (m.get("yes_bid") or m.get("yes_ask"))
            ]
            return markets
        elif res.status_code == 429:
            # Rate limited - return None to signal caller to back off
            error_data = res.json() if res.text else {}
            print(f"âŒ Kalshi fetch error 429 for {event_ticker}: {error_data}")
            return None  # Return None instead of [] to signal rate limit
        else:
            print(f"âŒ Kalshi fetch error {res.status_code} for {event_ticker}: {res.text[:120]}")
            return []
    except requests.exceptions.Timeout:
        print(f"âš ï¸ Kalshi fetch timeout for {event_ticker}")
        return []
    except Exception as e:
        print(f"âŒ Kalshi fetch error for {event_ticker}: {e}")
        return []

def get_event_total_volume(event_ticker, markets=None):
    """
    Get total trading volume for an event by summing volume across all markets.
    
    Args:
        event_ticker: The event ticker (e.g., "KXNCAAMBGAME-25NOV23BUTUVA")
        markets: Optional pre-fetched markets list. If None, will fetch them.
    
    Returns:
        Total volume as integer, or None if unable to fetch/calculate
    """
    if markets is None:
        markets = get_kalshi_markets(event_ticker, force_live=True)
    
    # Handle rate limiting (None) or empty markets ([])
    if not markets:  # None (rate limited) or [] (no markets) both indicate no data
        return None
    
    total_volume = sum(
        market.get("volume", 0) 
        for market in markets 
        if market.get("volume") is not None
    )
    
    return total_volume if total_volume > 0 else None

_PRIVATE_KEY_CACHE = None

def load_private_key():
    """
    Loads and caches the Kalshi private key from the file specified in PRIVATE_KEY_PATH
    """
    global _PRIVATE_KEY_CACHE
    if _PRIVATE_KEY_CACHE is None:
        # Use PRIVATE_KEY_PATH which is already an absolute path
        key_path = PRIVATE_KEY_PATH

        with open(key_path, "rb") as key_file:
            _PRIVATE_KEY_CACHE = serialization.load_pem_private_key(
                key_file.read(),   # âœ… Actual key contents
                password=None,
                backend=default_backend()
            )
    return _PRIVATE_KEY_CACHE

def ev_per_contract(win_prob: float, entry_price: float) -> float:
    """
    Expected value per contract in side-price space (after a simple fee model).
    """
    gross = win_prob * (1 - entry_price) - (1 - win_prob) * entry_price
    # This function doesn't have bid/ask context, default to taker (conservative)
    fees = kalshi_fee_per_contract(entry_price, is_maker=False)
    return gross - fees

def sign_message(private_key, message):
    """
    Signs the given message using the loaded private key and returns
    a Base64-encoded signature string.
    """
    signature = private_key.sign(
        message.encode(),
        padding.PSS(
            mgf=padding.MGF1(hashes.SHA256()),
            salt_length=padding.PSS.DIGEST_LENGTH
        ),
        hashes.SHA256()
    )
    return base64.b64encode(signature).decode()

def kalshi_headers(method, path):
    """
    Generates properly signed Kalshi API headers.
    """
    timestamp = str(int(time.time() * 1000))
    private_key = load_private_key()
    msg = timestamp + method + path.split("?")[0]
    signature = sign_message(private_key, msg)
    return {
        "KALSHI-ACCESS-KEY": API_KEY_ID,
        "KALSHI-ACCESS-SIGNATURE": signature,
        "KALSHI-ACCESS-TIMESTAMP": timestamp
    }

def reconcile_positions():
    """
    Internal reconciliation: trust local fills and merge any new ones from Kalshi.
    Then mark events as neutralized (both sides present) and compute hedge bands.
    """
    global positions, _LAST_RECONCILE_TS

    print("ðŸ” Internal reconcile â€” trusting local fills")

    try:
        live = get_live_positions()
    except Exception as e:
        print(f"âš ï¸ Could not fetch live positions ({e}); continuing with local state")
        live = []
        # --- Stamp last_seen_live for anything we still see on Kalshi ---
    live_now = now_utc().isoformat()
    live_keys = {(lp["ticker"], (lp["side"] or "").lower()) for lp in live}

    for p in positions:
        key = (p.get("market_ticker"), (p.get("side") or "").lower())
        if key in live_keys:
            p["last_seen_live"] = live_now

    # Keep all local positions; just append any new live ones
    # âœ… Also UPDATE existing positions with correct prices from live API
    new_positions = list(positions)
    local_keys = {(p["market_ticker"], p["side"].lower()): i for i, p in enumerate(new_positions)}

    for lp in live:
        key = (lp["ticker"], lp["side"].lower())
        
        # âœ… ALWAYS extract event_ticker from market_ticker (API might provide wrong one)
        # Extract event ticker from market ticker (e.g., "KXNCAAMBGAME-25NOV29CBUORST-ORST" -> "KXNCAAMBGAME-25NOV29CBUORST")
        event_ticker_from_api = ""
        if lp["ticker"]:
            parts = lp["ticker"].split("-")
            if len(parts) > 2:
                # âœ… Take first 2 parts (not 3) - the 3rd part is the team suffix
                event_ticker_from_api = "-".join(parts[:2]).upper()
            else:
                # Fallback: use API-provided event_ticker if extraction fails
                event_ticker_from_api = (lp.get("event_ticker") or "").upper()
        
        if key in local_keys:
            # âœ… UPDATE existing position with correct price and quantity from live API
            idx = local_keys[key]
            existing_pos = new_positions[idx]
            
            # âœ… DON'T update positions that are being closed or already settled
            # This prevents overwriting stake=0 that we set when placing sell orders
            # Kalshi may still show the position until the sell order fills, but we've already marked it for closing
            if existing_pos.get("settled", False) or existing_pos.get("closing_in_progress", False):
                if VERBOSE:
                    print(f"â¸ï¸ Skipping update for {lp['ticker']} {lp['side']} - position is being closed (settled={existing_pos.get('settled')}, closing={existing_pos.get('closing_in_progress')})")
                # Still update last_seen_live timestamp for tracking, but don't overwrite stake/price
                existing_pos["last_seen_live"] = live_now
                continue
            
            existing_pos["entry_price"] = lp["avg_price"]
            existing_pos["effective_entry"] = lp["avg_price"]
            existing_pos["stake"] = lp["contracts"]
            existing_pos["last_seen_live"] = live_now
            
            # âœ… ALWAYS update event_ticker (extracted from market_ticker)
            if event_ticker_from_api:
                existing_pos["event_ticker"] = event_ticker_from_api
                if VERBOSE:
                    print(f"   â†’ Updated event_ticker to: {event_ticker_from_api}")
            
            if VERBOSE:
                print(f"ðŸ”„ Updated position from Kalshi: {lp['ticker']} {lp['side']} @ {lp['avg_price']:.2%} (qty: {lp['contracts']})")
        else:
            # âœ… ADD new position
            print(f"âœ… Added live fill from Kalshi: {lp['ticker']} {lp['side']}")
            new_positions.append({
                "match": lp["ticker"],
                "side": lp["side"].lower(),
                "event_ticker": event_ticker_from_api,
                "market_ticker": lp["ticker"],
                "entry_price": lp["avg_price"],
                "stake": lp["contracts"],
                "effective_entry": lp["avg_price"],
                "entry_time": now_utc().isoformat(),
                "odds_prob": 0.5,
            })

    # âœ… Mark positions as settled if they exist locally but NOT on Kalshi (e.g., manually sold)
    # This ensures positions that were sold outside the bot are properly removed
    for pos in new_positions:
        if pos.get("settled", False) or pos.get("closing_in_progress", False):
            continue  # Skip positions already being closed
        
        key = (pos.get("market_ticker"), (pos.get("side") or "").lower())
        if key not in live_keys:
            # Position exists locally but not on Kalshi - mark as settled
            pos["settled"] = True
            pos["stake"] = 0
            if VERBOSE:
                print(f"ðŸ—‘ï¸ Marking {pos.get('market_ticker')} {pos.get('side')} as settled - no longer exists on Kalshi")

    positions[:] = new_positions
    
    # âœ… Fix any positions that still have wrong event_ticker format
    normalize_loaded_positions()

    # --- 1) Mark events as neutralized first ---
    events = {}
    for p in positions:
        if p.get("side") != "yes":
            continue
        evt = p.get("event_ticker", "")
        if not evt:
            continue
        events.setdefault(evt, set()).add(p.get("market_ticker", ""))

    for evt, mkts in events.items():
        is_neut = len(mkts) >= 2
        for p in positions:
            if p.get("event_ticker") == evt:
                p["neutralized"] = is_neut
        if is_neut:
            print(f"ðŸŸ¢ Event {evt} is NEUTRALIZED (both sides present).")
        else:
            print(f"ðŸŸ¡ Event {evt} has one side only.")

    # --- 2) Now compute hedge bands for neutralized pairs ---
    pairs = {}
    for p in positions:
        pairs.setdefault(p.get("event_ticker", ""), []).append(p)

    for evt, sides in pairs.items():
        sides_yes = [s for s in sides if s.get("side") == "yes"]
        if len(sides_yes) == 2 and all(s.get("neutralized") for s in sides_yes):
            h, a = sides_yes
            qA, pA = float(h["stake"]), float(h["entry_price"])
            pB = float(a["entry_price"])

            q_low, q_high = hedge_qty_bounds_target_roi(qA, pA, pB, r=MIN_HEDGE_RETURN)  # sync with live hedge policy
            if q_low is None or q_high is None or q_high <= 0:
                # No feasible +r band; clear any previous metadata
                for s in sides_yes:
                    s.pop("q_low", None)
                    s.pop("q_high", None)
                continue

            # store rounded ints (just metadata)
            for s in sides_yes:
                s["q_low"], s["q_high"] = int(math.ceil(q_low)), int(math.floor(q_high))

    _LAST_RECONCILE_TS = time.time()
    save_positions()

def save_positions():
    # ðŸ”’ Round numeric fields before saving to avoid fractional drift
    for p in positions:
        for key in ("stake", "q_low", "q_high"):
            if key in p and isinstance(p[key], (int, float)):
                p[key] = int(round(p[key]))
    with open(POSITIONS_FILE, "w") as f:
        json.dump(positions, f, indent=2)


def resolve_positions_file():
    """
    Choose which positions.json to use.
    Priority:
      1. KALSHI_POSITIONS_FILE env override
      2. Local positions.json next to this script (BASE_DIR)
    """
    env_path = os.getenv("KALSHI_POSITIONS_FILE")
    if env_path:
        return os.path.abspath(env_path)

    # Always use BASE_DIR (same directory as script) for positions.json
    return os.path.join(BASE_DIR, "positions.json")


POSITIONS_FILE = resolve_positions_file()


def resolve_first_detection_times_file():
    """
    Choose which first_detection_times.json to use.
    Uses the same location as positions.json.
    Priority:
      1. KALSHI_POSITIONS_FILE env override (uses same directory for consistency)
      2. Local first_detection_times.json next to this script (BASE_DIR)
    """
    positions_dir = os.path.dirname(POSITIONS_FILE)
    return os.path.join(positions_dir, "first_detection_times.json")


FIRST_DETECTION_TIMES_FILE = resolve_first_detection_times_file()


def load_positions():
    """Safely load positions.json whether itâ€™s a dict or list."""
    if not os.path.exists(POSITIONS_FILE):
        return []
    try:
        with open(POSITIONS_FILE, "r") as f:
            data = json.load(f)
            # Handle both possible formats
            if isinstance(data, list):
                return data
            elif isinstance(data, dict) and "positions" in data:
                return data["positions"]
            else:
                print("âš ï¸ Unrecognized JSON format in positions file.")
                return []
    except Exception as e:
        print(f"âš ï¸ Error loading positions file: {e}")
        return []


_last_balance_ts = 0.0
_last_balance_val = CAPITAL_SIM
_last_portfolio_value_ts = 0.0
_last_portfolio_value_val = None

def get_kalshi_balance(force=False):
    """
    Fetches current Kalshi cash balance in dollars.
    Caches for BALANCE_CACHE_SECS to reduce API calls.
    """
    global _last_balance_ts, _last_balance_val

    if PLACE_LIVE_KALSHI_ORDERS != "YES":
        if VERBOSE:
            print(f"ðŸ’µ SIM MODE BALANCE: ${CAPITAL_SIM:.2f}")
        return CAPITAL_SIM

    now = time.time()
    if not force and (now - _last_balance_ts) < BALANCE_CACHE_SECS:
        return _last_balance_val

    path = "/trade-api/v2/portfolio/balance"
    headers = kalshi_headers("GET", path)
    try:
        res = SESSION.get(KALSHI_BASE_URL + path, headers=headers, timeout=8)
        data = res.json()

        cash_val = None
        if "cash" in data:
            cash_val = float(data["cash"]) / 100.0
        elif "available_cash" in data:
            cash_val = float(data["available_cash"]) / 100.0
        elif "balances" in data and "available_cash" in data["balances"]:
            cash_val = float(data["balances"]["available_cash"]) / 100.0
        elif "balance" in data:
            cash_val = float(data["balance"]) / 100.0

        if cash_val is not None:
            if VERBOSE:
                print(f"ðŸ’° LIVE KALSHI BALANCE: ${cash_val:,.2f}")
            _last_balance_ts = now
            _last_balance_val = cash_val
            return cash_val

        if VERBOSE:
            print("âš ï¸ Unexpected Kalshi balance format:", data)
    except Exception as e:
        if VERBOSE:
            print("âŒ Kalshi balance fetch error:", e)

    _last_balance_ts = now
    _last_balance_val = CAPITAL_SIM
    return CAPITAL_SIM

def get_kalshi_portfolio_value(force=False):
    """
    Fetches current Kalshi portfolio value (cash + positions) in dollars.
    Caches for BALANCE_CACHE_SECS to reduce API calls.
    """
    global _last_portfolio_value_ts, _last_portfolio_value_val

    if PLACE_LIVE_KALSHI_ORDERS != "YES":
        return None

    now = time.time()
    if not force and (now - _last_portfolio_value_ts) < BALANCE_CACHE_SECS and _last_portfolio_value_val is not None:
        return _last_portfolio_value_val

    path = "/trade-api/v2/portfolio/balance"
    headers = kalshi_headers("GET", path)
    try:
        res = SESSION.get(KALSHI_BASE_URL + path, headers=headers, timeout=8)
        data = res.json()

        portfolio_val = None
        if "portfolio_value" in data:
            portfolio_val = float(data["portfolio_value"]) / 100.0
        elif "equity" in data:
            portfolio_val = float(data["equity"]) / 100.0
        elif "total_equity" in data:
            portfolio_val = float(data["total_equity"]) / 100.0

        if portfolio_val is not None:
            if VERBOSE:
                print(f"ðŸ’¼ LIVE KALSHI PORTFOLIO VALUE: ${portfolio_val:,.2f}")
            _last_portfolio_value_ts = now
            _last_portfolio_value_val = portfolio_val
            return portfolio_val

        if VERBOSE:
            print("âš ï¸ Unexpected Kalshi portfolio value format:", data)
    except Exception as e:
        if VERBOSE:
            print("âŒ Kalshi portfolio value fetch error:", e)

    _last_portfolio_value_ts = now
    return None

def get_live_positions():
    """
    Fetch live open positions directly from Kalshi.
    Parses actual API response structure:
      - market_positions[] with: ticker, position (signed: + = YES, - = NO), 
        total_traded, total_traded_dollars (used to calculate avg_price)
      - event_positions[] (nested structure with market_positions)
      - Legacy formats: positions / portfolio.positions (backward compatibility)
    Returns: [{ticker, side, contracts, avg_price, event_ticker}]
    """
    path = "/trade-api/v2/portfolio/positions"
    headers = kalshi_headers("GET", path)
    try:
        res = SESSION.get(KALSHI_BASE_URL + path, headers=headers, timeout=8)
        txt = res.text[:300]
        if res.status_code != 200:
            print(f"âš ï¸ Positions fetch failed: {res.status_code} {txt}")
            if VERBOSE:
                print(f"   Full response: {res.text[:500]}")
            return []

        try:
            data = res.json()
        except Exception:
            print(f"âš ï¸ Non-JSON /positions body: {txt}")
            return []

        live_positions = []

        def _push_pos(ticker, side, contracts, avg_price, event_ticker=None):
            try:
                if not ticker:
                    return
                side = (side or "").lower()
                qty = abs(int(contracts or 0))  # âœ… Use absolute value (position can be negative)
                if qty <= 0:
                    return
                ap = float(avg_price or 0.0)
                if ap > 1.0:   # Kalshi often returns cents
                    ap = ap / 100.0
                live_positions.append({
                    "ticker": ticker,
                    "side": side,
                    "contracts": qty,
                    "avg_price": ap,
                    "event_ticker": event_ticker or "",
                })
            except Exception as e:
                print(f"âš ï¸ parse helper err: {e}")

        # ---- NEW SHAPE 1: market_positions ----
        # âœ… Updated to match actual API: position (signed), calculate avg_price from total_traded_dollars
        for mp in (data.get("market_positions") or []):
            ticker = mp.get("ticker")  # Direct field, not nested
            if not ticker:
                continue
            
            # Position is signed: positive = YES, negative = NO
            position = mp.get("position", 0)
            if position == 0:
                continue  # Skip zero positions
            
            # Infer side from sign of position
            side = "yes" if position > 0 else "no"
            contracts = position  # Pass signed value, _push_pos will use abs()
            
            # Calculate avg_price - prefer market_exposure_dollars for current position
            # âœ… market_exposure_dollars / position = average entry price for CURRENT position
            # âš ï¸ total_traded_dollars / total_traded = average of ALL trades (including closed ones)
            avg_price = None
            
            # âœ… FIRST: Use market_exposure_dollars / position (current position's entry price)
            market_exposure_dollars_str = mp.get("market_exposure_dollars", "0")
            try:
                market_exposure_dollars = float(market_exposure_dollars_str)
                if abs(position) > 0 and market_exposure_dollars > 0:
                    # market_exposure_dollars is total cost in dollars, position is contract count
                    avg_price = market_exposure_dollars / abs(position)
                    # If result > 1, it's in cents, convert to decimal (0-1 range)
                    if avg_price > 1.0:
                        avg_price = avg_price / 100.0
            except (ValueError, TypeError):
                pass
            
            # âœ… FALLBACK: Use total_traded_dollars / total_traded (less accurate for current position)
            if avg_price is None or avg_price <= 0:
                total_traded = mp.get("total_traded", 0)
                total_traded_dollars_str = mp.get("total_traded_dollars", "0")
                try:
                    total_traded_dollars = float(total_traded_dollars_str)
                    if total_traded > 0:
                        avg_price = total_traded_dollars / total_traded
                        # If result > 1, it's in cents, convert to decimal
                        if avg_price > 1.0:
                            avg_price = avg_price / 100.0
                except (ValueError, TypeError):
                    pass
            
            # Skip if we can't calculate price
            if avg_price is None or avg_price <= 0:
                if VERBOSE:
                    print(f"âš ï¸ Could not calculate avg_price for {ticker}, skipping")
                continue
            
            evt = mp.get("event_ticker", "")
            _push_pos(ticker, side, contracts, avg_price, evt)

        # ---- NEW SHAPE 2: event_positions (nested) ----
        # âœ… Updated to match actual API structure
        for ep in (data.get("event_positions") or []):
            evt = ep.get("event_ticker") or ep.get("event") or ""
            nested_markets = ep.get("market_positions") or ep.get("markets") or []
            for mp in nested_markets:
                ticker = mp.get("ticker")
                if not ticker:
                    continue
                
                position = mp.get("position", 0)
                if position == 0:
                    continue
                
                side = "yes" if position > 0 else "no"
                contracts = position
                
                # Calculate avg_price - prefer market_exposure_dollars for current position
                # âœ… market_exposure_dollars / position = average entry price for CURRENT position
                # âš ï¸ total_traded_dollars / total_traded = average of ALL trades (including closed ones)
                avg_price = None
                
                # âœ… FIRST: Use market_exposure_dollars / position (current position's entry price)
                market_exposure_dollars_str = mp.get("market_exposure_dollars", "0")
                try:
                    market_exposure_dollars = float(market_exposure_dollars_str)
                    if abs(position) > 0 and market_exposure_dollars > 0:
                        # market_exposure_dollars is total cost in dollars, position is contract count
                        avg_price = market_exposure_dollars / abs(position)
                        # If result > 1, it's in cents, convert to decimal (0-1 range)
                        if avg_price > 1.0:
                            avg_price = avg_price / 100.0
                except (ValueError, TypeError):
                    pass
                
                # âœ… FALLBACK: Use total_traded_dollars / total_traded (less accurate for current position)
                if avg_price is None or avg_price <= 0:
                    total_traded = mp.get("total_traded", 0)
                    total_traded_dollars_str = mp.get("total_traded_dollars", "0")
                    try:
                        total_traded_dollars = float(total_traded_dollars_str)
                        if total_traded > 0:
                            avg_price = total_traded_dollars / total_traded
                            # If result > 1, it's in cents, convert to decimal
                            if avg_price > 1.0:
                                avg_price = avg_price / 100.0
                    except (ValueError, TypeError):
                        pass
                
                if avg_price is None or avg_price <= 0:
                    continue
                
                _push_pos(ticker, side, contracts, avg_price, evt)

        # ---- OLD SHAPES: positions / portfolio.positions / orders ----
        raw_positions = (
            data.get("positions")
            or data.get("portfolio", {}).get("positions")
            or data.get("orders")
            or []
        )
        for p in raw_positions:
            try:
                ticker = p.get("ticker") or p.get("market_ticker") or p.get("id")
                side = (p.get("side") or "").lower()
                contracts = int(
                    p.get("contracts_count") or p.get("count") or
                    p.get("size") or p.get("contracts") or 0
                )
                ap_raw = (p.get("average_price") or p.get("avg_price") or p.get("entry_price") or 0)
                avg_price = float(ap_raw) / (100.0 if float(ap_raw or 0) > 1 else 1)
                if contracts > 0 and ticker:
                    _push_pos(ticker, side, contracts, avg_price, p.get("event_ticker", ""))
            except Exception as e:
                print(f"âš ï¸ Error parsing legacy position: {e} â†’ {p}")
                continue

        if VERBOSE and live_positions:
            print(f"âœ… Parsed {len(live_positions)} positions from Kalshi API")
        elif VERBOSE and not live_positions and data:
            # Debug: show what we got from API
            market_pos_count = len(data.get("market_positions", []))
            event_pos_count = len(data.get("event_positions", []))
            if market_pos_count > 0 or event_pos_count > 0:
                print(f"âš ï¸ Found {market_pos_count} market_positions and {event_pos_count} event_positions but couldn't parse any")
                if market_pos_count > 0:
                    sample = data.get("market_positions", [])[0]
                    print(f"   Sample market_position keys: {list(sample.keys())}")

        return live_positions

    except Exception as e:
        print(f"âŒ Error fetching live positions: {e}")
        if VERBOSE:
            import traceback
            traceback.print_exc()
        return []

def kalshi_fee(num_contracts: int, price: float, is_maker: bool = False) -> float:
    """
    Calculate Kalshi fee in dollars.
    Taker fees: fees = round_up(0.07 Ã— C Ã— P Ã— (1-P))
    Maker fees: fees = round_up(0.0175 Ã— C Ã— P Ã— (1-P))
    
    Parameters
    ----------
    num_contracts : int
        Number of contracts being traded
    price : float
        Price of a contract in dollars (50 cents is 0.5)
    is_maker : bool
        True if this is a maker order (resting on orderbook), False if taker (immediately matched)
    """
    fee_rate = 0.0175 if is_maker else 0.07
    raw = fee_rate * num_contracts * price * (1 - price)
    # round up to nearest cent
    return math.ceil(raw * 100) / 100.0

def kalshi_fee_per_contract(price: float, is_maker: bool = False) -> float:
    """
    Convenience: fee per single contract at price P.
    
    Parameters
    ----------
    price : float
        Price of a contract in dollars
    is_maker : bool
        True if this is a maker order, False if taker
    """
    return kalshi_fee(1, price, is_maker=is_maker)

def maker_entry_fee(entry_price: float, yes_ask_raw: Optional[int], yes_ask: Optional[float] = None) -> float:
    """
    Calculate entry fee, determining maker vs taker based on entry price relative to bid/ask.
    For BUY orders: maker if entry_price < yes_ask, taker if entry_price >= yes_ask
    
    Parameters
    ----------
    entry_price : float
        Entry price in [0,1]
    yes_ask_raw : Optional[int]
        Legacy parameter (kept for compatibility, ignored)
    yes_ask : Optional[float]
        Current YES ask price (for maker/taker determination)
    """
    if yes_ask is not None:
        is_maker = entry_price < yes_ask  # Simple comparison!
    else:
        # Default to taker if we don't have ask price (conservative)
        is_maker = False
    return kalshi_fee_per_contract(entry_price, is_maker=is_maker)

def hedge_qty_bounds_target_roi(qA: float, pA: float, pB: float, r: float = MIN_HEDGE_RETURN,
                                 yes_ask_A: Optional[float] = None, yes_ask_B: Optional[float] = None):
    """
    Compute hedge quantity bounds q_low <= qB <= q_high such that BOTH outcomes
    (A wins or B wins) realize at least +r ROI on total locked capital.

    Fees are applied per contract on both sides at entry/exit resolution.
    Outcome PnL formulas (YES entries on both sides):
      A wins: pnl_A = qA*(1 - pA - fA) - qB*(pB + fB)
      B wins: pnl_B = qB*(1 - pB - fB) - qA*(pA + fA)
    ROI is with respect to locked capital L = qA*pA + qB*pB.
    We enforce: pnl_A >= r*L and pnl_B >= r*L simultaneously.

    Solving the linear inequalities yields:
      q_low  = qA*(pA*(1+r) + fA) / (1 - pB - fB - r*pB)
      q_high = qA*(1 - pA - fA - r*pA) / (pB*(1+r) + fB)

    Returns (q_low, q_high) or (None, None) if infeasible/denominators invalid.
    """
    # Determine maker/taker for each side
    is_maker_A = (yes_ask_A is not None and pA < yes_ask_A) if yes_ask_A is not None else False
    is_maker_B = (yes_ask_B is not None and pB < yes_ask_B) if yes_ask_B is not None else False
    fA = kalshi_fee_per_contract(pA, is_maker=is_maker_A)
    fB = kalshi_fee_per_contract(pB, is_maker=is_maker_B)

    denom_low  = (1.0 - pB - fB - r*pB)
    denom_high = (pB*(1.0 + r) + fB)

    if denom_low <= 1e-9 or denom_high <= 1e-9:
        return None, None

    q_low  = (qA*(pA*(1.0 + r) + fA)) / denom_low
    q_high = (qA*(1.0 - pA - fA - r*pA)) / denom_high

    if not (math.isfinite(q_low) and math.isfinite(q_high)):
        return None, None

    return max(0.0, q_low), max(0.0, q_high)


def hedge_outcome_rois(qA: float, pA: float, qB: float, pB: float,
                       yes_ask_A: Optional[float] = None, yes_ask_B: Optional[float] = None):
    """
    Utility: compute realized ROI (as fraction) for both outcomes given quantities and prices.
    ROI = pnl / locked_capital, where locked_capital = qA*pA + qB*pB.
    """
    # Determine maker/taker for each side
    is_maker_A = (yes_ask_A is not None and pA < yes_ask_A) if yes_ask_A is not None else False
    is_maker_B = (yes_ask_B is not None and pB < yes_ask_B) if yes_ask_B is not None else False
    fA = kalshi_fee_per_contract(pA, is_maker=is_maker_A)
    fB = kalshi_fee_per_contract(pB, is_maker=is_maker_B)
    L  = max(1e-9, qA*pA + qB*pB)

    pnl_A = qA*(1 - pA - fA) - qB*(pB + fB)
    pnl_B = qB*(1 - pB - fB) - qA*(pA + fA)

    return pnl_A / L, pnl_B / L


# === Profit Protection Helper Functions ===

def aggregate_positions_on_side(event_positions: list, market_ticker: str) -> tuple:
    """
    Aggregate positions on one side (calculate total qty and weighted avg entry price).
    Returns (total_qty, weighted_avg_entry, total_cost).
    """
    total_qty = 0.0
    total_cost = 0.0
    
    for pos in event_positions:
        if pos.get("market_ticker") == market_ticker and not pos.get("settled", False):
            try:
                qty = float(pos.get("stake", 0))
                price = float(pos.get("entry_price", 0))
                if qty > 0 and price > 0:
                    total_qty += qty
                    total_cost += qty * price
            except (TypeError, ValueError):
                continue
    
    if total_qty <= 0:
        return 0.0, 0.0, 0.0
    
    weighted_avg = total_cost / total_qty
    return total_qty, weighted_avg, total_cost


def calculate_settlement_roi(qA: float, pA: float, qB: float, pB: float) -> float:
    """
    Calculate guaranteed ROI if held to settlement (either outcome).
    Returns the minimum ROI (both outcomes should be positive for hedged positions).
    Uses existing hedge_outcome_rois function.
    """
    roi_A, roi_B = hedge_outcome_rois(qA, pA, qB, pB)
    # Return the minimum (guaranteed minimum if held to settlement)
    return min(roi_A, roi_B)


def calculate_current_profit_mtm(
    qA: float, pA: float, qB: float, pB: float,
    current_price_A: float, current_price_B: float,
    yes_ask_A: Optional[float] = None, yes_ask_B: Optional[float] = None,
    yes_bid_A: Optional[float] = None, yes_bid_B: Optional[float] = None
) -> tuple:
    """
    Calculate current profit using mark-to-market (current bid prices - what you'd get when selling).
    Returns (profit_dollars, profit_pct, roi_A, roi_B).
    
    IMPORTANT: Includes BOTH entry fees (already paid) AND sell fees (would be paid) 
    to make it comparable with settlement ROI.
    """
    entry_cost = (qA * pA) + (qB * pB)  # Base entry cost (for denominator consistency)
    if entry_cost <= 0:
        return 0.0, 0.0, 0.0, 0.0
    
    # Validate current prices
    if current_price_A is None or current_price_B is None:
        # Fallback to settlement calculation if prices unavailable
        # Calculate total_entry_costs (with fees) for proper denominator
        is_maker_A = (yes_ask_A is not None and pA < yes_ask_A) if yes_ask_A is not None else False
        is_maker_B = (yes_ask_B is not None and pB < yes_ask_B) if yes_ask_B is not None else False
        fA = kalshi_fee_per_contract(pA, is_maker=is_maker_A)
        fB = kalshi_fee_per_contract(pB, is_maker=is_maker_B)
        total_entry_costs = qA * (pA + fA) + qB * (pB + fB)
        
        pnl_A = qA * (1.0 - pA - fA) - qB * (pB + fB)
        pnl_B = qB * (1.0 - pB - fB) - qA * (pA + fA)
        roi_A = pnl_A / total_entry_costs if total_entry_costs > 0 else 0.0
        roi_B = pnl_B / total_entry_costs if total_entry_costs > 0 else 0.0
        best_profit = max(pnl_A, pnl_B)
        best_profit_pct = best_profit / total_entry_costs if total_entry_costs > 0 else 0.0
        return best_profit, best_profit_pct, roi_A, roi_B
    
    # Clamp current prices to valid range
    current_price_A = max(0.01, min(0.99, float(current_price_A)))
    current_price_B = max(0.01, min(0.99, float(current_price_B)))
    
    # âœ… CORRECT CALCULATION: Include ALL fees (entry + sell)
    
    # Entry fees (already paid when entering) - use maker/taker based on entry price
    is_maker_A_entry = (yes_ask_A is not None and pA < yes_ask_A) if yes_ask_A is not None else False
    is_maker_B_entry = (yes_ask_B is not None and pB < yes_ask_B) if yes_ask_B is not None else False
    fA_entry = kalshi_fee_per_contract(pA, is_maker=is_maker_A_entry)
    fB_entry = kalshi_fee_per_contract(pB, is_maker=is_maker_B_entry)
    
    # Sell fees (would be paid when selling at current prices) - selling at bid is typically maker
    is_maker_A_exit = (yes_bid_A is not None and current_price_A > yes_bid_A) if yes_bid_A is not None else True
    is_maker_B_exit = (yes_bid_B is not None and current_price_B > yes_bid_B) if yes_bid_B is not None else True
    fA_sell = kalshi_fee_per_contract(current_price_A, is_maker=is_maker_A_exit)
    fB_sell = kalshi_fee_per_contract(current_price_B, is_maker=is_maker_B_exit)
    
    # Gross proceeds from selling (what you'd receive before fees)
    gross_proceeds_A = qA * current_price_A
    gross_proceeds_B = qB * current_price_B
    
    # Net proceeds after sell fees
    net_proceeds_A = gross_proceeds_A - (qA * fA_sell)
    net_proceeds_B = gross_proceeds_B - (qB * fB_sell)
    total_net_proceeds = net_proceeds_A + net_proceeds_B
    
    # Total costs (entry prices + entry fees - already paid)
    total_entry_costs = qA * (pA + fA_entry) + qB * (pB + fB_entry)
    
    # Current profit = net proceeds - total entry costs
    current_profit = total_net_proceeds - total_entry_costs
    
    # Calculate as percentage of total_entry_costs (includes fees - matches actual cost basis)
    current_profit_pct = current_profit / total_entry_costs if total_entry_costs > 0 else 0.0
    
    # Also calculate settlement ROIs for reference (roi_A, roi_B)
    # Use total_entry_costs for consistency with current_profit_pct denominator
    pnl_A_settle = qA * (1.0 - pA - fA_entry) - qB * (pB + fB_entry)
    pnl_B_settle = qB * (1.0 - pB - fB_entry) - qA * (pA + fA_entry)
    roi_A = pnl_A_settle / total_entry_costs if total_entry_costs > 0 else 0.0
    roi_B = pnl_B_settle / total_entry_costs if total_entry_costs > 0 else 0.0
    
    return current_profit, current_profit_pct, roi_A, roi_B


def check_if_positions_growing_recently(
    side_A_positions: list,
    side_B_positions: list,
    window_seconds: float = 300
) -> tuple:
    """
    Check if positions have been growing recently (active pyramiding).
    Returns (is_growing, last_trade_age_seconds, total_qty_now).
    """
    now = time.time()
    cutoff_time = now - window_seconds
    
    # Find most recent entry time across all positions
    most_recent_entry = None
    total_qty_now = 0.0
    
    for pos in side_A_positions + side_B_positions:
        if pos.get("settled", False):
            continue
        
        entry_time_str = pos.get("entry_time")
        if entry_time_str:
            try:
                entry_time = parse_iso_utc(entry_time_str)
                if entry_time:
                    entry_ts = entry_time.timestamp()
                    if most_recent_entry is None or entry_ts > most_recent_entry:
                        most_recent_entry = entry_ts
            except Exception:
                # Skip invalid entry times
                pass
        
        total_qty_now += float(pos.get("stake", 0))
    
    if most_recent_entry is None:
        return False, None, total_qty_now
    
    last_trade_age = now - most_recent_entry
    is_growing = last_trade_age < window_seconds
    
    return is_growing, last_trade_age, total_qty_now


def calculate_theoretical_max_profit(
    qA: float, pA: float, qB: float, pB: float,
    yes_ask_A: Optional[float] = None, yes_ask_B: Optional[float] = None
) -> tuple:
    """
    Calculate theoretical maximum profit for current position sizes.
    This is what you'd get at settlement (since one side will definitely win).
    For hedged positions, the "max" is just the better of the two settlement outcomes.
    
    Returns (max_profit_dollars, max_profit_pct).
    """
    locked_capital = (qA * pA) + (qB * pB)
    if locked_capital <= 0:
        return 0.0, 0.0
    
    # Fees - determine maker/taker for each side
    is_maker_A = (yes_ask_A is not None and pA < yes_ask_A) if yes_ask_A is not None else False
    is_maker_B = (yes_ask_B is not None and pB < yes_ask_B) if yes_ask_B is not None else False
    fA = kalshi_fee_per_contract(pA, is_maker=is_maker_A)
    fB = kalshi_fee_per_contract(pB, is_maker=is_maker_B)
    
    # Settlement outcomes (one will definitely happen)
    pnl_A = qA * (1.0 - pA - fA) - qB * (pB + fB)
    pnl_B = qB * (1.0 - pB - fB) - qA * (pA + fA)
    
    # Theoretical max is the better outcome
    max_profit = max(pnl_A, pnl_B)
    max_profit_pct = max_profit / locked_capital
    
    return max_profit, max_profit_pct


def calculate_target_sell_prices_for_max_roi(
    qA: float, entry_A: float, qB: float, entry_B: float, max_settlement_roi: float
) -> tuple:
    """
    Approximate sell prices needed to achieve max_settlement_roi.
    Returns (target_price_A, target_price_B) assuming proportional movement (fees ignored).
    
    Formula:
    max_settlement_roi = (qA * price_A + qB * price_B - entry_cost) / entry_cost
    Solving: price_A and price_B that satisfy this equation.
    
    We assume prices move proportionally from their entry prices toward $1.00.
    """
    entry_cost = (qA * entry_A) + (qB * entry_B)
    if entry_cost <= 0 or qA <= 0 or qB <= 0:
        return None, None
    
    # Target total value needed to achieve max_settlement_roi
    target_total_value = entry_cost * (1.0 + max_settlement_roi)
    
    # Calculate settlement values (what we'd get at $1.00 each)
    settlement_value_A = qA * 1.0  # If A wins, get $1 per contract
    settlement_value_B = qB * 1.0  # If B wins, get $1 per contract
    
    # Max settlement happens when the winning side pays $1.00
    # So max_settlement_roi corresponds to one side being worth $1.00
    # We'll calculate what prices would give us the same total value
    
    # Option 1: Calculate weighted average price needed
    total_contracts = qA + qB
    if total_contracts <= 0:
        return None, None
    
    # If we need target_total_value from total_contracts, average price is:
    avg_price_needed = target_total_value / total_contracts
    
    # But we need individual prices. Let's assume they move proportionally:
    # If entry_A was 40% and entry_B was 55%, and we need avg 75%,
    # we can interpolate proportionally
    
    # Calculate what each side would need if moving proportionally toward $1.00
    # from their entry prices
    
    # Distance from entry to $1.00 for each side
    distance_A = 1.0 - entry_A
    distance_B = 1.0 - entry_B
    
    # Total distance weighted by quantity
    total_weighted_distance = (qA * distance_A) + (qB * distance_B)
    
    if total_weighted_distance <= 0:
        return None, None
    
    # How much of the way toward $1.00 do we need to go?
    # Current total value = entry_cost
    # Target total value = entry_cost * (1 + max_settlement_roi)
    # Extra value needed = entry_cost * max_settlement_roi
    
    extra_value_needed = entry_cost * max_settlement_roi
    
    # Proportion of distance to travel
    if total_weighted_distance > 0:
        proportion = extra_value_needed / total_weighted_distance
        proportion = max(0.0, min(1.0, proportion))  # Clamp to [0, 1]
    else:
        proportion = 0.0
    
    # Calculate target prices
    target_price_A = entry_A + (proportion * distance_A)
    target_price_B = entry_B + (proportion * distance_B)
    
    # Clamp to valid range
    target_price_A = max(0.01, min(0.99, target_price_A))
    target_price_B = max(0.01, min(0.99, target_price_B))
    
    return target_price_A, target_price_B


def _parse_period_clock(period_clock: Optional[str]) -> Optional[tuple]:
    """
    Parse period_clock string to extract period number and time remaining.
    
    Formats:
    - Men's: "1 - 05:30" (1st half) or "2 - 03:15" (2nd half)
    - Women's: "3 - 00:17" (3rd quarter) or "4 - 05:00" (4th quarter)
    
    Returns (period: int, minutes_remaining: float) or None if unable to parse.
    """
    if not period_clock:
        return None
    
    try:
        # Format: "X - MM:SS" (period - minutes:seconds)
        parts = period_clock.strip().split(" - ")
        if len(parts) != 2:
            return None
        
        period_str = parts[0].strip()
        time_str = parts[1].strip()
        
        # Extract period number (handle "1", "2", "3", "4", "1st", "2nd", etc.)
        period = None
        for char in period_str:
            if char.isdigit():
                period = int(char)
                break
        
        if period is None:
            return None
        
        # Parse time (format: "MM:SS" or "M:SS")
        time_parts = time_str.split(":")
        if len(time_parts) != 2:
            return None
        
        minutes = int(time_parts[0])
        seconds = int(time_parts[1])
        total_minutes = minutes + (seconds / 60.0)
        
        return (period, total_minutes)
    except Exception:
        return None

def _can_trigger_7pct_exit(period_clock: Optional[str], match_name: Optional[str]) -> bool:
    """
    Check if aggressive exit can be triggered based on game time and type.
    
    Rules:
    - Women's games: Only in 4th quarter with â‰¤ ODDS_FEED_EXIT_TIME_MINUTES minutes left
    - Men's games: Only in 2nd half with â‰¤ ODDS_FEED_EXIT_TIME_MINUTES minutes left
    
    Returns True if conditions are met, False otherwise.
    If period_clock or match_name is not available, returns True (allow exit - backward compatible).
    """
    if not period_clock or not match_name:
        # If we don't have time info, allow exit (backward compatible)
        return True
    
    parsed = _parse_period_clock(period_clock)
    if not parsed:
        # Can't parse time, allow exit (backward compatible)
        return True
    
    period, minutes_remaining = parsed
    
    # Check if it's a women's game
    is_womens = "(W)" in str(match_name)
    
    if is_womens:
        # Women's: Only 4th quarter with â‰¤ configured minutes left
        return period == 4 and minutes_remaining <= ODDS_FEED_EXIT_TIME_MINUTES
    else:
        # Men's: Only 2nd half with â‰¤ configured minutes left
        return period == 2 and minutes_remaining <= ODDS_FEED_EXIT_TIME_MINUTES


def _should_block_trading_by_game_time(period_clock: Optional[str], match_name: Optional[str]) -> Optional[bool]:
    """
    Check if trading should be blocked based on game time and type.
    
    Rules:
    - Women's games: Block if 4th quarter with â‰¤ 8.0 minutes left
    - Men's games: Block if 2nd half with â‰¤ 8.0 minutes left
    
    Returns:
    - True if trading should be blocked
    - False if trading is allowed
    - None if game state is unavailable (caller should use fallback logic)
    """
    if not period_clock or not match_name:
        # Game state unavailable - return None to trigger fallback
        return None
    
    parsed = _parse_period_clock(period_clock)
    if not parsed:
        # Can't parse time - return None to trigger fallback
        return None
    
    period, minutes_remaining = parsed
    
    # Check if it's a women's game
    is_womens = "(W)" in str(match_name)
    
    if is_womens:
        # Women's: Block if 4th quarter with â‰¤ 8.0 minutes left
        return period == 4 and minutes_remaining <= 8.0
    else:
        # Men's: Block if 2nd half with â‰¤ 8.0 minutes left
        return period == 2 and minutes_remaining <= 8.0


def _should_block_early_game_trading(period_clock: Optional[str], match_name: Optional[str]) -> Optional[bool]:
    """
    Check if trading should be blocked because the game is too early.
    
    Rules:
    - Women's games: Block if Q1 has more than 5 minutes remaining (wait until at least 5 min into Q1)
    - Men's games: Block if Q1 has more than 15 minutes remaining (wait until at least 5 min into Q1)
    
    Returns:
    - True if trading should be blocked (too early)
    - False if trading is allowed
    - None if game state is unavailable (caller should use fallback logic)
    """
    if not period_clock or not match_name:
        # Game state unavailable - return None to trigger fallback
        return None
    
    parsed = _parse_period_clock(period_clock)
    if not parsed:
        # Can't parse time - return None to trigger fallback
        return None
    
    period, minutes_remaining = parsed
    
    # Check if it's a women's game
    is_womens = "(W)" in str(match_name)
    
    # Only block if we're still in Q1
    if period == 1:
        if is_womens:
            # Women's Q1 is 10 minutes - block if more than 5 minutes remaining
            return minutes_remaining > 5.0
        else:
            # Men's Q1 is 20 minutes - block if more than 15 minutes remaining
            return minutes_remaining > 15.0
    
    # If we're past Q1, allow trading
    return False


def check_profit_protection(
    event_ticker: str,
    side_A_positions: list,
    side_B_positions: list,
    side_A_ticker: str,
    side_B_ticker: str,
    side_A_sell_price: float,
    side_B_sell_price: float,
    side_A_ask: Optional[float] = None,
    side_B_ask: Optional[float] = None,
    side_A_bid: Optional[float] = None,
    side_B_bid: Optional[float] = None,
    odds_feed_home_prob: Optional[float] = None,
    odds_feed_away_prob: Optional[float] = None,
    side_A_is_home: bool = None,
    period_clock: Optional[str] = None,  # NEW: e.g., "3 - 00:17" or "2 - 05:30"
    match_name: Optional[str] = None     # NEW: e.g., "Miami Ohio (W) vs Cincinnati (W)"
) -> dict:
    """
    Comprehensive profit protection check WITH pyramiding awareness.
    Only triggers when pyramiding has stopped AND it's clearly better to exit.
    
    Uses actual sell prices (bid - 1 tick) to ensure accurate comparison with settlement ROI.
    
    Returns {
        "should_close": bool,
        "reason": str,
        "current_profit_pct": float,
        "peak_profit_pct": float,
        "max_profit_pct": float,
        "settlement_roi": float,
        "is_pyramiding": bool
    }
    """
    global _PEAK_PROFITS
    
    evt_key = event_key(event_ticker)
    
    # Aggregate positions (recalculate each time - positions can grow!)
    qty_A, entry_A, _ = aggregate_positions_on_side(side_A_positions, side_A_ticker)
    qty_B, entry_B, _ = aggregate_positions_on_side(side_B_positions, side_B_ticker)
    
    if qty_A <= 0 or qty_B <= 0:
        return {
            "should_close": False,
            "reason": "not_hedged",
            "current_profit_pct": 0.0
        }
    
    # === ABSOLUTE EXIT RULE - EXECUTES NO MATTER WHAT (with time and price restrictions) ===
    # This check happens FIRST and bypasses ALL other checks (spread, pyramiding, unbalanced hedge, EV, etc.)
    # If Kalshi best bid is between ODDS_FEED_EXIT_THRESHOLD_MIN and ODDS_FEED_EXIT_THRESHOLD, exit that side immediately
    # BUT: Only if time conditions are met (women's: 4th quarter â‰¤ODDS_FEED_EXIT_TIME_MINUTES min, men's: 2nd half â‰¤ODDS_FEED_EXIT_TIME_MINUTES min)
    if ODDS_FEED_AGGRESSIVE_EXIT_ENABLED:
        # Check if time conditions allow 7% exit
        can_trigger = _can_trigger_7pct_exit(period_clock, match_name)
        
        if not can_trigger:
            parsed = _parse_period_clock(period_clock)
            if parsed:
                period, minutes = parsed
                is_womens = "(W)" in str(match_name) if match_name else False
                game_type = "women's" if is_womens else "men's"
                period_label = "4th quarter" if is_womens else "2nd half"
                if VERBOSE:
                    print(f"â¸ï¸  7% EXIT BLOCKED: {game_type} game in period {period} with {minutes:.1f} min left - only allowed in {period_label} with â‰¤5min remaining")
        
        # Use bid price for trigger check (fallback to sell_price if bid not provided)
        side_A_bid_check = side_A_bid if side_A_bid is not None else side_A_sell_price
        side_B_bid_check = side_B_bid if side_B_bid is not None else side_B_sell_price
        
        # Check if side A has low bid price (between 5% and 10%) - NO OTHER CHECKS, EXECUTE IMMEDIATELY (if time allows)
        if (can_trigger and side_A_bid_check is not None and 
            side_A_bid_check <= ODDS_FEED_EXIT_THRESHOLD and 
            side_A_bid_check >= ODDS_FEED_EXIT_THRESHOLD_MIN):
            if VERBOSE:
                print(f"ðŸš¨ ABSOLUTE EXIT: Side A best bid {side_A_bid_check:.2%} is between {ODDS_FEED_EXIT_THRESHOLD_MIN:.0%}-{ODDS_FEED_EXIT_THRESHOLD:.0%} threshold - EXITING IMMEDIATELY (bypassing all other checks)")
            return {
                "should_close": True,
                "reason": f"absolute_exit_side_A_{side_A_bid_check:.1%}",
                "current_profit_pct": 0.0,
                "kalshi_price_triggered": True,
                "partial_exit_side": "A",  # Only sell side A
                "side_A_sell_price": side_A_sell_price,
                "side_B_sell_price": side_B_sell_price
            }
        elif can_trigger and side_A_bid_check is not None and side_A_bid_check < ODDS_FEED_EXIT_THRESHOLD_MIN:
            if VERBOSE:
                print(f"ðŸ›¡ï¸ EXIT BLOCKED: Side A best bid {side_A_bid_check:.2%} < {ODDS_FEED_EXIT_THRESHOLD_MIN:.0%} minimum - holding to settlement (avoiding fee trap, keeping lottery ticket)")
        
        # Check if side B has low bid price (between 5% and 10%) - NO OTHER CHECKS, EXECUTE IMMEDIATELY (if time allows)
        if (can_trigger and side_B_bid_check is not None and 
            side_B_bid_check <= ODDS_FEED_EXIT_THRESHOLD and 
            side_B_bid_check >= ODDS_FEED_EXIT_THRESHOLD_MIN):
            if VERBOSE:
                print(f"ðŸš¨ ABSOLUTE EXIT: Side B best bid {side_B_bid_check:.2%} is between {ODDS_FEED_EXIT_THRESHOLD_MIN:.0%}-{ODDS_FEED_EXIT_THRESHOLD:.0%} threshold - EXITING IMMEDIATELY (bypassing all other checks)")
            return {
                "should_close": True,
                "reason": f"absolute_exit_side_B_{side_B_bid_check:.1%}",
                "current_profit_pct": 0.0,
                "kalshi_price_triggered": True,
                "partial_exit_side": "B",  # Only sell side B
                "side_A_sell_price": side_A_sell_price,
                "side_B_sell_price": side_B_sell_price
            }
        elif can_trigger and side_B_bid_check is not None and side_B_bid_check < ODDS_FEED_EXIT_THRESHOLD_MIN:
            if VERBOSE:
                print(f"ðŸ›¡ï¸ EXIT BLOCKED: Side B best bid {side_B_bid_check:.2%} < {ODDS_FEED_EXIT_THRESHOLD_MIN:.0%} minimum - holding to settlement (avoiding fee trap, keeping lottery ticket)")
    
    # Check for unbalanced hedge (one side too small relative to other)
    # This prevents selling positions with extreme imbalance that could have negative settlement ROI
    hedge_ratio = min(qty_A, qty_B) / max(qty_A, qty_B) if max(qty_A, qty_B) > 0 else 0.0
    if hedge_ratio < 0.30:  # One side is less than 30% of the other
        if VERBOSE:
            print(f"ðŸ›¡ï¸ Profit protection blocked: Unbalanced hedge "
                  f"(qA={qty_A:.1f}, qB={qty_B:.1f}, ratio={hedge_ratio:.1%})")
        return {
            "should_close": False,
            "reason": "unbalanced_hedge",
            "current_profit_pct": 0.0,
            "hedge_ratio": hedge_ratio
        }
    
    # SAFEGUARD 1: Check if positions are actively growing (pyramiding)
    is_growing, last_trade_age, total_qty_now = check_if_positions_growing_recently(
        side_A_positions, side_B_positions, PROFIT_PROTECTION_PYRAMIDING_WINDOW
    )
    
    if is_growing and PROFIT_PROTECTION_REQUIRE_NO_RECENT_GROWTH:
        if VERBOSE:
            print(f"ðŸ›¡ï¸ Profit protection blocked: Positions actively growing "
                  f"(last trade {last_trade_age:.0f}s ago)")
        return {
            "should_close": False,
            "reason": "active_pyramiding",
            "current_profit_pct": 0.0,
            "pyramiding_active": True
        }
    
    # Calculate settlement ROI (both outcomes)
    roi_A, roi_B = hedge_outcome_rois(qty_A, entry_A, qty_B, entry_B)
    settlement_roi_min = min(roi_A, roi_B)  # Guaranteed minimum (worst case)
    
    # Calculate profit at actual sell prices (bid - 1 tick - what you'd actually get when selling)
    _, current_profit_pct, _, _ = calculate_current_profit_mtm(
        qty_A, entry_A, qty_B, entry_B,
        side_A_sell_price, side_B_sell_price
    )
    
    # Calculate WEIGHTED AVERAGE settlement ROI based on current market probabilities
    # Current sell prices represent market's view of win probabilities
    # Normalize them to get probability weights
    total_price = side_A_sell_price + side_B_sell_price
    if total_price > 0:
        prob_A = side_A_sell_price / total_price
        prob_B = side_B_sell_price / total_price
    else:
        # Fallback to 50/50 if prices are invalid
        prob_A = 0.5
        prob_B = 0.5
    
    # Expected settlement ROI = probability-weighted average of both outcomes
    weighted_settlement_roi = (prob_A * roi_A) + (prob_B * roi_B)
    
    # Extra safeguard: If weighted settlement ROI is negative, we should consider exiting if MTM is positive
    # (This catches edge cases where hedge is slightly imbalanced but still worth closing early)
    if weighted_settlement_roi < 0 and current_profit_pct > 0:
        if VERBOSE:
            print(f"âš ï¸ Weighted settlement ROI is negative ({weighted_settlement_roi:.2%}) but current MTM is positive ({current_profit_pct:.2%}) - allowing exit consideration")
        # Don't return here, let it proceed through normal checks
    
    # SAFEGUARD 2: Weighted Settlement-based floor
    # The natural floor is the EXPECTED settlement ROI based on current probabilities
    # This is adaptive to each position and reflects current market conditions
    settlement_floor = weighted_settlement_roi  # Expected value if held to settlement
    
    # For very negative settlements, we still want to allow exits if MTM is better
    # But we won't exit if we're doing WORSE than expected settlement (that would be irrational)
    if current_profit_pct < settlement_floor:
        if VERBOSE:
            print(f"ðŸ›¡ï¸ Profit protection blocked: Current MTM {current_profit_pct:.2%} < expected settlement {settlement_floor:.2%} "
                  f"(prob-weighted: {prob_A:.1%} Ã— {roi_A:.2%} + {prob_B:.1%} Ã— {roi_B:.2%}) - holding to settlement is better")
        return {
            "should_close": False,
            "reason": "worse_than_settlement",
            "current_profit_pct": current_profit_pct,
            "settlement_roi": weighted_settlement_roi,
            "settlement_roi_min": settlement_roi_min,
            "roi_A": roi_A,
            "roi_B": roi_B,
            "prob_A": prob_A,
            "prob_B": prob_B
        }
    
    # Calculate theoretical max (settlement - best outcome)
    _, theoretical_max_pct = calculate_theoretical_max_profit(qty_A, entry_A, qty_B, entry_B)
    
    # Use theoretical_max_pct directly (it's the same as max(roi_A, roi_B) but ensures consistency)
    max_settlement_roi = theoretical_max_pct
    
    # Track peak profit (actual sell price-based - bid - 1 tick - what you'd get when selling)
    peak_key = f"{evt_key}_peak"
    if peak_key not in _PEAK_PROFITS:
        _PEAK_PROFITS[peak_key] = {
            "profit_pct": current_profit_pct,
            "timestamp": time.time()
        }
    else:
        peak_data = _PEAK_PROFITS[peak_key]
        if current_profit_pct > peak_data["profit_pct"]:
            peak_data["profit_pct"] = current_profit_pct
            peak_data["timestamp"] = time.time()
    
    peak_profit_pct = _PEAK_PROFITS[peak_key]["profit_pct"]
    
    # Calculate target prices to reach max ROI
    target_price_A, target_price_B = calculate_target_sell_prices_for_max_roi(
        qty_A, entry_A, qty_B, entry_B, max_settlement_roi
    )
    
    result = {
        "should_close": False,
        "reason": None,
        "current_profit_pct": current_profit_pct,  # Actual sell price-based (bid - 1 tick - what you'd get when selling)
        "peak_profit_pct": peak_profit_pct,
        "max_profit_pct": max_settlement_roi,  # Use max_settlement_roi for consistency with comparison logic
        "settlement_roi": weighted_settlement_roi,  # Expected settlement ROI (probability-weighted)
        "settlement_roi_min": settlement_roi_min,  # Guaranteed minimum (worst case)
        "roi_A": roi_A,  # Outcome if A wins
        "roi_B": roi_B,  # Outcome if B wins
        "prob_A": prob_A,  # Market probability of A winning
        "prob_B": prob_B,  # Market probability of B winning
        "is_pyramiding": is_growing if is_growing else False,
        "target_price_A": target_price_A,  # Price needed on side A to reach max ROI
        "target_price_B": target_price_B   # Price needed on side B to reach max ROI
    }
    
    # SAFEGUARD: Minimum hold time after hedge (applies to profit protection exits, NOT 7% exit)
    # The 7% exit (checked above) can trigger immediately, but other profit protection exits require 5 minutes
    latest_entry_time = None
    for pos in side_A_positions + side_B_positions:
        entry_time_str = pos.get("entry_time")
        if entry_time_str:
            try:
                entry_time = parse_iso_utc(entry_time_str)
                if entry_time and (latest_entry_time is None or entry_time > latest_entry_time):
                    latest_entry_time = entry_time
            except Exception:
                pass
    
    if latest_entry_time:
        now_dt = now_utc()
        hold_duration = (now_dt - latest_entry_time).total_seconds()
        
        if hold_duration < PROFIT_PROTECTION_MIN_HOLD_SECONDS:
            if VERBOSE:
                print(f"ðŸ›¡ï¸ Profit protection blocked: Only {hold_duration:.0f}s since hedge "
                      f"(need {PROFIT_PROTECTION_MIN_HOLD_SECONDS}s minimum)")
            return {
                "should_close": False,
                "reason": "too_soon_after_hedge",
                "current_profit_pct": current_profit_pct
            }
    
    # Check minimum time remaining before allowing profit protection exit
    if PROFIT_PROTECTION_ENABLED:
        # Parse period_clock to get time remaining
        time_remaining = None
        if period_clock:
            parsed = _parse_period_clock(period_clock)
            if parsed:
                period, minutes = parsed
                time_remaining = minutes * 60.0  # Convert to seconds
        
        if time_remaining is not None and time_remaining < PROFIT_PROTECTION_MIN_TIME_REMAINING:
            if VERBOSE:
                print(f"â¸ï¸ Skip profit protection exit â€” only {time_remaining:.1f}s remaining "
                      f"(minimum {PROFIT_PROTECTION_MIN_TIME_REMAINING:.1f}s required)")
            return {
                "should_close": False,
                "reason": "insufficient_time_remaining",
                "current_profit_pct": current_profit_pct,
                "time_remaining": time_remaining
            }
    
    # === 1. MAX PROFIT DETECTION (only if NOT pyramiding) ===
    # Compare current MTM profit (at actual sell prices - bid - 1 tick) to maximum settlement ROI
    if MAX_PROFIT_DETECTION_ENABLED and max_settlement_roi > 0 and not is_growing:
        # Calculate ratio: how close is current MTM profit (at actual sell price) to best settlement outcome?
        max_profit_ratio = current_profit_pct / max_settlement_roi if max_settlement_roi > 0 else 0.0
        
        if max_profit_ratio >= MAX_PROFIT_THRESHOLD:
            # When at 90%+ of theoretical max, use SMALLER margin requirement
            # (capturing this much of max is already excellent - don't be too greedy)
            margin_for_max_profit = min(
                PROFIT_PROTECTION_MIN_MARGIN_ABOVE_SETTLEMENT * 0.33,  # 1/3 of normal margin
                0.01  # Cap at 1% maximum
            )
            required_profit = weighted_settlement_roi + margin_for_max_profit
            
            # Check both: above settlement+margin AND above absolute minimum safety threshold
            if current_profit_pct >= required_profit and current_profit_pct >= PROFIT_PROTECTION_MIN_ABSOLUTE_PROFIT:
                result["should_close"] = True
                result["reason"] = f"max_profit_{max_profit_ratio:.0%}_no_pyramiding"
                if VERBOSE:
                    target_A = result.get("target_price_A")
                    target_B = result.get("target_price_B")
                    target_info = ""
                    if target_A is not None and target_B is not None:
                        target_info = f" (target prices for max ROI: {target_A:.2%}, {target_B:.2%})"
                    
                    print(f"ðŸš€ MAX PROFIT: {current_profit_pct:.2%} ({max_profit_ratio:.0%} of settlement max {max_settlement_roi:.2%}), "
                          f"above settlement+margin {required_profit:.2%} (reduced margin: {margin_for_max_profit:.2%}) and absolute min {PROFIT_PROTECTION_MIN_ABSOLUTE_PROFIT:.1%}, NOT pyramiding - taking profit!{target_info}")
                return result
            elif current_profit_pct >= required_profit:
                # Above settlement but below absolute minimum - log and hold
                if VERBOSE:
                    print(f"ðŸ›¡ï¸ Max profit trigger activated ({max_profit_ratio:.0%}) and above settlement+margin ({current_profit_pct:.2%} > {required_profit:.2%}), "
                          f"but below absolute minimum {PROFIT_PROTECTION_MIN_ABSOLUTE_PROFIT:.1%} - holding for safety")
            else:
                if VERBOSE:
                    print(f"ðŸ›¡ï¸ Max profit reached ({max_profit_ratio:.0%}) but {current_profit_pct:.2%} < settlement+margin {required_profit:.2%} "
                          f"(reduced margin: {margin_for_max_profit:.2%}) - holding")
    
    # === 2. TRAILING STOP (only if NOT pyramiding AND profit dropping) ===
    # Use actual sell price-based profit (bid - 1 tick - what you'd actually get when selling)
    if TRAILING_STOP_ENABLED and current_profit_pct >= MIN_PROFIT_FOR_TRAILING_STOP and not is_growing:
        # Use unified TRAILING_STOP_PCT instead of separate initial/tightened values
        trailing_stop_pct = TRAILING_STOP_PCT
        # Optionally tighten if profit exceeds threshold
        if peak_profit_pct >= TRAILING_STOP_TIGHTEN_THRESHOLD:
            trailing_stop_pct = TRAILING_STOP_PCT * 0.5  # Tighten to 50% of base
        stop_distance = trailing_stop_pct
        
        # Compare current profit to peak profit
        drop_from_peak = max(0.0, peak_profit_pct - current_profit_pct)
        
        if drop_from_peak >= stop_distance:
            # Use reduced margin for trailing stop (consistent with max profit logic)
            # When profit is dropping, we want to be aggressive about locking in gains
            margin_for_trailing = min(
                PROFIT_PROTECTION_MIN_MARGIN_ABOVE_SETTLEMENT * 0.5,  # Half of normal margin
                0.0075  # Cap at 0.75%
            )
            required_profit = weighted_settlement_roi + margin_for_trailing
            
            # Check both: above settlement+margin AND above absolute minimum safety threshold
            if current_profit_pct > required_profit and current_profit_pct >= PROFIT_PROTECTION_MIN_ABSOLUTE_PROFIT:
                result["should_close"] = True
                result["reason"] = f"trailing_stop_drop_{drop_from_peak:.1%}_no_pyramiding"
                if VERBOSE:
                    print(f"ðŸ›‘ TRAILING STOP: {current_profit_pct:.2%} dropped {drop_from_peak:.2%} from peak {peak_profit_pct:.2%}, "
                          f"{current_profit_pct:.2%} > settlement+margin {required_profit:.2%} (reduced margin: {margin_for_trailing:.2%}) and absolute min {PROFIT_PROTECTION_MIN_ABSOLUTE_PROFIT:.1%}, NOT pyramiding - closing!")
            elif current_profit_pct > required_profit:
                # Above settlement but below absolute minimum - log and hold
                if VERBOSE:
                    print(f"ðŸ›¡ï¸ Trailing stop activated (drop {drop_from_peak:.2%}) and above settlement+margin ({current_profit_pct:.2%} > {required_profit:.2%}), "
                          f"but below absolute minimum {PROFIT_PROTECTION_MIN_ABSOLUTE_PROFIT:.1%} - holding for safety")
            else:
                if VERBOSE:
                    print(f"ðŸ›¡ï¸ Trailing stop triggered but {current_profit_pct:.2%} <= settlement+margin {required_profit:.2%} "
                          f"(reduced margin: {margin_for_trailing:.2%}) - holding")
    
    # If we reach here, no exit triggers fired - log diagnostic info if profit is significant
    if VERBOSE and current_profit_pct > 0.03:  # Only log if > 3% profit
        max_profit_ratio = current_profit_pct / max_settlement_roi if max_settlement_roi > 0 else 0.0
        drop_from_peak = max(0.0, peak_profit_pct - current_profit_pct)
        
        reasons = []
        if not MAX_PROFIT_DETECTION_ENABLED:
            reasons.append("max profit disabled")
        elif max_profit_ratio < MAX_PROFIT_THRESHOLD:
            reasons.append(f"only {max_profit_ratio:.0%} of max")
        
        if not TRAILING_STOP_ENABLED:
            reasons.append("trailing stop disabled")
        elif drop_from_peak < (TRAILING_STOP_TIGHTENED_PCT if peak_profit_pct >= TRAILING_STOP_TIGHTEN_THRESHOLD else TRAILING_STOP_INITIAL_PCT):
            reasons.append(f"drop {drop_from_peak:.1%} < threshold")
        
        if is_growing:
            reasons.append("pyramiding active")
        
        if reasons:
            print(f"ðŸ’¤ Holding position: {current_profit_pct:.2%} profit (peak: {peak_profit_pct:.2%}, max: {max_settlement_roi:.2%}) - {', '.join(reasons)}")
    
    return result


def market_yes_mid(market: Optional[dict]) -> Optional[float]:
    """Return best-effort YES mid price for a Kalshi market."""
    if not market:
        return None
    yb = format_price(market.get("yes_bid"))
    ya = format_price(market.get("yes_ask"))
    if yb is not None and ya is not None:
        return (yb + ya) / 2.0
    return ya if ya is not None else yb


def report_event_hedge_bands(event_ticker: str, kalshi_markets=None, label: str = ""):
    """
    After any trade, show q_low/q_high using the opposite sideâ€™s current midpoint.
    Helpful for sanity-checking hedge readiness even when no hedge order is sent.
    """
    evt_key = event_key(event_ticker)
    event_positions = [
        p for p in positions
        if event_key(p.get("event_ticker")) == evt_key
        and p.get("side") == "yes"
        and p.get("stake", 0) > 0
    ]
    if not event_positions:
        return

    mkts = kalshi_markets or get_kalshi_markets(event_ticker, force_live=True) or []
    if not mkts:
        print("âš ï¸ Hedge-band snapshot skipped â€” no Kalshi markets available.")
        return

    yes_markets = [
        m for m in mkts
        if (m.get("market_type") == "binary") and (m.get("yes_sub_title") not in (None, ""))
    ]
    if len(yes_markets) > 2:
        print("âš ï¸ Hedge-band snapshot ambiguous â€” more than two YES markets detected.")
        return

    print(f"ðŸ“ Hedge bands @ live mids for {label or event_ticker}:")
    for pos in event_positions:
        opp_market = next(
            (
                m for m in mkts
                if event_key(m.get("event_ticker") or event_ticker) == evt_key
                and m.get("ticker") != pos.get("market_ticker")
            ),
            None
        )
        if not opp_market:
            print(f"   - {pos['market_ticker']}: opposite market not found.")
            continue

        opp_mid = market_yes_mid(opp_market)
        if opp_mid is None:
            print(f"   - {pos['market_ticker']}: no mid available for {opp_market.get('ticker')}.")
            continue

        # keep odds in a sane range so band math never explodes
        opp_mid = max(0.01, min(0.99, float(opp_mid)))

        q_low, q_high = hedge_qty_bounds_target_roi(
            float(pos["stake"]),
            float(pos["entry_price"]),
            float(opp_mid),
            r=MIN_HEDGE_RETURN
        )
        if q_low is None or q_high is None:
            continue
        ql_i = math.ceil(q_low)
        qh_i = math.floor(q_high)
        print(
            f"   - {pos['market_ticker']} hedge via {opp_market.get('ticker')} @ {opp_mid:.2%} â†’ "
            f"q in [{ql_i}, {qh_i}]"
        )


def _positions_snapshot_text() -> str:
    """Return a human-readable snapshot of current positions and live prices."""
    active_positions = [p for p in positions if not p.get("settled", False)]
    if not active_positions:
        return "No open positions."

    lines = ["Match | Side | Qty | Entry | Live | P&L | ROI%"]
    markets_cache: Dict[str, list] = {}
    total_unreal = 0.0
    rows_added = 0

    for pos in active_positions:
        qty = int(pos.get("stake", 0))
        if qty <= 0:
            continue

        evt = pos.get("event_ticker") or ""
        key = event_key(evt)
        if key not in markets_cache:
            mkts = []
            if evt:
                try:
                    mkts = get_kalshi_markets(evt, force_live=True) or []
                except Exception as exc:
                    print(f"âš ï¸ Email snapshot: market fetch failed for {evt}: {exc}")
            markets_cache[key] = mkts

        mkts = markets_cache[key]
        market = next((m for m in mkts if m.get("ticker") == pos.get("market_ticker")), None)
        live_price = market_yes_mid(market) if market else None

        entry = float(pos.get("entry_price", 0.0))
        unrealized = None if live_price is None else (live_price - entry) * qty
        roi = None
        if unrealized is not None and entry > 0 and qty > 0:
            roi = unrealized / (qty * entry)

        live_str = "--" if live_price is None else f"{live_price:.2%}"
        unrealized_str = "--" if unrealized is None else f"${unrealized:,.2f}"
        roi_str = "--" if roi is None else f"{roi * 100:.2f}%"

        lines.append(
            f"{pos.get('match','?')} | {pos.get('side','').upper()} | {qty} | "
            f"{entry:.2%} | {live_str} | {unrealized_str} | {roi_str}"
        )

        if unrealized is not None:
            total_unreal += unrealized
        rows_added += 1

    if rows_added == 0:
        lines.append("No open positions.")

    # --- Calculate cost of positions ---
    total_cost_of_positions = 0.0
    for pos in active_positions:
        qty = int(pos.get("stake", 0))
        entry = float(pos.get("entry_price", 0.0))
        if qty > 0 and entry > 0:
            total_cost_of_positions += qty * entry

    # --- session summary ---
    session_equity = None
    current_cash = None
    if PLACE_LIVE_KALSHI_ORDERS == "YES":
        try:
            current_cash = get_kalshi_balance()
        except Exception as exc:
            print(f"âš ï¸ Email snapshot: balance fetch failed: {exc}")
            current_cash = SESSION_START_BAL or 0.0
        # Total equity = cash + cost of positions + unrealized P&L
        session_equity = (current_cash or 0.0) + total_cost_of_positions + total_unreal
    else:
        current_cash = capital_sim + realized_pnl
        # Total equity = cash + cost of positions + unrealized P&L
        session_equity = capital_sim + realized_pnl + total_cost_of_positions + total_unreal

    session_roi_str = "--"
    if SESSION_START_BAL not in (None, 0):
        session_roi = (session_equity - SESSION_START_BAL) / SESSION_START_BAL
        session_roi_str = f"{session_roi * 100:.2f}%"

    lines.append("")
    lines.append("=" * 60)
    lines.append("CAPITAL BREAKDOWN:")
    lines.append(f"  Current Cash Balance: ${current_cash:,.2f}")
    lines.append(f"  Cost of Positions: ${total_cost_of_positions:,.2f}")
    lines.append(f"  Unrealized P&L: ${total_unreal:,.2f}")
    lines.append("-" * 60)
    lines.append(f"  Total Equity: ${session_equity:,.2f}")
    lines.append("=" * 60)
    lines.append(f"ROI since start: {session_roi_str}")

    timestamp = now_utc().isoformat()
    return f"Snapshot at {timestamp}\n" + "\n".join(lines)


def send_positions_email(reason: str = "hourly"):
    """Email the current positions snapshot if emailing is enabled."""
    if not SEND_EMAIL_TURN_ON:
        return
    if not EMAIL_SENDER or not EMAIL_APP_PASSWORD:
        print("âš ï¸ Email disabled â€” missing EMAIL_SENDER or EMAIL_APP_PASSWORD.")
        return

    body = _positions_snapshot_text()
    subject = f"Kalshi positions update ({reason})"

    msg = EmailMessage()
    msg["Subject"] = subject
    msg["From"] = EMAIL_SENDER
    msg["To"] = EMAIL_RECIPIENT
    msg.set_content(body)

    try:
        with smtplib.SMTP_SSL(EMAIL_SMTP_HOST, EMAIL_SMTP_PORT, timeout=15) as smtp:
            smtp.login(EMAIL_SENDER, EMAIL_APP_PASSWORD)
            smtp.send_message(msg)
        print(f"ðŸ“§ Sent positions email to {EMAIL_RECIPIENT} ({reason}).")
        print(f"Email sent to {EMAIL_RECIPIENT}")
    except Exception as exc:
        print(f"âš ï¸ Failed to send positions email: {exc}")


def log_hedge_band_preview(existing_position: dict, candidate_market: dict, match_label: str):
    """
    During hedge evaluation, show the current q_low/q_high band using the live midpoint
    of the candidate market so we can see what would be required even if we skip the trade.
    """
    if not SHOW_HEDGE_BAND_PREVIEW:
        return
    if not existing_position or not candidate_market:
        return

    hedge_mid = market_yes_mid(candidate_market)
    opp_label = candidate_market.get("yes_sub_title") or candidate_market.get("ticker") or "opposite side"

    if hedge_mid is None:
        return

    # Clamp to Kalshi's practical range so bounding math stays finite.
    hedge_mid = max(0.01, min(0.99, float(hedge_mid)))

    try:
        q_band = hedge_qty_bounds_target_roi(
            float(existing_position.get("stake", 0)),
            float(existing_position.get("entry_price", 0)),
            float(hedge_mid),
            r=MIN_HEDGE_RETURN
        )
    except Exception:
        return

    if not q_band:
        return

    q_low, q_high = q_band
    if q_low is None or q_high is None:
        return
    try:
        ql_i = math.ceil(float(q_low))
        qh_i = math.floor(float(q_high))
    except (TypeError, ValueError):
        return

    print(
        f"   ðŸ“ Hedge preview: {opp_label} @ {hedge_mid:.2%} â†’ q_low={ql_i}, q_high={qh_i}"
    )


def format_price(price, units_hint="usd_cent"):
    """
    Normalize raw Kalshi/odds-feed prices to float between 0 and 1.
    Compatible with both old calls and those passing `units_hint`.
    """
    if price is None:
        return None
    try:
        v = float(price)
    except Exception:
        return None
    if units_hint == "usd_cent":
        v /= 100.0
    return max(0.0, min(1.0, v))


# === MATH / DEVIG / EV HELPERS ===

USE_SHIN_DEVIG = True          # set False to keep proportional de-vig

def devig_proportional(p_raw):
    s = sum(p_raw)
    return [x/s for x in p_raw] if s else [None]*len(p_raw)

def devig_shin_two_way(dec_home, dec_away, tol=1e-9, max_iter=100):
    ph = 1.0/dec_home; pa = 1.0/dec_away
    s = ph + pa
    qh, qa = ph/s, pa/s
    z = 0.0
    def fair_q(q, z_):
        return (math.sqrt(z_*z_ + 4*(1-z_)*q) - z_) / (2*(1-z_) + 1e-12)
    for _ in range(max_iter):
        fh, fa = fair_q(qh, z), fair_q(qa, z)
        F = (fh + fa) - 1.0
        if abs(F) < tol: break
        dz = 1e-5
        Fp = (fair_q(qh, z+dz) + fair_q(qa, z+dz)) - 1.0
        dF = (Fp - F) / dz if abs(Fp - F) > 1e-15 else 0.0
        if abs(dF) < 1e-12: break
        z = max(0.0, min(0.999999, z - F/dF))
    return fh, fa

def ev_exit_yes(odds_prob, entry_price, yes_bid, yes_ask):
    """
    Backwards-compat wrapper; compute settlement EV using entry_price only.
    Returns (ev_cash_per_ct, ev_pct_on_entry).
    """
    return ev_settlement_yes(odds_prob, entry_price)


def ev_settlement_yes(p: float, entry_price: float, yes_ask_raw: Optional[int] = None, yes_ask: Optional[float] = None):
    """
    EV to settlement if we BUY YES and hold, always including Kalshi entry fees.
    yes_ask_raw is accepted for compatibility but no longer suppresses fees.
    Returns: (ev_cash_per_ct, ev_pct_on_entry)
    """
    if entry_price is None:
        return None, None
    entry_fee = maker_entry_fee(entry_price, yes_ask_raw, yes_ask=yes_ask)
    ev_cash = p - entry_price - entry_fee
    ev_pct = (ev_cash / entry_price) if entry_price > 0 else None
    return ev_cash, ev_pct


def ev_mark_to_bid_yes(entry_price: float, yes_bid: Optional[float]):
    """
    Instant liquidation PnL per contract (cash), if we SOLD now at yes_bid.
    Diagnostic only (you don't exit early today).
    """
    if yes_bid is None or entry_price is None:
        return None
    # Selling at bid is typically a maker order (resting above bid)
    exit_fee = kalshi_fee_per_contract(yes_bid, is_maker=True)
    return (yes_bid - entry_price) - exit_fee

def kelly_yes_with_costs(p, price, rt_cost=0.0):
    p_eff = min(max(price + rt_cost, 1e-6), 1-1e-6)
    b = (1/p_eff) - 1
    q = 1 - p
    f = (b*p - q) / b
    return max(0.0, f)

def log_trade(trade):
    if not WRITE_TRADES_CSV:
        return

    # âœ… Skip ghost trades (no stake)
    if not trade.get("stake") or trade["stake"] <= 0:
        return

    # âœ… Try to confirm, but donâ€™t block logging if not visible yet
    try:
        live_positions = get_live_positions()
        live_keys = {(p["ticker"], p["side"]) for p in live_positions}
        local_key = (trade.get("market_ticker"), trade.get("side"))
        if local_key not in live_keys:
            print(f"âš ï¸ Not yet visible on Kalshi ({local_key}) â€” logging anyway.")
    except Exception as e:
        print(f"âš ï¸ Live confirm error ({e}) â€” logging anyway.")

    # --- always log now ---
    path = "trades_basketball.csv"
    write_header = not os.path.exists(path) or os.path.getsize(path) == 0
    with open(path, "a", newline="") as f:
        writer = csv.DictWriter(f, fieldnames=trade.keys())
        if write_header:
            writer.writeheader()
        writer.writerow(trade)

    # Show HOME/AWAY if available, otherwise fall back to side
    side_display = trade.get('side_name', trade.get('side', 'UNKNOWN'))
    print(f"ðŸ“ Trade logged: {trade.get('match')} {side_display} x{trade.get('stake')}")


def _append_csv(path, row, fixed_fields=None, add_timestamp=False):
    """
    Appends a row to CSV with consistent columns.
    If add_timestamp=True â†’ automatically prepends ts field.
    Respects CSV writing switches - returns early if CSV writing is disabled.
    """
    # Check if CSV writing is disabled (all switches are False)
    if not any([WRITE_SNAPSHOTS, WRITE_EVALS, WRITE_BOT_LOG, WRITE_TRADES_CSV, 
                WRITE_SESSION_METRICS, WRITE_TRADE_METRICS, WRITE_BACKTEST_FEED]):
        return
    
    # Add timestamp once (if desired)
    if add_timestamp:
        row = {"ts": now_utc().isoformat(), **row}

    # Build stable field ordering
    cols = list(fixed_fields or [])
    for k in row.keys():
        if k not in cols:
            cols.append(k)

    write_header = not os.path.exists(path) or os.path.getsize(path) == 0

    with open(path, "a", newline="") as f:
        writer = csv.DictWriter(f, fieldnames=cols)
        if write_header:
            writer.writeheader()
        writer.writerow({k: row.get(k, "") for k in cols})


def log_backtest_metrics(row: dict):
    """
    Logs detailed per-trade analytics for later model tuning.
    Creates/updates 'trade_metrics.csv' with factors like
    spread width, volatility mode, EV, Kelly, and realized PnL.
    """
    if not WRITE_TRADE_METRICS:
        return
    
    path = "trade_metrics_basketball.csv"
    cols = [
        "ts","match","market_ticker","side","entry_price","exit_price",
        "odds_prob","spread","fair_ev","kelly_fraction","volatility_mode",
        "stake","pnl_cash","pnl_pct","hold_seconds"
    ]
    row = {"ts": now_utc().isoformat(), **row}
    with open(path, "a", newline="") as f:
        w = csv.DictWriter(f, fieldnames=cols)
        if f.tell() == 0:
            w.writeheader()
        w.writerow({k: row.get(k, "") for k in cols})


# Cache for first detection times to avoid repeated file reads
_FIRST_DETECTION_TIMES = {}
_FIRST_DETECTION_TIMES_LOADED = False


def load_first_detection_times():
    """
    Load first detection times from JSON file.
    Returns a dictionary mapping event_ticker to ISO timestamp strings.
    """
    global _FIRST_DETECTION_TIMES, _FIRST_DETECTION_TIMES_LOADED
    
    if _FIRST_DETECTION_TIMES_LOADED:
        return _FIRST_DETECTION_TIMES
    
    if not os.path.exists(FIRST_DETECTION_TIMES_FILE):
        _FIRST_DETECTION_TIMES_LOADED = True
        return {}
    
    try:
        with open(FIRST_DETECTION_TIMES_FILE, 'r', encoding='utf-8') as f:
            data = json.load(f)
            # Convert ISO strings to datetime objects in cache
            for ticker, iso_str in data.items():
                try:
                    _FIRST_DETECTION_TIMES[ticker] = parse_iso_utc(iso_str)
                except Exception:
                    continue
        
        # Clean up old entries on load (runs once per startup)
        cleanup_old_first_detection_times(max_age_hours=48.0)
        
        _FIRST_DETECTION_TIMES_LOADED = True
        return _FIRST_DETECTION_TIMES
    except Exception as e:
        if VERBOSE:
            print(f"âš ï¸ Error loading first detection times: {e}")
        _FIRST_DETECTION_TIMES_LOADED = True
        return {}


def save_first_detection_times():
    """
    Save first detection times to JSON file.
    Converts datetime objects to ISO timestamp strings.
    """
    global _FIRST_DETECTION_TIMES
    
    try:
        # Convert datetime objects to ISO strings for JSON
        data = {}
        for ticker, dt in _FIRST_DETECTION_TIMES.items():
            if dt:
                data[ticker] = dt.isoformat()
        
        # Ensure directory exists
        file_dir = os.path.dirname(FIRST_DETECTION_TIMES_FILE)
        if file_dir:  # Only create directory if path is not empty
            os.makedirs(file_dir, exist_ok=True)
        
        with open(FIRST_DETECTION_TIMES_FILE, 'w', encoding='utf-8') as f:
            json.dump(data, f, indent=2)
    except Exception as e:
        if VERBOSE:
            print(f"âš ï¸ Error saving first detection times: {e}")


def cleanup_old_first_detection_times(max_age_hours: float = 48.0):
    """
    Remove first detection times older than max_age_hours.
    This prevents the file from growing indefinitely with old game data.
    
    Args:
        max_age_hours: Maximum age in hours before removal (default: 48 hours)
    
    Note: This function assumes _FIRST_DETECTION_TIMES is already loaded.
    It should be called from load_first_detection_times() after loading data.
    """
    global _FIRST_DETECTION_TIMES
    
    if not _FIRST_DETECTION_TIMES:
        return 0
    
    current_time = now_utc()
    max_age_seconds = max_age_hours * 3600.0
    initial_count = len(_FIRST_DETECTION_TIMES)
    
    # Remove entries older than max_age_hours
    cleaned = {}
    removed_count = 0
    for ticker, detection_time in _FIRST_DETECTION_TIMES.items():
        if detection_time:
            age_seconds = (current_time - detection_time).total_seconds()
            if age_seconds <= max_age_seconds:
                cleaned[ticker] = detection_time
            else:
                removed_count += 1
    
    if removed_count > 0:
        _FIRST_DETECTION_TIMES = cleaned
        save_first_detection_times()
        if VERBOSE:
            print(f"ðŸ§¹ Cleaned up {removed_count} old first detection times (kept {len(cleaned)}, removed entries older than {max_age_hours:.0f} hours)")
    
    return removed_count


def record_first_detection_time(event_ticker: str, detection_time: Optional[datetime] = None):
    """
    Record the first detection time for an event.
    Always preserves the earliest detection time - updates if new time is earlier.
    Saves to JSON file.
    """
    global _FIRST_DETECTION_TIMES
    
    # Load from file if not already loaded
    load_first_detection_times()
    
    ticker_key = event_key(event_ticker)
    
    if detection_time is None:
        detection_time = now_utc()
    
    # Record if not set, or update if new time is earlier (preserve earliest detection)
    if ticker_key not in _FIRST_DETECTION_TIMES:
        _FIRST_DETECTION_TIMES[ticker_key] = detection_time
        save_first_detection_times()
        if VERBOSE:
            print(f"ðŸ“ First detection recorded: {event_ticker} at {detection_time.strftime('%H:%M:%S')}")
        return True
    elif detection_time < _FIRST_DETECTION_TIMES[ticker_key]:
        # Update to earlier time
        _FIRST_DETECTION_TIMES[ticker_key] = detection_time
        save_first_detection_times()
        if VERBOSE:
            print(f"ðŸ“ First detection updated to earlier time: {event_ticker} at {detection_time.strftime('%H:%M:%S')}")
        return True
    return False


def get_first_detection_time(event_ticker: str) -> Optional[datetime]:
    """
    Get the first detection time for an event.
    Priority:
      1. In-memory cache (already loaded)
      2. JSON file (first_detection_times.json)
      3. CSV file (for backwards compatibility)
      4. Record current time as first detection if not found
    Results are cached to avoid repeated file reads.
    """
    global _FIRST_DETECTION_TIMES
    
    # Load from JSON file if not already loaded
    load_first_detection_times()
    
    ticker_key = event_key(event_ticker)
    
    # Check cache first
    if ticker_key in _FIRST_DETECTION_TIMES and _FIRST_DETECTION_TIMES[ticker_key]:
        return _FIRST_DETECTION_TIMES[ticker_key]
    
    # Try to find in CSV - check multiple locations (for backwards compatibility)
    csv_paths = [
        os.path.join(BASE_DIR, "market_snapshots_for_duke_basketball.csv"),
        os.path.join(os.path.dirname(BASE_DIR), "market_snapshots_for_duke_basketball.csv"),
        "market_snapshots_for_duke_basketball.csv",  # Current directory
    ]
    
    first_ts = None
    csv_path = None
    for path in csv_paths:
        if os.path.exists(path):
            csv_path = path
            break
    
    if csv_path:
        try:
            with open(csv_path, 'r', encoding='utf-8') as f:
                reader = csv.DictReader(f)
                for row in reader:
                    # Check both 'ticker' and 'event_ticker' columns
                    ticker_match = (
                        row.get("ticker", "").upper() == event_ticker.upper() or
                        row.get("event_ticker", "").upper() == event_ticker.upper()
                    )
                    if ticker_match:
                        # Check both 'ts' and 'kalshi_fetch_ts' columns, use earliest
                        for ts_col in ["ts", "kalshi_fetch_ts"]:
                            ts_str = row.get(ts_col, "")
                            if ts_str:
                                try:
                                    ts = parse_iso_utc(ts_str)
                                    if first_ts is None or ts < first_ts:
                                        first_ts = ts
                                except Exception:
                                    continue
            # If found in CSV, save to JSON for future use (preserve earliest if already exists)
            if first_ts:
                if ticker_key in _FIRST_DETECTION_TIMES:
                    # Use the earlier time
                    if first_ts < _FIRST_DETECTION_TIMES[ticker_key]:
                        _FIRST_DETECTION_TIMES[ticker_key] = first_ts
                        save_first_detection_times()
                else:
                    _FIRST_DETECTION_TIMES[ticker_key] = first_ts
                    save_first_detection_times()
        except Exception as e:
            if VERBOSE:
                print(f"âš ï¸ Error reading first detection time from CSV: {e}")
    
    # âœ… If not found, record current time as first detection
    if first_ts is None:
        first_ts = now_utc()
        _FIRST_DETECTION_TIMES[ticker_key] = first_ts
        save_first_detection_times()
        if VERBOSE:
            print(f"ðŸ“ First detection recorded for {event_ticker}: {first_ts.strftime('%H:%M:%S')}")
    
    return first_ts

def log_snapshot_scan(match: dict):
    """
    Build and append a rich snapshot row for market_snapshots_for_duke_basketbal.csv.
    Expects match to include:
      match["match"], ["home"], ["away"], ["ticker"], ["date"]
      match["odds_feed"]["home_odds"/"away_odds"/"home_prob"/"away_prob"]
      match["kalshi"] (list of market dicts for both players)
    """
    if not WRITE_SNAPSHOTS:
        return

    global _last_snapshot_write_per_match, _snapshot_scan_counter

    def _spread(yb_raw, ya_raw):
        if yb_raw is None or ya_raw is None: return None
        return max(0.0, (ya_raw - yb_raw)/100.0)

    def _mid(yb, ya):
        if yb is None and ya is None: return None
        return (yb + ya)/2.0 if (yb is not None and ya is not None) else (yb or ya)

    def _prices(m):
        """
        Safely extract raw + normalized bid/ask/no prices from a Kalshi market.
        Always returns 5 values: (yb_raw, ya_raw, yb, ya, nb)
        so downstream unpacking never fails even if some values are missing.
        """
        if not m:
            return None, None, None, None, None

        try:
            yb_raw = m.get("yes_bid")
            ya_raw = m.get("yes_ask")

            # normalize to 0â€“1
            yb = format_price(yb_raw)
            ya = format_price(ya_raw)

            # compute complementary "no" side safely
            if ya is not None:
                nb = 1.0 - ya
            elif yb is not None:
                nb = 1.0 - yb
            else:
                nb = None

            return yb_raw, ya_raw, yb, ya, nb

        except Exception as e:
            print(f"âš ï¸ _prices() error: {e}")
            return None, None, None, None, None


    def _find_mkt_for(label: str, kalshi_markets: list):
        lab = normalize_name(label)
        for m in kalshi_markets or []:
            st = normalize_name(m.get("yes_sub_title",""))
            if lab in st or st in lab:
                return m
        return None

    def _fee_at(px):
        return kalshi_fee_per_contract(px) if px is not None else None

    match_id = match.get("match") or match.get("ticker") or "unknown"
    now = time.time()
    last_ts = _last_snapshot_write_per_match.get(match_id, 0.0)
    if (now - last_ts) < float(SNAPSHOT_MIN_INTERVAL_SECS):
        return
    _last_snapshot_write_per_match[match_id] = now
    _snapshot_scan_counter += 1
    if _snapshot_scan_counter % max(1, SNAPSHOT_EVERY_N_SCANS) != 0:
        return

    # pull comps
    home = match["home"]; away = match["away"]
    kalshi = match.get("kalshi") or []
    home_mkt = _find_mkt_for(home, kalshi)
    away_mkt = _find_mkt_for(away, kalshi)

    h_yb_raw, h_ya_raw, h_yb, h_ya, h_nb = _prices(home_mkt)
    a_yb_raw, a_ya_raw, a_yb, a_ya, a_nb = _prices(away_mkt)

    home_spread = _spread(h_yb_raw, h_ya_raw)
    away_spread = _spread(a_yb_raw, a_ya_raw)
    home_mid = _mid(h_yb, h_ya)
    away_mid = _mid(a_yb, a_ya)

    # EV relative to settlement (your ev_exit_yes)
    cons_h = fair_h = cons_a = fair_a = None
    odds_snapshot = match.get("odds_feed") or {}
    hp = odds_snapshot.get("home_prob")
    ap = odds_snapshot.get("away_prob")
    if hp is not None and home_mid is not None and h_yb is not None and h_ya is not None:
        cons_h, fair_h = ev_exit_yes(hp, home_mid, h_yb, h_ya)
    if ap is not None and away_mid is not None and a_yb is not None and a_ya is not None:
        cons_a, fair_a = ev_exit_yes(ap, away_mid, a_yb, a_ya)

    # event-level exposure summary
    evt = match.get("ticker", "")
    evt_key = event_key(evt)
    open_yes_home = sum(
        p["stake"]
        for p in positions
        if event_key(p.get("event_ticker")) == evt_key
        and p.get("market_ticker") == ((home_mkt or {}).get("ticker"))
        and p.get("side") == "yes"
    )
    open_yes_away = sum(
        p["stake"]
        for p in positions
        if event_key(p.get("event_ticker")) == evt_key
        and p.get("market_ticker") == ((away_mkt or {}).get("ticker"))
        and p.get("side") == "yes"
    )
    exposure_evt_usd = sum(
        p["stake"] * p["entry_price"]
        for p in positions
        if event_key(p.get("event_ticker")) == evt_key
    )
    neutralized_flag = event_is_neutralized(evt)

    row = {
        "ts": now_utc().isoformat(),
        "date_code": match.get("date",""),
        "match": match["match"],
        "home": home,
        "away": away,
        "home_odds": odds_snapshot.get("home_odds",""),
        "away_odds": odds_snapshot.get("away_odds",""),
        "home_prob": hp,
        "away_prob": ap,
        "ticker_found": True,
        "tickers_tried": "",  # not tracked here
        "ticker": evt,

        # old price columns (kept for continuity)
        "kalshi_home_yes_bid": h_yb,
        "kalshi_home_yes_ask": h_ya,
        "kalshi_home_no_bid":  h_nb,
        "kalshi_away_yes_bid": a_yb,
        "kalshi_away_yes_ask": a_ya,
        "kalshi_away_no_bid":  a_nb,

        # NEW microstructure
        "home_spread": home_spread,
        "away_spread": away_spread,
        "home_mid": home_mid,
        "away_mid": away_mid,
        "home_yes_bid_size": (home_mkt or {}).get("yes_bid_size",""),
        "home_yes_ask_size": (home_mkt or {}).get("yes_ask_size",""),
        "away_yes_bid_size": (away_mkt or {}).get("yes_bid_size",""),
        "away_yes_ask_size": (away_mkt or {}).get("yes_ask_size",""),

        # Fees at book edges
        "home_fee_at_bid": _fee_at(h_yb),
        "home_fee_at_ask": _fee_at(h_ya),
        "away_fee_at_bid": _fee_at(a_yb),
        "away_fee_at_ask": _fee_at(a_ya),

        # Model vs market
        "edge_home_abs": (hp - home_mid) if (hp is not None and home_mid is not None) else "",
        "edge_away_abs": (ap - away_mid) if (ap is not None and away_mid is not None) else "",
        "cons_ev_home": cons_h,
        "fair_ev_home": fair_h,
        "cons_ev_away": cons_a,
        "fair_ev_away": fair_a,

        # Identity / mapping
        "event_ticker": evt,
        "home_market_ticker": (home_mkt or {}).get("ticker",""),
        "away_market_ticker": (away_mkt or {}).get("ticker",""),

        # State
        "open_yes_home_qty": open_yes_home,
        "open_yes_away_qty": open_yes_away,
        "exposure_event_usd": exposure_evt_usd,
        "neutralized_flag": neutralized_flag,

        # Meta
        "log_score": match.get("log_score",""),
        "odds_ts": now_utc().isoformat(),
        "kalshi_fetch_ts": now_utc().isoformat(),
        "scan_seq": _snapshot_scan_counter,
    }

    # Column order (stable)
    fixed = [
        "ts","date_code","match","home","away",
        "home_odds","away_odds","home_prob","away_prob",
        "ticker_found","tickers_tried","ticker",

        "kalshi_home_yes_bid","kalshi_home_yes_ask","kalshi_home_no_bid",
        "kalshi_away_yes_bid","kalshi_away_yes_ask","kalshi_away_no_bid",

        "home_spread","away_spread","home_mid","away_mid",
        "home_yes_bid_size","home_yes_ask_size","away_yes_bid_size","away_yes_ask_size",
        "home_fee_at_bid","home_fee_at_ask","away_fee_at_bid","away_fee_at_ask",
        "edge_home_abs","edge_away_abs","cons_ev_home","fair_ev_home","cons_ev_away","fair_ev_away",

        "event_ticker","home_market_ticker","away_market_ticker",
        "open_yes_home_qty","open_yes_away_qty","exposure_event_usd","neutralized_flag",

        "odds_ts","kalshi_fetch_ts","scan_seq",
        "log_score",
    ]

    _append_csv(os.path.join(BASE_DIR, "market_snapshots_for_duke_basketball.csv"), row, fixed_fields=fixed)



def log_eval(row: dict):
    """
    Optional: one row per side evaluation in run_engine.
    Set WRITE_EVALS_TRADE_ONLY = True to persist only when decision âˆˆ {yes,no}.
    """
    if not WRITE_EVALS:
        return
    if WRITE_EVALS_TRADE_ONLY and row.get("decision") not in ("yes", "no"):
        return
    row = {"ts": now_utc().isoformat(), **row}
    fixed = [
        "ts","event_ticker","market_ticker","match","side_label",
        "odds_prob","yes_bid","yes_ask","kalshi_price",
        "edge","kelly_fraction","spread","cost_buffer","logit_gap",
        "decision"
    ]
    _append_csv("market_evals_basketball.csv", row, fixed_fields=fixed)


def log_backtest_feed(row: dict):
    """
    Persist a richer per-evaluation snapshot so we can replay decisions offline.
    Captures odds-feed context, Kalshi quotes, capital-scaled sizing rules,
    and whether the evaluation was in hedge or entry mode.
    """
    if not WRITE_BACKTEST_FEED:
        return
    fixed = [
        "ts","match","event_ticker","market_ticker","side_label",
        "books_used","books_weights","books_sampled",
        "home_prob","away_prob","odds_prob",
        "yes_bid","yes_ask","kalshi_mid","kalshi_price","spread",
        "edge_pct","fair_ev","cons_ev","rt_ev","kelly_fraction","volatility_mode",
        "capital","min_qty_required","planned_qty","has_event_position","is_hedge","decision",
        "cost_buffer"
    ]
    _append_csv("backtest_feed_basketball.csv", row, fixed_fields=fixed, add_timestamp=True)

def show_book():
    print(f"\nðŸ’µ CAPITAL: ${capital_sim:.2f}" if PLACE_LIVE_KALSHI_ORDERS != "YES" else "ðŸ’° LIVE MODE")
    if positions:
        # âœ… Filter out positions that are being closed
        open_positions = [p for p in positions if not p.get("settled", False) and not p.get("closing_in_progress", False)]
        if open_positions:
            print(f"ðŸ““ OPEN POSITIONS ({len(open_positions)}):")
            for pos in open_positions:
                print(f"â€¢ {pos['match']} {pos['side']} @ {pos['entry_price']:.2%}")
        print("-" * 50)
        # âœ… Count open positions (unsettled and not closing) + closed trades
        open_trades = len([p for p in positions if not p.get("settled", False) and not p.get("closing_in_progress", False)])
        closed_trades_count = wins + losses
        total = open_trades + closed_trades_count
        unreal, equity = _current_unrealized_and_equity()
        roi = _roi_pct_from_equity(equity)

        # âœ… Use portfolio value and cash directly from Kalshi (no internal math)
        if SESSION_START_PORTFOLIO_VALUE is not None and PLACE_LIVE_KALSHI_ORDERS == "YES":
            current_portfolio_value = get_kalshi_portfolio_value()
            current_cash = get_kalshi_balance()
            
            if current_portfolio_value is not None:
                session_pnl = current_portfolio_value - SESSION_START_PORTFOLIO_VALUE
                session_roi = 100.0 * (session_pnl / SESSION_START_PORTFOLIO_VALUE) if SESSION_START_PORTFOLIO_VALUE else 0.0
            else:
                # Fallback if portfolio value not available
                session_pnl = 0.0
                session_roi = 0.0
        elif SESSION_START_BAL is not None:
            if PLACE_LIVE_KALSHI_ORDERS == "YES":
                # Fallback: use cash + unrealized if portfolio value not available
                live_cash_now = get_kalshi_balance()
                session_pnl = (live_cash_now + unreal) - SESSION_START_BAL
            else:
                session_pnl = realized_pnl
            session_roi = 100.0 * (session_pnl / SESSION_START_BAL) if SESSION_START_BAL else 0.0
        else:
            session_pnl = 0.0
            session_roi = 0.0

        print(f"ðŸ“Š Trades: {total} | âœ… Wins: {wins} | âŒ Losses: {losses} "
            f"| ROI (unrealized): {roi:.2f}% | Realized: ${realized_pnl:.2f} | Unrealized: ${unreal:.2f}")
        session_time_str = SESSION_START_TIME.strftime('%Y-%m-%d %H:%M:%S') if SESSION_START_TIME else "N/A"
        print(f"ðŸ’¹ Session P&L: ${session_pnl:+.2f} | Session ROI: {session_roi:+.2f}% (since {session_time_str})")


def _ensure_log_header():
    if not os.path.exists(LOG_FILE) or os.path.getsize(LOG_FILE) == 0:
        with open(LOG_FILE, "w", newline="") as f:
            csv.DictWriter(f, fieldnames=LOG_FIELDS).writeheader()

def _write_log_row(row: dict):
    if not WRITE_BOT_LOG:
        return
    _ensure_log_header()
    with open(LOG_FILE, "a", newline="") as f:
        w = csv.DictWriter(f, fieldnames=LOG_FIELDS)
        for k in LOG_FIELDS:
            row.setdefault(k, "")
        w.writerow(row)


def _format_price_f(x):
    try:
        return round(float(x), 4)
    except:
        return ""

def _current_unrealized_and_equity():
    """
    Compute conservative MTM and equity.

    MTM (unrealized):
      - YES positions: assume you could exit by SELLING at yes_bid and pay exit fee.
      - If yes_bid missing, fall back to yes_ask (still conservative-ish).
      - If no quotes, skip MTM for that position.

    Equity:
      - LIVE mode   â†’ equity = live_cash + unreal
      - SIM  mode   â†’ equity = capital_sim + realized_pnl + unreal

    Returns:
      (unreal: float, equity: float)
    """
    unreal = 0.0

    for p in positions:
        try:
            mkts = get_kalshi_markets(p["event_ticker"], force_live=True)
            # Handle rate limiting (None) or empty markets
            if not mkts:  # None (rate limited) or [] (no markets)
                continue
            m = next((m for m in mkts if m.get("ticker") == p.get("market_ticker")), None)
            if not m:
                continue

            yes_bid = format_price(m.get("yes_bid"))
            yes_ask = format_price(m.get("yes_ask"))

            if (p.get("side") or "").lower() == "yes":
                entry = float(p.get("effective_entry", p.get("entry_price", 0.0)))
                # Use bid to mark a sellable exit; fallback to ask if bid missing
                exit_price = yes_bid if yes_bid is not None else yes_ask
                if exit_price is None:
                    continue  # no quote available â†’ skip this position

                # Conservative: include exit fee as if you sold now
                # Selling at bid is typically a maker order (resting above bid)
                exit_fee = kalshi_fee_per_contract(exit_price, is_maker=True)
                mtm_per_ct = (exit_price - entry) - exit_fee
                unreal += float(p.get("stake", 0)) * mtm_per_ct

            # NOTE: If NO positions are ever supported, add analogous MTM here.

        except Exception:
            # swallow and continue to avoid breaking equity on a single bad read
            continue

    if PLACE_LIVE_KALSHI_ORDERS == "YES":
        # Live cash already reflects realized PnL; add MTM to get equity
        live_cash = get_kalshi_balance()
        equity = live_cash + unreal
    else:
        # In sim, start from sim capital and add realized + unrealized
        equity = capital_sim + realized_pnl + unreal

    return unreal, equity

# === POSITION TRACKING HEALTH ===
def refresh_position_tracking(active_matches):
    """
    Mark open positions as 'settled/untracked' if their Kalshi market
    is no longer active in the current match list.
    """
    global positions
    if PRESERVE_MANUAL_POSITIONS:
        if VERBOSE:
            print("ðŸ›¡ï¸ Manual positions enabled â€” refresh_position_tracking() skipped.")
        return

    tracked_event_keys = {
        event_key(m.get("ticker"))
        for m in active_matches
        if m.get("ticker")
    }

    tracked_market_tickers = set()
    for match in active_matches:
        for market in match.get("kalshi") or []:
            ticker = market.get("ticker")
            if ticker:
                tracked_market_tickers.add(ticker.upper())

    changed = False

    for p in positions:
        market_tkr = (p.get("market_ticker") or "").upper()
        event_tkr_key = event_key(p.get("event_ticker"))

        market_active = market_tkr and market_tkr in tracked_market_tickers
        event_active = event_tkr_key and event_tkr_key in tracked_event_keys

        if market_active or event_active:
            continue

        if not p.get("settled", False):
            print(f"âš ï¸ Market for {p['market_ticker']} no longer active â€” marking as settled/untracked")
            p["settled"] = True
            p["tracking_status"] = "lost"
            changed = True

    if changed:
        save_positions()

def purge_stale_positions(hours: int = 4, active_matches: list = None):
    global positions
    active_matches = active_matches or []

    cutoff = now_utc() - timedelta(hours=hours)
    before = len(positions)
    kept = []

    for p in positions:
        try:
            entry_ts = parse_iso_utc(p.get("entry_time")) if p.get("entry_time") else None
            last_seen = parse_iso_utc(p.get("last_seen_live")) if p.get("last_seen_live") else None

            # Always let settled positions be handled by purge_old_positions()
            if p.get("settled"):
                kept.append(p)
                continue

            # ðŸ”Ž Ask Kalshi directly if this specific market still has quotes
            mkts = get_kalshi_markets(p.get("event_ticker", ""), force_live=True) or []
            live_m = next((m for m in mkts
                           if m.get("ticker") == p.get("market_ticker")
                           and m.get("status") == "active"
                           and (m.get("yes_bid") or m.get("yes_ask"))), None)

            # If Kalshi shows it live, keep (regardless of active_matches)
            if live_m:
                kept.append(p)
                continue

            # Otherwise, treat as stale if never seen live or seen > hours ago
            ref_ts = last_seen or entry_ts
            if ref_ts and ref_ts < cutoff:
                print(f"ðŸ§¹ Purging stale (>{hours}h unseen on Kalshi): "
                      f"{p.get('match')} {p.get('side')} @ {p.get('entry_price'):.2%}")
                continue

            # No timestamps â†’ conservative keep (or flip to purge if you prefer)
            kept.append(p)

        except Exception as e:
            print(f"âš ï¸ purge_stale_positions error on {p.get('market_ticker')}: {e}")
            kept.append(p)

    if len(kept) != before:
        print(f"ðŸ§¹ Removed {before - len(kept)} stale positions (> {hours}h).")
    positions = kept
    save_positions()


def purge_old_positions(hours: int = 24):
    """
    Optionally remove 'settled' positions older than N hours.
    """
    global positions
    cutoff = now_utc() - timedelta(hours=hours)
    before = len(positions)
    positions = [
        p for p in positions
        if not p.get("settled") or parse_iso_utc(p["entry_time"]) > cutoff
    ]
    if len(positions) != before:
        print(f"ðŸ§¹ Purged {before - len(positions)} old settled positions.")
        save_positions()


def purge_stale_live_positions(hours: int = 12):
    """Drop any live (unsettled) positions whose entry time is older than N hours."""
    global positions
    cutoff = now_utc() - timedelta(hours=hours)
    kept = []
    removed = 0
    for pos in positions:
        if pos.get("settled"):
            kept.append(pos)
            continue
        entry_ts = pos.get("entry_time")
        if not entry_ts:
            kept.append(pos)
            continue
        try:
            entry_dt = parse_iso_utc(entry_ts)
        except Exception:
            kept.append(pos)
            continue
        if entry_dt < cutoff:
            removed += 1
            print(
                f"ðŸ§¹ Removing stale live position (> {hours}h): "
                f"{pos.get('match')} {pos.get('side')} @ {pos.get('entry_price'):.2%}"
            )
            continue
        kept.append(pos)
    if removed:
        positions = kept
        save_positions()


def _roi_pct_from_equity(equity: float) -> float:
    denom = max(1e-9, float(INITIAL_CAPITAL))
    return 100.0 * (equity - INITIAL_CAPITAL) / denom

def log_entry_row(position: dict, ticker: str):
    unreal, equity = _current_unrealized_and_equity()
    roi = _roi_pct_from_equity(equity)
    _write_log_row({
        "ts": now_utc().isoformat(),
        "event": "entry",
        "match": position.get("match", ""),
        "ticker": ticker,
        "side": position.get("side", ""),
        "market_ticker": position.get("market_ticker", ""),
        "yes_bid": "",
        "yes_ask": "",
        "odds_feed_home_prob": "",
        "odds_feed_away_prob": "",
        "entry_price": _format_price_f(position.get("entry_price")),
        "exit_price": "",
        "qty": int(position.get("stake", 0)),
        "pnl": "",
        "realized_pnl": round(realized_pnl, 4),
        "unrealized_pnl": round(unreal, 4),
        "equity": round(equity, 4),
        "roi_pct": round(roi, 4),
        "note": ""
    })

def log_exit_row(position: dict, exit_price: float, pnl_cash: float, settled: bool = False):
    unreal, equity = _current_unrealized_and_equity()
    roi = _roi_pct_from_equity(equity)
    # For exit fees: selling at bid is typically maker (conservative - lower fee)
    # For entry fee: we don't have historical yes_ask, default to taker (conservative - higher fee)
    exit_fee = 0.0 if settled else kalshi_fee_per_contract(exit_price, is_maker=True)
    entry_fee = kalshi_fee_per_contract(position.get("entry_price"), is_maker=False)
    total_fees = entry_fee + (0.0 if settled else exit_fee)
    _write_log_row({
        "ts": now_utc().isoformat(),
        "event": "exit",
        "match": position.get("match", ""),
        "ticker": position.get("event_ticker", ""),
        "side": position.get("side", ""),
        "market_ticker": position.get("market_ticker", ""),
        "yes_bid": "",
        "yes_ask": "",
        "odds_feed_home_prob": "",
        "odds_feed_away_prob": "",
        "entry_price": _format_price_f(position.get("entry_price")),
        "exit_price": _format_price_f(exit_price),
        "qty": int(position.get("stake", 0)),
        "pnl": round(float(pnl_cash), 4),
        "realized_pnl": round(realized_pnl, 4),
        "unrealized_pnl": round(unreal, 4),
        "equity": round(equity, 4),
        "roi_pct": round(roi, 4),
        "note": "",
        "exit_fee": round(exit_fee, 4),
        "total_fees": round(total_fees, 4),
    })

# Status map for event status codes
STATUS_MAP = {
    "0": "Not started",
    "1": "Live",
    "2": "Finished",
    "3": "Postponed",
    "4": "Cancelled",
    "5": "Walkover",
    "6": "Interrupted",
    "7": "Abandoned",
    "8": "Retired",
}

def _format_status(event: Dict[str, Any]) -> str:
    """Format event status with quarter/time information."""
    code = str(event.get("time_status", ""))
    base = STATUS_MAP.get(code, f"status={code}" if code else "Unknown")
    timer = event.get("timer") or {}
    quarter = timer.get("q")
    minutes = timer.get("tm")
    seconds = timer.get("ts")
    if quarter:
        clock = ""
        if minutes not in (None, "") and seconds not in (None, ""):
            sec_str = str(seconds).zfill(2) if isinstance(seconds, (int, float)) else str(seconds).zfill(2)
            clock = f" {minutes}:{sec_str}"
        base = f"{base} | Q{quarter}{clock}"
    return base

def _format_score(event: Dict[str, Any], score_snapshot: Optional[str] = None) -> str:
    """Format score from event or score_snapshot."""
    if score_snapshot:
        return str(score_snapshot)
    if event.get("ss"):
        return str(event["ss"])
    scores = event.get("scores") or {}
    total = scores.get("7") or {}
    home = total.get("home")
    away = total.get("away")
    if home is None or away is None:
        return "0-0"
    return f"{away}-{home}"

def smart_team_lookup(team_name: str, team_map: dict) -> tuple:
    """
    Intelligently match team name to team_map, handling mascot names.
    Returns (team_code, confidence_level, matched_key)
    confidence_level: 'exact', 'without_mascot', 'prefix_match', 'fallback'
    """
    if not team_name:
        return None, 'fallback', None
    
    # Common college basketball mascots to strip
    MASCOTS = [
        'tigers', 'bulldogs', 'wildcats', 'eagles', 'bears', 'panthers',
        'lions', 'hawks', 'falcons', 'cougars', 'huskies', 'terriers',
        'cardinals', 'blue devils', 'tar heels', 'spartans', 'trojans',
        'aggies', 'longhorns', 'wolverines', 'buckeyes', 'crimson tide',
        'razorbacks', 'gators', 'seminoles', 'hurricanes', 'gamecocks',
        'orange', 'hoyas', 'jayhawks', 'sooners', 'cornhuskers',
        'volunteers', 'crimson', 'golden bears', 'bruins', 'sun devils',
        'rebels', 'commodores', 'vols', 'knights',
        'mean green', 'golden eagles', 'red raiders', 'mustangs',
        'rams', 'golden gophers', 'badgers', 'fighting irish',
        'mountaineers', 'cyclones', 'horned frogs', 'black bears',
        'great danes', 'seahawks', 'seawolves', 'pirates', 'raiders',
        'owls', 'bison', 'broncos', 'redhawks', 'retrievers', 'colonials',
        'peacocks', 'gaels', 'stags', 'zags', 'friars', 'explorers',
        'minutemen', 'patriots', 'river hawks', 'pride',
        'jaspers', 'terrapins', 'blue jays', 'purple eagles',
        'bombers', 'ambassadors', 'crusaders', 'flying dutchmen',
        'green wave', 'maroons', 'mocs', 'monarchs', 'hatters',
        'billikens', 'aces', '49ers', 'rattlers', 'aztecs',
        'bearcats', 'beavers', 'boilermakers', 'buffalo', 'chippewas',
        'cobbers', 'ducks', 'fighting camels', 'golden flashes',
        'grizzlies', 'hilltoppers', 'hokies', 'horned frogs',
        'jaguars', 'lumberjacks', 'midshipmen', 'minutewomen',
        'musketeers', 'nittany lions', 'penguins', 'phoenix',
        'quakers', 'ramblers', 'rebels', 'redbirds', 'running rebels',
        'salukis', 'scarlet knights', 'shockers', 'sooners',
        'tar heels', 'thundering herd', 'utes', 'vandals',
        'volunteers', 'wolfpack', 'yellow jackets'
    ]
    
    # Normalize the team name
    normalized = team_name.lower().strip()
    # Remove (W), (M), state codes, etc.
    normalized = re.sub(r"\s*\([WMwm]\)\s*", " ", normalized)
    normalized = re.sub(r"\s*\([A-Z]{2}\)\s*", " ", normalized, flags=re.IGNORECASE)
    normalized = normalized.replace("&", " and ")
    normalized = normalized.replace("-", " ")
    normalized = re.sub(r"[()]", " ", normalized)
    normalized = re.sub(r"\bst\.\b", "st", normalized)
    normalized = re.sub(r"\bsaint\b", "st", normalized)
    normalized = normalized.replace("'", "")
    normalized = re.sub(r"[^a-z\s]", " ", normalized)
    normalized = re.sub(r"\s+", " ", normalized).strip()
    
    # Try 1: Exact match
    if normalized in team_map:
        return team_map[normalized], 'exact', normalized
    
    # Try 2: Remove mascot suffix and try again
    words = normalized.split()
    if len(words) > 1:
        # Try removing last word if it's a mascot
        if words[-1] in MASCOTS:
            without_mascot = " ".join(words[:-1])
            if without_mascot in team_map:
                return team_map[without_mascot], 'without_mascot', without_mascot
        
        # Try removing last 2 words if they form a two-word mascot
        if len(words) > 2:
            last_two = f"{words[-2]} {words[-1]}"
            if last_two in MASCOTS:
                without_mascot = " ".join(words[:-2])
                if without_mascot in team_map:
                    return team_map[without_mascot], 'without_mascot', without_mascot
    
    # Try 3: Check if any team_map key is a prefix of the normalized name
    # This handles cases like "duke" matching "duke blue devils"
    for key in team_map:
        # Use word boundary check to avoid false matches
        if len(key) >= 3:  # Only match keys with 3+ chars for safety
            if re.match(rf"\b{re.escape(key)}\b", normalized):
                return team_map[key], 'prefix_match', key
    
    # Fallback: None (let caller handle it)
    return None, 'fallback', None


def make_ncaa_event_ticker(home_team: str, away_team: str, event_date) -> List[str]:
    """
    Build Kalshi NCAA Basketball event ticker from home/away team names and date.
    Returns men's or women's ticker format based on whether team names contain "(W)".
    Uses smart team matching to handle mascot names (e.g., "Princeton Tigers" â†’ "PRIN").
    Works if event_date is a datetime or a preformatted string like '25NOV11'.
    Examples: 
    - Men's: 'KXNCAAMBGAME-25NOV11MSSTISU'
    - Women's: 'KXNCAAWBGAME-25NOV11MSSTISU'
    """

    # âœ… Handle both datetime and string inputs
    if hasattr(event_date, "strftime"):
        date_code = event_date.strftime("%y%b%d").upper()
    else:
        date_code = str(event_date).upper()

    # Use smart lookup to match teams, handling mascot names
    home_code, home_confidence, home_key = smart_team_lookup(home_team, team_map)
    away_code, away_confidence, away_key = smart_team_lookup(away_team, team_map)
    
    # Fallback to first 4 chars if no match found
    if not home_code:
        home_clean = re.sub(r"\s*\([WMwm]\)\s*", "", str(home_team)).strip()
        home_code = home_clean[:4].upper() if home_clean else home_team[:4].upper()
        home_confidence = 'fallback'
    
    if not away_code:
        away_clean = re.sub(r"\s*\([WMwm]\)\s*", "", str(away_team)).strip()
        away_code = away_clean[:4].upper() if away_clean else away_team[:4].upper()
        away_confidence = 'fallback'
    
    # Log confidence levels for debugging (only if not exact match)
    if VERBOSE and (home_confidence != 'exact' or away_confidence != 'exact'):
        print(f"   ðŸ” Team matching: {home_team} â†’ {home_code} ({home_confidence}), "
              f"{away_team} â†’ {away_code} ({away_confidence})")

    # Check if this is a women's game (either team has "(W)" in the name)
    is_womens = "(W)" in str(home_team) or "(W)" in str(away_team)
    
    if is_womens:
        # Women's game - only return women's ticker
        ticker_womens = f"KXNCAAWBGAME-{date_code}{away_code}{home_code}"
        return [ticker_womens]
    else:
        # Men's game - only return men's ticker
        ticker_mens = f"KXNCAAMBGAME-{date_code}{away_code}{home_code}"
        return [ticker_mens]

def normalize_tokens(s: str):
    """
    Normalize a team name string into comparable token(s).
    Converts known team names to canonical abbreviations (from team_map)
    and strips punctuation/nonletters for fuzzy matching.
    
    Handles all variations in team_map.py:
    - "&" -> "and" (e.g., "florida a&m" -> "florida a and m")
    - "st." -> "st" (e.g., "st. mary's" -> "st marys")
    - "saint" -> "st" (e.g., "saint louis" -> "st louis")
    - Hyphens -> spaces (e.g., "tennessee-martin" -> "tennessee martin")
    - Parentheses removed (e.g., "miami (oh)" -> "miami oh")
    - Apostrophes removed (e.g., "mary's" -> "marys")
    """
    if not s:
        return set()
    
    s = s.lower().strip()
    
    # Step 1: Handle common variations before removing punctuation
    # Strip state abbreviations in parentheses like "(MN)", "(OH)", etc. before general parenthesis removal
    s = re.sub(r"\s*\([A-Z]{2}\)\s*", " ", s, flags=re.IGNORECASE)
    # Convert "&" to "and" (handles "florida a&m", "william & mary", etc.)
    s = s.replace("&", " and ")
    # Convert hyphens to spaces (handles "tennessee-martin", "bethune-cookman", etc.)
    s = s.replace("-", " ")
    # Remove parentheses but keep their contents (e.g., "miami (oh)" -> "miami oh")
    s = re.sub(r"[()]", " ", s)
    # Normalize "st." -> "st" (handles "st. mary's", "st. john's", etc.)
    s = re.sub(r"\bst\.\b", "st", s)
    # Normalize "saint" -> "st" (handles "saint louis", "saint mary's", etc.)
    s = re.sub(r"\bsaint\b", "st", s)
    
    # Step 2: Remove all remaining non-alphabetic characters (including apostrophes)
    # This handles "mary's" -> "marys", "john's" -> "johns", etc.
    s = re.sub(r"[^a-z\s]", " ", s)
    # Normalize whitespace
    s = re.sub(r"\s+", " ", s).strip()
    
    # Step 3: Replace matching team names from team_map (longest first)
    # Create a working copy for replacements
    s_normalized = s
    
    # Sort by length descending to match longer names first
    # (e.g., "north carolina state" before "north carolina")
    for full_name in sorted(team_map.keys(), key=len, reverse=True):
        # Normalize the team_map key the same way we normalized the input
        normalized_key = full_name.lower().strip()
        normalized_key = normalized_key.replace("&", " and ")
        normalized_key = normalized_key.replace("-", " ")
        normalized_key = re.sub(r"[()]", " ", normalized_key)
        normalized_key = re.sub(r"\bst\.\b", "st", normalized_key)
        normalized_key = re.sub(r"\bsaint\b", "st", normalized_key)
        normalized_key = re.sub(r"[^a-z\s]", " ", normalized_key)
        normalized_key = re.sub(r"\s+", " ", normalized_key).strip()
        
        if not normalized_key:
            continue
        
        # Check if normalized key matches as a word or phrase
        # Use word boundaries to avoid partial matches
        pattern = r"\b" + re.escape(normalized_key) + r"\b"
        if re.search(pattern, s_normalized):
            # Replace the matching portion with the abbreviation
            s_normalized = re.sub(pattern, team_map[full_name].lower(), s_normalized)
    
    # Step 4: Final whitespace normalization and return as set of tokens
    s_normalized = re.sub(r"\s+", " ", s_normalized).strip()
    return set(s_normalized.split()) if s_normalized else set()


def get_overlapping_matches(preloaded_events: Optional[List[Dict[str, Any]]] = None):
    """
    Fetches live odds-feed basketball matches (NBA/NCAA),
    calculates implied probabilities,
    and attempts to match them to Kalshi tickers (KXNBAGAME-... or KXNCAAMBGAME-...).
    """
    overlaps = []

    # === Helper: extract and normalize Kalshi market prices ===
    def _kalshi_side_prices(markets, home_name, away_name):
        """
        Match odds-feed team names to Kalshi yes_sub_titles and return both sidesâ€™ prices.
        Returns (home_yb, home_ya, home_nb, away_yb, away_ya, away_nb)
        """
        
        home_tokens = normalize_tokens(home_name)
        away_tokens = normalize_tokens(away_name)
        home_mkt, away_mkt = None, None

        for m in markets or []:
            ysub_raw = (m.get("yes_sub_title") or "")
            ytokens = normalize_tokens(ysub_raw)
            if home_tokens & ytokens:
                home_mkt = m
                print(f"âœ… Matched HOME '{home_name}' â†” '{ysub_raw}' ({ytokens})")
            elif away_tokens & ytokens:
                away_mkt = m
                print(f"âœ… Matched AWAY '{away_name}' â†” '{ysub_raw}' ({ytokens})")

        if not home_mkt or not away_mkt:
            print(f"âš ï¸ Kalshi side match failed for {home_name} vs {away_name}")
            # add detailed normalization view
            print(f"   home_tokens={list(home_tokens)}, away_tokens={list(away_tokens)}")
            print(f"   Kalshi titles normalized: {[list(normalize_tokens(m.get('yes_sub_title'))) for m in (markets or [])]}")


        def _extract_prices(m):
            if not m:
                return None, None, None
            uh = (m or {}).get("response_price_units", "usd_cent")
            yb = format_price(m.get("yes_bid"), units_hint=uh)
            ya = format_price(m.get("yes_ask"), units_hint=uh)
            nb = (1.0 - ya) if ya is not None else ((1.0 - yb) if yb is not None else None)
            return yb, ya, nb

        h_yb, h_ya, h_nb = _extract_prices(home_mkt)
        a_yb, a_ya, a_nb = _extract_prices(away_mkt)
        return h_yb, h_ya, h_nb, a_yb, a_ya, a_nb


    _load_odds_snapshot()

    def _format_books_list(names: List[str]) -> str:
        if not names:
            return ""
        if len(names) == 1:
            return names[0]
        if len(names) == 2:
            return f"{names[0]} and {names[1]}"
        return f"{', '.join(names[:-1])}, and {names[-1]}"

    # === 1. Fetch live BetsAPI events (NCAA only) ===
    if preloaded_events is not None:
        events = preloaded_events
    else:
        events = _fetch_odds_feed_live_events()
    print("\nðŸ€ Live NCAA Basketball Matches â€“ With Moneyline Odds\n")

    if not events:
        print("âš ï¸ No live basketball matches found.")
        return overlaps

    # Filter for NCAA events
    print(f"\n   Filtering for NCAA events...", end="", flush=True)
    ncaa_events = [e for e in events if _is_ncaa_event(e)]
    print(f" âœ“ ({len(ncaa_events)} NCAA events)")
    
    # Include both men's and women's NCAA basketball games
    print(f"   Including all NCAA basketball games (men's and women's)...", end="", flush=True)
    print(f" âœ“ ({len(ncaa_events)} NCAA events)")
    
    if not ncaa_events:
        return overlaps

    # Try to match each NCAA event to Kalshi tickers
    print(f"\n   ðŸ§  Matching NCAA events to Kalshi tickers:", flush=True)
    # First pass: match tickers for all events
    ticker_matches = {}  # event_id -> ticker
    for e in ncaa_events:
        home_obj = e.get("home")
        away_obj = e.get("away")
        if isinstance(home_obj, dict):
            home = home_obj.get("name") or home_obj.get("short_name") or home_obj.get("display_name")
        else:
            home = home_obj or (e.get("team_home") or {}).get("name") if isinstance(e.get("team_home"), dict) else None
        if isinstance(away_obj, dict):
            away = away_obj.get("name") or away_obj.get("short_name") or away_obj.get("display_name")
        else:
            away = away_obj or (e.get("team_away") or {}).get("name") if isinstance(e.get("team_away"), dict) else None
        if not home or not away:
            # Debug: show why we're skipping
            print(f"      âš ï¸ Skipping event (missing team names): home={home}, away={away}", flush=True)
            continue
        
        # Get event time for ticker generation
        start_time = e.get("time") or e.get("starts") or e.get("start_at") or e.get("starts_at")
        try:
            if isinstance(start_time, (int, float)):
                dt_utc = datetime.fromtimestamp(start_time, tz=UTC)
            elif start_time:
                # Try to parse as ISO, but fallback to current time if it fails
                try:
                    dt_utc = parser.isoparse(str(start_time))
                except (ValueError, TypeError):
                    # If ISO parsing fails, use current time as fallback (same as current_odds_from_bet_365.py)
                    dt_utc = datetime.now(UTC)
            else:
                # No time provided, use current time as fallback
                dt_utc = datetime.now(UTC)
        except Exception as exc:
            # Final fallback: use current time
            dt_utc = datetime.now(UTC)
        
        match_date = dt_utc
        date_prior = match_date - timedelta(days=1)
        
        # Build ticker candidates
        ticker_candidates = []
        for tag, h, a, ts in [
            ("today", home, away, match_date),
            ("today", away, home, match_date),
            ("yesterday", home, away, date_prior),
            ("yesterday", away, home, date_prior),
        ]:
            for ticker_option in make_ncaa_event_ticker(h, a, ts):
                ticker_candidates.append((ticker_option, tag))
        
        print(f"      {away} vs {home}:", flush=True)
        ticker = None
        if not ticker_candidates:
            print(f"         âš ï¸ No ticker candidates generated", flush=True)
        else:
            print(f"         ðŸ” Trying {len(ticker_candidates)} ticker candidate(s):", flush=True)
            for ticker_try, tag in ticker_candidates:
                print(f"            - {ticker_try} ({tag})", flush=True)
        for ticker_try, tag in ticker_candidates:
            # Add delay between API calls to respect rate limits
            time.sleep(0.15)  # 150ms delay between ticker attempts
            
            markets = get_kalshi_markets(ticker_try, force_live=True)
            
            # Handle rate limiting with exponential backoff
            if markets is None:  # None indicates 429 rate limit error
                print(f"         âš ï¸ Rate limited, waiting 2 seconds before retry...", flush=True)
                time.sleep(2.0)  # Wait 2 seconds when rate limited
                # Try one more time after backoff
                markets = get_kalshi_markets(ticker_try, force_live=True)
                if markets is None:
                    print(f"         âš ï¸ Still rate limited, skipping remaining tickers for this game", flush=True)
                    break  # Stop trying this game's tickers
            
            if markets:
                print(f"         âœ… Found {len(markets)} markets for {ticker_try}", flush=True)
                ticker = ticker_try
                break
        
        if ticker:
            # Store ticker with event ID as key (ensure it's the same type as lookup)
            evt_id_key = e.get("id")
            ticker_matches[evt_id_key] = ticker
        else:
            print(f"         âš ï¸ No Kalshi markets found for any ticker", flush=True)
    
    print(f"\n   Fetching odds and building board...", flush=True)
    # === 2. Process each event ===
    seen_matchups = set()
    events_with_odds = 0
    for e in ncaa_events:
        tournament = e.get("tournament") or {}
        league = (
            e.get("league_name")
            or (e.get("league") or {}).get("name")
            or tournament.get("name")
            or ""
        ).strip()
        # Handle BetsAPI format: home/away is a dict with "name" key
        home_obj = e.get("home")
        away_obj = e.get("away")
        if isinstance(home_obj, dict):
            home = home_obj.get("name") or home_obj.get("short_name") or home_obj.get("display_name")
        else:
            home = home_obj or (e.get("team_home") or {}).get("name") if isinstance(e.get("team_home"), dict) else None
        
        if isinstance(away_obj, dict):
            away = away_obj.get("name") or away_obj.get("short_name") or away_obj.get("display_name")
        else:
            away = away_obj or (e.get("team_away") or {}).get("name") if isinstance(e.get("team_away"), dict) else None

        if not home or not away:
            print(f"         âš ï¸ Skipping event: missing team names (home={home}, away={away})")
            continue

        matchup_key = (home.strip().lower(), away.strip().lower())
        if matchup_key in seen_matchups:
            # Upstream feed sometimes returns duplicate entries with stale odds; keep only the latest
            print(f"         âš ï¸ Skipping duplicate: {away} vs {home}")
            continue
        seen_matchups.add(matchup_key)

        # === 3. Parse start time (UTC) ===
        # BetsAPI returns Unix timestamp - use same logic as current_odds_from_bet_365.py
        start_time = e.get("time") or e.get("starts") or e.get("start_at") or e.get("starts_at")
        if isinstance(start_time, (int, float)):
            dt_utc = datetime.fromtimestamp(start_time, tz=UTC)
        else:
            # If not a number, use current time as fallback (same as current_odds_from_bet_365.py)
            dt_utc = datetime.now(UTC)
        match_date = dt_utc
        date_code = dt_utc.strftime("%d%b%y").upper()

        # === 4. Fetch odds from BetsAPI (same method as current_odds_from_bet_365.py) ===
        # Always fetches fresh odds - no caching
        evt_id = str(e.get("id"))
        if not evt_id:
            print(f"         âš ï¸ Skipping {away} vs {home}: No event ID")
            continue
        
        try:
            # Always fetch fresh odds from API (cache-busting handled in fetch_event_moneyline)
            moneyline = fetch_event_moneyline(evt_id)
            if not moneyline:
                # Debug output for missing odds
                print(f"         âš ï¸ No odds available from BetsAPI for: {away} vs {home}")
                continue
        except RuntimeError as exc:
            # Skip events without odds
            print(f"         âš ï¸ Error fetching odds for {away} vs {home}: {exc}")
            continue
        except Exception as exc:
            # Skip any other errors
            print(f"         âš ï¸ Unexpected error for {away} vs {home}: {exc}")
            continue
        
        home_dec = float(moneyline["home_odds"])
        away_dec = float(moneyline["away_odds"])

        # Convert decimal odds â†’ implied probabilities
        implied_home = 1.0 / home_dec
        implied_away = 1.0 / away_dec

        # Proportional devig (simple)
        fair_prop_home, fair_prop_away = devig_proportional([implied_home, implied_away])

        # Shin devig (advanced) - use same method as v7
        fair_shin_home, fair_shin_away = devig_shin_two_way(home_dec, away_dec)

        # Use Shin devig by default (same as v7)
        if USE_SHIN_DEVIG:
            home_prob = fair_shin_home
            away_prob = fair_shin_away
        else:
            home_prob = fair_prop_home
            away_prob = fair_prop_away

        # Store odds as floats
        home_odds = home_dec
        away_odds = away_dec
        
        # Create odds_snapshot for compatibility
        odds_snapshot = {
            "home_prob": home_prob,
            "away_prob": away_prob,
            "home_odds": home_odds,
            "away_odds": away_odds,
            "score_snapshot": moneyline.get("score_snapshot"),
            "period_clock": moneyline.get("period_clock"),
            "last_update_ts": time.time(),
            "last_update_iso": datetime.utcnow().isoformat() + "Z",
        }
        
        # Small delay to avoid rate limiting
        time.sleep(EVENT_ODDS_SLEEP)

        # === 6. Use pre-matched ticker or build Kalshi tickers ===
        evt_id_for_lookup = e.get("id")
        ticker = ticker_matches.get(evt_id_for_lookup) if evt_id_for_lookup else None
        kalshi_markets = None
        
        if ticker:
            # Use pre-matched ticker
            kalshi_markets = get_kalshi_markets(ticker, force_live=True)
            # Handle rate limiting
            if kalshi_markets is None:
                print(f"      âš ï¸ {away} vs {home}: Rate limited while fetching ticker {ticker}")
                time.sleep(2.0)  # Back off when rate limited
                kalshi_markets = get_kalshi_markets(ticker, force_live=True) or []
            elif not kalshi_markets:
                print(f"      âš ï¸ {away} vs {home}: Ticker {ticker} found but no markets returned")
        else:
            # Fallback: try to match ticker (shouldn't happen if first pass worked)
            match_date = dt_utc
            date_prior = match_date - timedelta(days=1)

            ticker_candidates = []
            for tag, h, a, ts in [
                ("today", home, away, match_date),
                ("today", away, home, match_date),
                ("yesterday", home, away, date_prior),
                ("yesterday", away, home, date_prior),
            ]:
                for ticker_option in make_ncaa_event_ticker(h, a, ts):
                    ticker_candidates.append((ticker_option, tag))

            for ticker_try, tag in ticker_candidates:
                # Add delay between API calls to respect rate limits
                time.sleep(0.15)  # 150ms delay between ticker attempts
                
                markets = get_kalshi_markets(ticker_try, force_live=True)
                
                # Handle rate limiting with exponential backoff
                if markets is None:  # None indicates 429 rate limit error
                    print(f"         âš ï¸ Rate limited, waiting 2 seconds before retry...", flush=True)
                    time.sleep(2.0)  # Wait 2 seconds when rate limited
                    # Try one more time after backoff
                    markets = get_kalshi_markets(ticker_try, force_live=True)
                    if markets is None:
                        print(f"         âš ï¸ Still rate limited, skipping remaining tickers for this game", flush=True)
                        break  # Stop trying this game's tickers
                
                if markets:
                    ticker = ticker_try
                    kalshi_markets = markets
                    break

        # === 8. Print match summary (only if we have odds) ===
        # Note: We process events with odds even if they don't have Kalshi markets
        # But we only add to overlaps if they have both odds and Kalshi markets
        if not home_odds or not away_odds or home_prob is None or away_prob is None:
            # Skip if no odds
            print(f"         âš ï¸ Skipping {away} vs {home}: Invalid odds (home_odds={home_odds}, away_odds={away_odds}, home_prob={home_prob}, away_prob={away_prob})")
            continue

        events_with_odds += 1

        # === 9. Extract Kalshi prices ===
        # Only extract Kalshi prices if we have markets
        if kalshi_markets:
            kh_yb, kh_ya, kh_nb, ka_yb, ka_ya, ka_nb = _kalshi_side_prices(kalshi_markets, home, away)
        else:
            kh_yb, kh_ya, kh_nb, ka_yb, ka_ya, ka_nb = None, None, None, None, None, None

        odds_ts = odds_snapshot.get("last_update_ts") or time.time()
        odds_ts_iso = odds_snapshot.get("last_update_iso") or datetime.fromtimestamp(odds_ts).isoformat()

        # === 10. Save overlap if valid ===
        # Add to overlaps if we have both odds and Kalshi markets (even if bid/ask not visible yet)
        if kalshi_markets and home_odds and away_odds and home_prob is not None and away_prob is not None:
            # Format status and score for overlapping matches only
            status_str = _format_status(e)
            score_str = _format_score(e, moneyline.get("score_snapshot"))
            period_clock = moneyline.get("period_clock")
            
            # Print detailed match summary only for overlapping matches
            print(f"ðŸ“… {match_date.strftime('%b %d')} | {away} vs {home} | League: {league.upper()} | Status: {status_str}", end="")
            if score_str and score_str != "0-0":
                print(f" | Score: {score_str}", end="")
            print()
            
            if period_clock:
                print(f"   Clock: {period_clock}", end="")
            if moneyline.get("score_snapshot"):
                print(f" | Score snapshot: {moneyline.get('score_snapshot')}", end="")
            if period_clock or moneyline.get("score_snapshot"):
                print()
            
            print(f"  â€“ {home}: {home_odds:.3f} âž” {home_prob:.2%}")
            print(f"  â€“ {away}: {away_odds:.3f} âž” {away_prob:.2%}")
            print(f"  â†’ Kalshi Ticker Matched: {ticker}")
            print("â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”")
            
            # Check if we have bid/ask prices
            has_prices = any(x is not None for x in [kh_yb, kh_ya, kh_nb, ka_yb, ka_ya, ka_nb])
            if not has_prices:
                print(f"      âš ï¸ {away} vs {home}: Has Kalshi markets but no bid/ask prices yet")
            print(f"      âœ… Adding to overlaps: {away} vs {home}")
            overlaps.append({
                "id": e.get("id"),
                "match": f"{home} vs {away}",
                "date": date_code,
                "ticker": ticker,
                "home": home,
                "away": away,
                "waiting_books": [],
                "books_used": [],  # No book tracking with simple odds fetch
                "needs_odds_update": False,  # Always use odds from API
                "odds_feed": {
                    "home_odds": float(home_odds) if home_odds is not None else None,  # Store as float
                    "away_odds": float(away_odds) if away_odds is not None else None,  # Store as float
                    "home_prob": home_prob,
                    "away_prob": away_prob,
                    "score_snapshot": odds_snapshot.get("score_snapshot"),
                    "period_clock": odds_snapshot.get("period_clock"),
                    "books_sampled": 1,  # Single book from fetch_event_moneyline
                    "last_update_ts": odds_ts,
                    "last_update_iso": odds_ts_iso,
                },
                "kalshi": kalshi_markets,
            })
        elif not kalshi_markets:
            # Has odds but no Kalshi markets - skip silently to speed up processing
            pass

    print(f" âœ“ ({events_with_odds} events with odds, {len(overlaps)} games with both odds and Kalshi markets)")
    return overlaps

def prepare_kalshi_order(
    market_ticker,
    side,
    price,
    quantity,
    order_type="limit",
    action="buy",
):
    """
    Build and submit a Kalshi order payload.

    Parameters
    ----------
    side   : "yes" or "no"
    price  : If side == "yes" â†’ YES price in [0,1]
             If side == "no"  â†’ NO  price in [0,1]
             (i.e., pass the natural price for the side you're trading)
    action : "buy" or "sell"
    """
    path = "/trade-api/v2/portfolio/orders"
    headers = kalshi_headers("POST", path)
    headers.update({"Content-Type": "application/json"})

    # ðŸš« Safety: block NO orders at the API level
    if side.lower() != "yes":
        raise ValueError(f"âŒ Attempted to place a {side.upper()} order â€” only YES trades allowed.")

    
    payload = {
        "ticker": market_ticker,
        "action": action.lower(),      # <-- buy or sell
        "side": side.lower(),          # <-- yes or no
        "count": int(quantity),
        "type": order_type,
        "client_order_id": str(uuid.uuid4()),
    }

    # Price is provided in the side's own space
    if side.lower() == "yes":
        payload["yes_price"] = int(round(float(price) * 100))
    elif side.lower() == "no":
        payload["no_price"]  = int(round(float(price) * 100))
    else:
        raise ValueError(f"Invalid side: {side}")

    if VERBOSE:
        print("\nðŸ“¦ === Kalshi Order Build ===")
        print(f"Ticker: {market_ticker}")
        print(f"Action: {action}")
        print(f"Side:   {side}")
        print(f"Price:  {price:.2%}")
        print(f"Qty:    {quantity}")
        print(f"Type:   {order_type}")
        print(json.dumps(payload, indent=2))
        print("â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€")

    if PLACE_LIVE_KALSHI_ORDERS == "YES":
        if VERBOSE:
            print("ðŸš€ Sending live order to Kalshi...")
        response = SESSION.post(KALSHI_BASE_URL + path, headers=headers, json=payload, timeout=10)
        if VERBOSE:
            print("ðŸ’¬ Kalshi Response:", response.status_code, response.text)
        return response
    else:
        print("ðŸ§ª SAFE MODE: Order preview only, not submitted.")
        return payload


def safe_prepare_kalshi_order(
    market_ticker: str,
    side: str,
    price: float,
    quantity: int,
    max_total_contracts: Optional[int] = None,
    order_type: str = "limit",
    action: str = "buy",
):
    """
    Wrapper around prepare_kalshi_order that guards against accidental oversizing.

    Typical usage
    -------------
    - When you've just cancelled or modified an order and are about to place another
      order on the same market, but want to be sure you don't accidentally double
      your size if the previous order actually filled.

    Behavior
    --------
    - If max_total_contracts is provided:
        * Fetches live positions from Kalshi.
        * Computes current live contracts on (market_ticker, side).
        * If current >= max_total_contracts â†’ skip placing a new order.
        * If current + quantity > max_total_contracts â†’ shrink quantity so the
          live total does not exceed max_total_contracts.
    - If max_total_contracts is None â†’ just forwards to prepare_kalshi_order.
    """
    # Only enforce when we're actually sending live orders
    if PLACE_LIVE_KALSHI_ORDERS == "YES" and max_total_contracts is not None and quantity > 0:
        try:
            live_positions = get_live_positions() or []
            live_qty = sum(
                int(p.get("contracts") or 0)
                for p in live_positions
                if p.get("ticker") == market_ticker
                and (p.get("side") or "").lower() == side.lower()
            )

            # Already at or above the cap â†’ do nothing
            if live_qty >= max_total_contracts:
                print(
                    f"ðŸ›¡ï¸ SAFE ORDER: Already have {live_qty} contracts on {market_ticker} "
                    f"(max {max_total_contracts}). Skipping new order to prevent oversizing."
                )
                return None

            # Adjust the quantity so we don't exceed the cap
            allowed = max_total_contracts - live_qty
            if quantity > allowed:
                if allowed <= 0:
                    print(
                        f"ðŸ›¡ï¸ SAFE ORDER: Proposed quantity {quantity} would exceed max {max_total_contracts} "
                        f"given current live {live_qty}. Skipping order."
                    )
                    return None

                print(
                    f"ðŸ›¡ï¸ SAFE ORDER: Adjusting quantity from {quantity} to {allowed} on {market_ticker} "
                    f"to respect max_total_contracts={max_total_contracts} (live={live_qty})."
                )
                quantity = allowed
        except Exception as e:
            # Don't hard-fail the trade if the safety check itself has an issue
            print(f"âš ï¸ safe_prepare_kalshi_order position check failed: {e} â€” proceeding with original quantity {quantity}")

    return prepare_kalshi_order(
        market_ticker=market_ticker,
        side=side,
        price=price,
        quantity=quantity,
        order_type=order_type,
        action=action,
    )


# ==== ORDER FILL HELPERS (add below prepare_kalshi_order) ====
from typing import Optional, Tuple

def _extract_order_id(resp) -> Tuple[Optional[str], Optional[str]]:
    """
    Return (order_id, client_order_id) from the place-order response.
    Handles {order:{...}} or top-level shapes.
    """
    try:
        d = resp.json()
    except Exception:
        return None, None

    order_obj = d.get("order") or d
    order_id = order_obj.get("order_id") or order_obj.get("id")
    client_order_id = order_obj.get("client_order_id")
    return order_id, client_order_id


def get_order(order_id: str):
    """
    Fetch order details by order_id. Returns (json_or_none, status_code).
    Handles non-JSON bodies gracefully.
    """
    path = f"/trade-api/v2/portfolio/orders/{order_id}"
    headers = kalshi_headers("GET", path)
    try:
        r = SESSION.get(KALSHI_BASE_URL + path, headers=headers, timeout=10)
        try:
            data = r.json()
        except Exception:
            # Not JSON (e.g., 404 HTML). Return a minimal stub so callers don't crash.
            data = {"order": {"status": f"http_{r.status_code}", "remaining_count": None, "filled_count": 0}}
        return data, r.status_code
    except Exception as e:
        print(f"âŒ get_order error for {order_id}: {e}")
        return None, None

def _is_filled(order_json: dict,
               expected_count: Optional[int] = None,
               require_full: bool = True) -> Tuple[bool, int]:
    """
    Detects fill state from Kalshi order JSON.
    Returns (is_filled, filled_qty).

    Recognises common Kalshi shapes:
      {"order": {"status": "executed", "filled_count": 1, ...}}
      {"status": "filled", "count": 1}
      {"order": {"taker_fill_count": 1}}
    """
    if not isinstance(order_json, dict):
        return False, 0

    o = order_json.get("order") or order_json
    status = str(o.get("status") or "").lower()

    # accept several fill count key names
    for key in (
        "filled_count", "filled_qty", "count_filled",
        "taker_fill_count", "maker_fill_count", "count"
    ):
        if key in o and o[key] is not None:
            try:
                filled_qty = int(o[key])
                break
            except Exception:
                filled_qty = 0
    else:
        filled_qty = 0

    remaining = o.get("remaining_count")
    try:
        remaining = int(remaining) if remaining is not None else None
    except Exception:
        remaining = None

    # treat these as final cancellations
    cancelled_like = {"cancelled", "canceled", "closed_cancelled", "rejected"}
    if any(c in status for c in cancelled_like):
        return False, 0

    # interpret "executed"/"filled" as success even if counts missing
    if ("executed" in status or "filled" in status) and filled_qty == 0:
        if remaining == 0 and expected_count:
            filled_qty = expected_count
        else:
            # not final yet; wait for counts/remaining to settle
            return False, 0

    # positive fill detected
    if filled_qty > 0:
        if require_full:
            if remaining == 0:
                return True, filled_qty
            if expected_count and filled_qty >= expected_count:
                return True, filled_qty
            return False, filled_qty  # partial
        return True, filled_qty

    return False, 0

def cancel_order_best_effort(order_id: Optional[str] = None,
                             client_order_id: Optional[str] = None):
    """
    Try multiple cancel endpoints until one works (no exception and non-404).
    """
    # Try DELETE /orders/{id}
    if order_id:
        try:
            path = f"/trade-api/v2/portfolio/orders/{order_id}"
            headers = kalshi_headers("DELETE", path)
            r = SESSION.delete(KALSHI_BASE_URL + path, headers=headers, timeout=10)
            if r.status_code < 400 and r.status_code != 404:
                print(f"ðŸ›‘ Cancel via DELETE succeeded ({r.status_code})")
                return r
            else:
                print(f"â†ªï¸ DELETE cancel returned {r.status_code}: {r.text[:180]}")
        except Exception as e:
            print(f"âŒ DELETE cancel error: {e}")

    # Try POST /orders/{id}/cancel
    if order_id:
        try:
            path = f"/trade-api/v2/portfolio/orders/{order_id}/cancel"
            headers = kalshi_headers("POST", path)
            for body in [{"order_id": order_id}, {"order_ids": [order_id]}]:
                r = SESSION.post(KALSHI_BASE_URL + path, headers=headers, json=body, timeout=10)
                if r.status_code < 400 and r.status_code != 404:
                    print(f"ðŸ›‘ Cancel via POST /{order_id}/cancel succeeded ({r.status_code})")
                    return r
            if r.status_code < 400 and r.status_code != 404:
                print(f"ðŸ›‘ Cancel via POST /{order_id}/cancel succeeded ({r.status_code})")
                return r
            else:
                print(f"â†ªï¸ /{order_id}/cancel returned {r.status_code}: {r.text[:180]}")
        except Exception as e:
            print(f"âŒ POST cancel error: {e}")

    # Try POST /orders/cancel with body
    try:
        path = "/trade-api/v2/portfolio/orders/cancel"
        headers = kalshi_headers("POST", path)
        body_candidates = []
        if order_id:
            body_candidates.append({"order_id": order_id})
            body_candidates.append({"order_ids": [order_id]})
        if client_order_id:
            body_candidates.append({"client_order_id": client_order_id})

        for body in body_candidates:
            r = requests.post(KALSHI_BASE_URL + path, headers=headers, json=body, timeout=10)
            if r.status_code < 400 and r.status_code != 404:
                print(f"ðŸ›‘ Cancel via /orders/cancel {body} succeeded ({r.status_code})")
                return r
            else:
                print(f"â†ªï¸ /orders/cancel {body} returned {r.status_code}: {r.text[:180]}")
    except Exception as e:
        print(f"âŒ POST /orders/cancel error: {e}")

    print("âš ï¸ All cancel attempts failed (likely already gone or API shape different).")
    return None

def wait_for_fill_or_cancel(order_id: str,
                            client_order_id: Optional[str] = None,
                            timeout_s: int = 30,
                            poll_s: float = 1.0,
                            expected_count: Optional[int] = None,
                            require_full: bool = True,
                            verify_ticker: Optional[str] = None,
                            verify_side: Optional[str] = "yes") -> Tuple[str, int]:

    """
    Polls Kalshi for fill status up to timeout_s.
    If not filled, attempts cancel â€” but double-checks for fills that race with cancels.
    Returns (status, filled_qty) where status âˆˆ {"filled","cancelled"}.
    """
    t0 = time.time()
    time.sleep(0.25)  # small pause so status can transition

    # --- Poll until timeout ---
    while time.time() - t0 < timeout_s:
        data, code = get_order(order_id)

        if code == 404:
            print("âš ï¸ order temporarily not found (likely just filled or settling). Retrying...")
            ...
            continue

        filled, qty = _is_filled(
            data or {},
            expected_count=expected_count,
            require_full=require_full
        )
        if filled:
            print(f"âœ… Order filled: {order_id} (qty={qty})")
            return "filled", qty


        # ðŸ”¹ NEW: progress log every second
        o = (data.get("order") or {}) if data else {}
        status = o.get("status", "unknown")
        remaining = o.get("remaining_count")
        print(f"âŒ› Waiting fill... status={status}, remaining={remaining}, elapsed={time.time()-t0:.1f}s")

        time.sleep(max(0.25, poll_s))

    # --- Timeout reached â†’ send cancel ---
    print(f"â³ Not filled in {timeout_s}s â†’ sending cancel for {order_id}")
    cancel_order_best_effort(order_id=order_id, client_order_id=client_order_id)

    # --- Post-cancel grace period to catch race fills ---
    t1 = time.time()
    while time.time() - t1 < 5.0:
        data, code = get_order(order_id)
        filled, qty = _is_filled(
            data or {},
            expected_count=expected_count,
            require_full=require_full
        )

        # âœ… Detect â€œexecutedâ€ or â€œfilledâ€ even if 404s appear
        if filled or (data and "executed" in str(data).lower()):
            print(f"âœ… FILLED detected after cancel window: {order_id} (qty={qty or 1})")
            return "filled", qty or 1

        # If 404, verify via live positions (by ticker/side) before assuming execution
        if code == 404:
            try:
                lp = get_live_positions() or []
                if verify_ticker and verify_side:
                    found = next(
                        (p for p in lp if p.get("ticker") == verify_ticker and (p.get("side") or "").lower() == (verify_side or "").lower()),
                        None
                    )
                    if found and int(found.get("contracts") or 0) > 0:
                        print("âœ… Order endpoint 404 but position present â€” treating as filled.")
                        return "filled", expected_count or int(found.get("contracts") or 1)
            except Exception:
                pass
            print("ðŸ›‘ Order not found post-cancel; treating as cancelled.")
            return "cancelled", 0

        time.sleep(0.75)

    print("ðŸ›‘ Cancel completed â€” no fill.")
    return "cancelled", 0

def realize_if_settled():
    """
    If a market is settled/resolved, realize PnL based on entry only (hold-to-expiry),
    then drop the position. This expects Kalshi market JSON to expose status/result.
    """
    global positions, realized_pnl, wins, losses

    keep = []
    for p in positions:
        try:
            mkts = get_kalshi_markets(p["event_ticker"], force_live=True)
            # Handle rate limiting (None) or empty markets
            if not mkts:  # None (rate limited) or [] (no markets)
                keep.append(p)
                continue
            m = next((x for x in mkts if x.get("ticker") == p["market_ticker"]), None)
            if not m:
                keep.append(p)
                continue

            status = (m.get("status") or "").lower()
            if status not in ("settled", "closed", "resolved"):
                keep.append(p)
                continue

            # Adjust these keys depending on the actual Kalshi payload you get on resolution:
            # common shapes: m["result"] in {"yes", "no"} or {"yes_won","no_won"}
            result = (m.get("result") or m.get("resolution") or "").lower()

            entry = p.get("effective_entry", p["entry_price"])
            # For settled positions, we don't have historical bid/ask, default to taker (conservative)
            fee_entry = kalshi_fee_per_contract(entry, is_maker=False)

            if result.startswith("yes"):
                # YES won; receive $1 per contract, no exit fee (hold-to-expiry)
                pnl_ct = (1.0 - entry) - fee_entry
                wins += 1
                exit_px = 1.0
            elif result.startswith("no"):
                # YES lost
                pnl_ct = -(entry + fee_entry)
                losses += 1
                exit_px = 0.0
            else:
                # Unknown result shape; keep position and try again next loop
                keep.append(p)
                continue

            cash = p["stake"] * pnl_ct
            realized_pnl += cash
            log_exit_row(p, exit_price=exit_px, pnl_cash=cash, settled=True)

        except Exception as e:
            print(f"âš ï¸ realize_if_settled error on {p.get('market_ticker')}: {e}")
            keep.append(p)

    positions[:] = keep
    save_positions()

def check_time_based_exits():
    """
    Exit positions that have been held longer than TIME_EXIT_THRESHOLD_MINUTES.
    Only active if TIME_BASED_EXITS_ENABLED is True.
    """
    global positions
    
    if not TIME_BASED_EXITS_ENABLED:
        return
    
    current_time = now_utc()
    threshold_seconds = TIME_EXIT_THRESHOLD_MINUTES * 60.0
    
    for p in positions:
        if p.get("settled", False):
            continue
        
        entry_time_str = p.get("entry_time")
        if not entry_time_str:
            continue
        
        try:
            entry_time = parse_iso_utc(entry_time_str)
            hold_duration = (current_time - entry_time).total_seconds()
            
            if hold_duration >= threshold_seconds:
                # Mark for exit - actual exit logic should be handled by main loop
                p["time_exit_triggered"] = True
                if VERBOSE:
                    print(f"â° Time-based exit triggered for {p.get('market_ticker')} "
                          f"(held {hold_duration/60:.1f} minutes, threshold {TIME_EXIT_THRESHOLD_MINUTES:.1f} minutes)")
        except Exception as e:
            if VERBOSE:
                print(f"âš ï¸ Error checking time-based exit for {p.get('market_ticker')}: {e}")

def is_neutralized(market_ticker):
    """Returns True if this match is already hedged (both sides exist)."""
    sides = set(p["side"] for p in positions if p["market_ticker"] == market_ticker)
    return len(sides) > 1

def _is_ncaa_event(event: Dict[str, Any]) -> bool:
    """Check if event is NCAA basketball."""
    league = (event.get("league") or {}).get("name") or ""
    country = (event.get("league") or {}).get("cc") or ""
    league_lower = league.lower()
    
    # Strong signals
    if "ncaa" in league_lower:
        return True
    
    # Some feeds label NCAA as "USA College Basketball"
    if "college" in league_lower and "usa" in league_lower:
        return True
    
    # Extra safety: US leagues in college divisions
    if country == "USA" and any(
        key in league_lower
        for key in ["college", "ncaa", "u19"]
    ):
        return True
    
    return False


def _fetch_odds_feed_live_events(statuses: Optional[Iterable[str]] = None) -> list:
    """
    Fetch live NCAA basketball events from BetsAPI.
    Filters for NCAA events only.
    """
    events: List[Dict[str, Any]] = []
    page = 1
    
    while True:
        payload = _betsapi_request(
            BETSAPI_EVENTS_INPLAY_PATH,
            {"sport_id": BASKETBALL_SPORT_ID, "page": page}
        )
        results = payload.get("results") or []
        
        # Filter for NCAA events only
        for evt in results:
            if _is_ncaa_event(evt):
                events.append(evt)
        
        pager = payload.get("pager") or {}
        total = pager.get("total")
        per_page = pager.get("per_page") or len(results)
        
        if not results:
            break
        if not pager or total is None or per_page is None:
            page += 1
            continue
        if page * per_page >= total:
            break
        page += 1
    
    return events


def _implied_prob(value: Optional[float]) -> Optional[float]:
    if not isinstance(value, (int, float)) or value <= 0:
        return None
    return 1.0 / float(value)


def _format_epoch(value: Optional[str]) -> str:
    """Format epoch timestamp to ISO string."""
    if not value:
        return "unknown"
    try:
        dt = datetime.fromtimestamp(int(value), tz=UTC)
        return dt.strftime("%Y-%m-%d %H:%M:%S UTC")
    except (ValueError, TypeError):
        return "unknown"


def fetch_event_moneyline(
    event_id: str, moneyline_key: str = BASKETBALL_MONEYLINE_KEY
) -> Optional[Dict[str, Any]]:
    """
    Fetch moneyline odds from BetsAPI for a specific event.
    Always fetches fresh data (no caching).
    Returns dict with home_odds, away_odds, score_snapshot, period_clock, recorded_at.
    Returns None if no odds found.
    """
    # Always fetch fresh - no caching
    payload = _betsapi_request(BETSAPI_EVENT_ODDS_PATH, {"event_id": event_id})
    odds = payload.get("results", {}).get("odds") or {}
    entries = odds.get(moneyline_key) or []
    for record in entries:
        home_od = record.get("home_od")
        away_od = record.get("away_od")
        if home_od in (None, "-", "") or away_od in (None, "-", ""):
            continue
        return {
            "home_odds": home_od,
            "away_odds": away_od,
            "score_snapshot": record.get("ss"),
            "period_clock": record.get("time_str"),
            "recorded_at": _format_epoch(record.get("add_time")) if record.get("add_time") else None,
        }
    return None


def _odds_feed_homeaway_avgs(
    event_id: int,
    prev_snapshot: Optional[Dict[str, Dict[str, float]]],
    require_update: bool = True,
) -> tuple[
    Optional[float],
    Optional[float],
    int,
    int,
    int,
    Dict[str, Dict[str, float]],
    List[str],
    List[str],
]:
    """
    Fetch moneyline odds from BetsAPI for an event and return devigged probabilities.
    Always fetches fresh data - no caching.
    If multiple books are available, devig each and average the results.
    prev_snapshot is only used for change detection, never for returning cached odds.
    Returns (home_prob, away_prob, book_count, changed_count, avg_count, snapshot_dict, book_names, used_labels).
    """
    _ = require_update  # legacy arg
    _ = prev_snapshot  # Only used for comparison, never for returning cached odds
    
    # Always fetch fresh odds from API (cache-busting handled in _betsapi_request)
    payload = _betsapi_request(BETSAPI_EVENT_ODDS_PATH, {"event_id": event_id})
    odds = payload.get("results", {}).get("odds") or {}
    entries = odds.get(BASKETBALL_MONEYLINE_KEY) or []
    
    event_snapshot: Dict[str, Dict[str, float]] = {}
    all_entries: List[Dict[str, Any]] = []
    book_count = 0
    book_names: List[str] = []
    
    def _book_probabilities(dec_home, dec_away) -> tuple[Optional[float], Optional[float]]:
        """Convert decimal odds to devigged probabilities."""
        try:
            dh = float(dec_home)
            da = float(dec_away)
        except (TypeError, ValueError):
            return None, None
        if dh <= 0 or da <= 0:
            return None, None
        if USE_SHIN_DEVIG:
            return devig_shin_two_way(dh, da)
        probs = devig_proportional([1.0 / dh, 1.0 / da])
        return probs[0], probs[1]
    
    def _fmt_book_odds(val: Optional[float]) -> str:
        return f"{float(val):.2f}" if isinstance(val, (int, float)) else "?"
    
    def _simple_mean(entries: List[Dict[str, Any]]) -> tuple[Optional[float], Optional[float], List[str]]:
        """Simple average of devigged probabilities across all books (no weights)."""
        valid = [e for e in entries if e["home"] is not None and e["away"] is not None]
        if not valid:
            return None, None, []
        # Simple arithmetic mean
        home_avg = sum(e["home"] for e in valid) / len(valid)
        away_avg = sum(e["away"] for e in valid) / len(valid)
        return home_avg, away_avg, [e["label"] for e in valid]
    
    # Process each book's odds
    for record in entries:
        home_od = record.get("home_od")
        away_od = record.get("away_od")
        
        # Skip invalid odds
        if home_od in (None, "-", "") or away_od in (None, "-", ""):
            continue
        
        try:
            home_dec = float(home_od)
            away_dec = float(away_od)
        except (TypeError, ValueError):
            continue
        
        if home_dec <= 0 or away_dec <= 0:
            continue
        
        # Use bookmaker name or ID as identifier
        book_id = str(record.get("bookmaker_id") or record.get("id") or f"book_{book_count}")
        book_label = record.get("bookmaker_name") or "UNKNOWN"  # Default fallback if bookmaker name missing
        
        # Store snapshot
        event_snapshot[book_id] = {
            "outcome_0": home_dec,
            "outcome_1": away_dec,
        }
        
        # Devig probabilities
        hp, ap = _book_probabilities(home_dec, away_dec)
        if hp is None or ap is None:
            continue
        
        book_count += 1
        home_odds_disp = _fmt_book_odds(home_dec)
        away_odds_disp = _fmt_book_odds(away_dec)
        book_names.append(f"{book_label} (H:{home_odds_disp} | A:{away_odds_disp})")
        
        entry = {
            "home": hp,
            "away": ap,
            "label": book_label,
            "book_id": book_id,
        }
        
        # Always use all odds from API (no "changed" filtering)
        all_entries.append(entry)
        
        # Small delay between book processing
        time.sleep(EVENT_ODDS_SLEEP)
    
    if not all_entries:
        return None, None, book_count, 0, 0, event_snapshot, book_names, []
    
    # Simple average across all books (no weights)
    home_avg, away_avg, used_labels = _simple_mean(all_entries)
    if home_avg is None or away_avg is None or not all_entries:
        return None, None, book_count, 0, 0, event_snapshot, book_names, []
    
    # Normalize probabilities
    total = home_avg + away_avg
    if total > 0:
        home_avg /= total
        away_avg /= total
    
    # Return counts (all entries are used, so changed_count = avg_count = total)
    avg_count = len(all_entries)
    changed_count = avg_count
    effective_count = avg_count
    
    return (
        home_avg,
        away_avg,
        book_count,
        effective_count,
        avg_count,
        event_snapshot,
        book_names,
        used_labels,
    )


def _normalize_start_ts(start_at: Optional[str]) -> str:
    """
    Odds feed supplies naive timestamps (YYYY-mm-dd HH:MM:SS). Convert to ISO8601 UTC.
    """
    if not start_at:
        return datetime.utcnow().isoformat() + "Z"
    start_at = start_at.strip().replace(" ", "T")
    if start_at.endswith("Z") or "+" in start_at:
        return start_at
    return f"{start_at}Z"


def get_odds_feed_events(
    overlap_map: Optional[Dict[int, Dict[str, Any]]] = None,
    raw_events: Optional[List[Dict[str, Any]]] = None,
):
    """
    Fetch live NCAA basketball events from BetsAPI and adapt them to the
    structure the rest of the bot expects (money_line-style data).
    Always fetches fresh data - no caching.
    """
    global _odds_cache_events, _odds_cache_ts

    overlap_ids = set(overlap_map.keys()) if overlap_map else None

    # DISABLED CACHE: Always fetch fresh odds, never return cached events
    # Removed cache check: if overlap_ids and _odds_cache_events and (now - _odds_cache_ts) <= ODDS_FEED_CACHE_TTL:

    last_err = None
    current_snapshot: Dict[str, Dict[str, Dict[str, float]]] = {}
    _load_odds_snapshot()  # Only used for detecting changes, not for returning cached odds
    if overlap_map is not None and not overlap_map:
        print("âš ï¸ No Kalshi overlaps provided â€” skipping odds-feed scan.")
        return []

    try:
        if raw_events is None:
            raw_events = _fetch_odds_feed_live_events()  # Always fetches fresh
        adapted = []
        for evt in raw_events:
            # Extract team names from BetsAPI format (same logic as get_overlapping_matches)
            home_obj = evt.get("home")
            away_obj = evt.get("away")
            if isinstance(home_obj, dict):
                home = home_obj.get("name") or home_obj.get("short_name") or home_obj.get("display_name")
            else:
                home = home_obj or (evt.get("team_home") or {}).get("name") if isinstance(evt.get("team_home"), dict) else None
            
            if isinstance(away_obj, dict):
                away = away_obj.get("name") or away_obj.get("short_name") or away_obj.get("display_name")
            else:
                away = away_obj or (evt.get("team_away") or {}).get("name") if isinstance(evt.get("team_away"), dict) else None
            
            if not home or not away:
                continue
            
            # Already filtered for NCAA in _fetch_odds_feed_live_events, but double-check
            if not _is_ncaa_event(evt):
                continue

            evt_id = evt.get("id")
            if evt_id is None:
                continue
            if overlap_ids is not None and evt_id not in overlap_ids:
                continue
            
            # prev_books is only used for comparison/detection, not for returning cached odds
            prev_books = _odds_prev_snapshot.get(str(evt_id)) if _odds_snapshot_loaded else None
            (
                home_prob,
                away_prob,
                books_sampled,
                changed_count,
                avg_count,
                evt_snapshot,
                book_names,
                books_used_now,
            ) = _odds_feed_homeaway_avgs(
                evt_id,
                prev_books,  # Only for comparison, not for caching
            )
            current_snapshot[str(evt_id)] = evt_snapshot

            # Always use odds from API (no "changed" filtering)
            if home_prob is None or away_prob is None:
                # Debug output for missing probabilities
                print(f"         âš ï¸ No probabilities available from BetsAPI for: {away} vs {home}")
                continue

            home_odds = float(1.0 / max(home_prob, 1e-6))  # Ensure float
            away_odds = float(1.0 / max(away_prob, 1e-6))  # Ensure float
            quote_ts = time.time()

            # Clean up any old waiting stage flags (no longer used)
            if overlap_map:
                match_info = overlap_map.get(evt_id)
                if match_info:
                    match_info.pop("_waiting_notice_stage", None)

            # Format start time from BetsAPI
            start_time = evt.get("time")
            if start_time:
                try:
                    # BetsAPI returns Unix timestamp
                    if isinstance(start_time, (int, float)):
                        start_time = datetime.fromtimestamp(start_time, tz=UTC).isoformat()
                    else:
                        start_time = _normalize_start_ts(str(start_time))
                except Exception:
                    start_time = _normalize_start_ts(None)

            adapted.append({
                "id": evt_id,
                "home": home,
                "away": away,
                "league_name": "NCAA",
                "starts": start_time or _normalize_start_ts(None),
                "periods": {
                    "num_0": {
                        "money_line": {
                            "home": home_odds,
                            "away": away_odds,
                        }
                    }
                },
                "odds_feed": {
                    "home_prob": home_prob,
                    "away_prob": away_prob,
                    "books_sampled": avg_count,
                    "last_update_ts": quote_ts,
                    "last_update_iso": datetime.fromtimestamp(quote_ts).isoformat(),
                    "books_used": books_used_now,
                }
            })

        if current_snapshot:
            _save_odds_snapshot(current_snapshot)  # Save for next run's change detection only

        # Don't cache events - always fetch fresh
        if adapted:
            # Cache storage disabled: _odds_cache_events = adapted, _odds_cache_ts = time.time()
            return adapted

        if current_snapshot:
            last_err = "No NCAA games with updated sportsbook odds."
        else:
            last_err = "No live NCAA odds returned from BetsAPI."
    except Exception as exc:
        last_err = str(exc)

    # DISABLED CACHE: Never return cached events, always fail if fetch fails
    # Removed cache fallback: if _odds_cache_events and (time.time() - _odds_cache_ts) <= ODDS_FEED_CACHE_TTL:

    print(f"âŒ Odds-feed fetch failed: {last_err}")
    return []


def event_is_neutralized(evt: str) -> bool:
    """True if we have YES positions on two distinct market_tickers in the same event."""
    evt_key = event_key(evt)
    mkts = {
        p["market_ticker"]
        for p in positions
        if event_key(p.get("event_ticker")) == evt_key
        and p.get("side") == "yes"
        and p.get("stake", 0) > 0
    }
    return len(mkts) >= 2

def per_ct_fee_for_qty(price: float, qty: int, is_maker: bool = False) -> float:
    return kalshi_fee(qty, price, is_maker=is_maker) / max(1, qty)

def total_dollars_needed(price: float, qty: int, is_maker: bool = False) -> float:
    return qty * price + kalshi_fee(qty, price, is_maker=is_maker)

def max_qty_with_cap(dollars_cap: float, price: float, q_hi: int = 5000) -> int:
    if price <= 0 or dollars_cap <= 0:
        return 0
    lo, hi, ans = 0, q_hi, 0
    while lo <= hi:
        mid = (lo + hi) // 2
        need = total_dollars_needed(price, mid)
        if need <= dollars_cap:
            ans = mid
            lo = mid + 1
        else:
            hi = mid - 1
    return ans

def upsert_position(new_pos):
    for p in positions:
        if p["market_ticker"] == new_pos["market_ticker"] and p["side"] == new_pos["side"]:
            # weighted-average entry
            total = p["stake"] + new_pos["stake"]
            if total > 0:
                p["entry_price"] = (
                    p["entry_price"] * p["stake"]
                    + new_pos["entry_price"] * new_pos["stake"]
                ) / total
            p["stake"] = total
            p["max_price"] = max(p.get("max_price", 0), new_pos["entry_price"])
            p["last_price"] = new_pos.get("last_price", p.get("last_price"))
            return
    positions.append(new_pos)

def normalize_loaded_positions():
    """Ensure loaded positions have correct ticker formats for hedge recognition."""
    for p in positions:
        # Strip whitespace
        for k in ("event_ticker", "market_ticker", "match"):
            if k in p and isinstance(p[k], str):
                p[k] = p[k].strip()

        # Ensure tickers are consistent casing
        if "event_ticker" in p:
            p["event_ticker"] = p["event_ticker"].upper()
        
        # Backward compatibility: add entry_value if missing
        if "entry_value" not in p:
            stake = p.get("stake", 0)
            entry_price = p.get("entry_price", 0)
            p["entry_value"] = stake * entry_price if stake > 0 and entry_price > 0 else 0
        
        # Backward compatibility: add stop_loss_triggered if missing
        if "stop_loss_triggered" not in p:
            p["stop_loss_triggered"] = False
        # Backward compatibility: add closing_in_progress if missing
        if "closing_in_progress" not in p:
            p["closing_in_progress"] = False
        # Clear stale closing flags from previous runs (older than 5 minutes)
        if p.get("closing_in_progress") and p.get("closing_initiated_at"):
            age_seconds = time.time() - p.get("closing_initiated_at", 0)
            if age_seconds > 300:  # 5 minutes
                p["closing_in_progress"] = False
                p.pop("closing_initiated_at", None)
                p.pop("closing_check_result", None)
        elif p.get("closing_in_progress") and not p.get("closing_initiated_at"):
            # If closing_in_progress is True but no timestamp, clear it (stale from old code)
            p["closing_in_progress"] = False
        if "market_ticker" in p:
            p["market_ticker"] = p["market_ticker"].upper()

        # Backfill missing event_ticker if only market_ticker present
        # Also fix event_ticker if it looks like a market ticker (has more than 3 parts)
        if p.get("market_ticker"):
            current_event_ticker = p.get("event_ticker", "")
            market_ticker = p["market_ticker"]
            
            # Extract event ticker from market ticker
            parts = market_ticker.split("-")
            if len(parts) > 2:
                # âœ… Take first 2 parts (not 3) - the 3rd part is the team suffix
                correct_event_ticker = "-".join(parts[:2]).upper()
                
                # Fix if event_ticker is missing or if it looks like a market ticker
                if not current_event_ticker or current_event_ticker == market_ticker.upper():
                    p["event_ticker"] = correct_event_ticker
                # Also fix if event_ticker has more than 3 parts (looks like market ticker)
                elif len(current_event_ticker.split("-")) > 3:
                    p["event_ticker"] = correct_event_ticker

def deduplicate_positions():
    """Ensure no duplicate market_ticker entries and flag events with both sides open."""
    global positions
    unique = {}
    for p in positions:
        key = (p["market_ticker"], p["side"])
        if key not in unique:
            unique[key] = p
        else:
            print(f"âš ï¸ Duplicate detected for {p['match']} {p['side']} â€” keeping first, discarding later.")
    positions = list(unique.values())

    # Detect events where both YES sides exist
    events = {}
    for p in positions:
        events.setdefault(p["event_ticker"], []).append(p)
    for evt, ps in events.items():
        yes_count = sum(1 for x in ps if x["side"].lower() == "yes")
        if yes_count >= 2:
            print(f"ðŸ” Event {evt} has both sides active (neutralized candidate).")

def normalize_event_ticker(t):
    """
    Cleans and normalizes event tickers so comparisons match across sides.
    Strips case, suffixes like '-SET1', and whitespace.
    """
    if not t:
        return ""
    t = t.lower().strip()
    t = re.sub(r"-set\d+", "", t)   # remove set-level suffixes
    t = re.sub(r"[_\s]+", "", t)    # remove underscores/spaces
    return t

def event_key(evt: Optional[str]) -> str:
    """
    Canonical event identifier used for comparisons and locks.
    Keeps everything in lowercase without SET suffixes or whitespace.
    """
    return normalize_event_ticker(evt or "")

def label_for_market_ticker(mkt_ticker, kalshi_markets):
    m = next((x for x in kalshi_markets if x.get("ticker") == mkt_ticker), None)
    return (m.get("yes_sub_title") if m else mkt_ticker) or mkt_ticker

def exposure_violation(
    market_ticker: str,
    event_ticker: str,
    added_qty: int,
    entry_price: float,
    capital: float,
    is_hedge_trade: bool
) -> tuple[bool, str]:
    if added_qty <= 0 or entry_price <= 0:
        return True, "non_positive_size"

    add_exposure = added_qty * entry_price

    side_exposure = sum(
        p["stake"] * p["entry_price"]
        for p in positions
        if p.get("market_ticker") == market_ticker
    )
    side_future = side_exposure + add_exposure

    evt_key = event_key(event_ticker)

    evt_exposure = sum(
        p["stake"] * p["entry_price"]
        for p in positions
        if event_key(p.get("event_ticker")) == evt_key
    )
    evt_future = evt_exposure + add_exposure

    cap_pct = MAX_TOTAL_EXPOSURE_HEDGE_PCT if is_hedge_trade else MAX_TOTAL_EXPOSURE_PCT
    limit = capital * cap_pct

    if side_future > limit:
        return True, f"side_exposure {side_future:.2f} > {limit:.2f}"
    if evt_future > limit:
        return True, f"event_exposure {evt_future:.2f} > {limit:.2f}"
    
    # âœ… NEW: Check percentage-based cap per game (95% of total capital)
    max_exposure_per_game = capital * MAX_EXPOSURE_PER_GAME_PCT
    if evt_future > max_exposure_per_game:
        return True, f"event_exposure ${evt_future:.2f} > ${max_exposure_per_game:.2f} ({MAX_EXPOSURE_PER_GAME_PCT:.0%} of capital ${capital:.2f})"
    
    return False, ""

def side_exposure_dollars(event_ticker: str, market_ticker: str) -> float:
    """Total dollars currently risked on a given event/market combo."""
    key = event_key(event_ticker)
    total = 0.0
    for p in positions:
        if (
            event_key(p.get("event_ticker")) == key
            and p.get("market_ticker") == market_ticker
            and not p.get("settled", False)
        ):
            total += float(p.get("stake", 0)) * float(p.get("entry_price", 0.0))
    return total

def commit_trade_and_persist(position, order_id, filled_qty):
    existing = next((p for p in positions
                     if p["market_ticker"].upper() == position["market_ticker"].upper()
                     and p["side"] == position["side"]), None)
    if existing:
        # Calculate weighted average entry price (consistent with upsert_position)
        total = existing["stake"] + filled_qty
        if total > 0:
            existing["entry_price"] = (
                existing["entry_price"] * existing["stake"]
                + position["entry_price"] * filled_qty
            ) / total
            # Also update effective_entry with weighted average
            existing_eff = existing.get("effective_entry", existing["entry_price"])
            new_eff = position.get("effective_entry", position["entry_price"])
            existing["effective_entry"] = (
                existing_eff * existing["stake"]
                + new_eff * filled_qty
            ) / total
            # Update entry_value (weighted average)
            existing_entry_value = existing.get("entry_value", existing["stake"] * existing["entry_price"])
            new_entry_value = filled_qty * position["entry_price"]
            existing["entry_value"] = existing_entry_value + new_entry_value
        existing["stake"] = total
        existing["max_price"] = max(existing.get("max_price", 0.0), position["entry_price"])
    else:
        new_pos = dict(position)
        new_pos["stake"] = filled_qty
        # Track entry_value for stop-loss: total cost basis
        new_pos["entry_value"] = filled_qty * position["entry_price"]
        new_pos["stop_loss_triggered"] = False
        positions.append(new_pos)

    log_trade({**position, "type": "live_filled", "order_id": order_id, "filled_qty": filled_qty})
    log_entry_row(position, position["event_ticker"])

    try:
        reconcile_positions()
    except Exception as e:
        print(f"âš ï¸ Post-fill reconcile failed: {e}")

    save_positions()

def rebalance_positions_outside_bounds(kalshi_markets_dict=None):
    """
    âš ï¸ DEPRECATED - NO LONGER USED âš ï¸
    
    This function checked all hedged positions and tried to rebalance if they drifted outside ROI bounds.
    Rebalancing logic has been removed for simplification - profit protection handles exits instead.
    
    Original behavior:
    - Checked all hedged positions and rebalanced if they're outside ROI bounds
    - Like a first hedge - if positions drift outside bounds, hedge to get back in
    
    Kept for reference but not called anywhere in the code.
    """
    global positions
    
    if not positions:
        return
    
    # Group positions by event
    events = {}
    for p in positions:
        if p.get("side") != "yes" or p.get("settled", False):
            continue
        evt = normalize_event_ticker(p.get("event_ticker", ""))
        if not evt:
            continue
        events.setdefault(evt, []).append(p)
    
    # Check each event that has both sides
    for evt, event_positions in events.items():
        if len(event_positions) < 2:
            continue  # Need both sides to be hedged
        
        # Get markets for this event
        ticker_key = event_key(evt)
        kalshi = kalshi_markets_dict.get(ticker_key) if kalshi_markets_dict else None
        if not kalshi:
            continue
        
        # Aggregate positions on each side
        side_positions = {}
        for pos in event_positions:
            market_ticker = pos.get("market_ticker")
            if market_ticker not in side_positions:
                side_positions[market_ticker] = []
            side_positions[market_ticker].append(pos)
        
        if len(side_positions) != 2:
            continue  # Need exactly 2 sides
        
        sides = list(side_positions.values())
        side_A_positions = sides[0]
        side_B_positions = sides[1]
        
        # Aggregate each side
        def aggregate_side(positions_list):
            total_qty = 0.0
            total_cost = 0.0
            for p in positions_list:
                try:
                    qty = float(p.get("stake", 0))
                    price = float(p.get("entry_price", 0))
                    if qty > 0 and price > 0:
                        total_qty += qty
                        total_cost += qty * price
                except (TypeError, ValueError):
                    continue
            if total_qty > 0:
                return total_qty, total_cost / total_qty
            return 0.0, 0.0
        
        qA, pA = aggregate_side(side_A_positions)
        qB, pB = aggregate_side(side_B_positions)
        
        if qA <= 0 or qB <= 0:
            continue
        
        # Get current market prices for both sides
        market_A = next((m for m in kalshi if m.get("ticker") == side_A_positions[0].get("market_ticker")), None)
        market_B = next((m for m in kalshi if m.get("ticker") == side_B_positions[0].get("market_ticker")), None)
        
        if not market_A or not market_B:
            continue
        
        # Check if side A is outside bounds
        price_A_mid = market_yes_mid(market_A)
        if price_A_mid:
            price_A_mid = max(0.01, min(0.99, float(price_A_mid)))
            bands_A = hedge_qty_bounds_target_roi(qB, pB, price_A_mid, MIN_HEDGE_RETURN)
            if bands_A:
                ql_A, qh_A = bands_A
                ql_A_i, qh_A_i = int(math.ceil(ql_A)), int(math.floor(qh_A))
                
                if qA < ql_A_i or qA > qh_A_i:
                    # Side A is outside bounds - need to rebalance
                    target_A = max(ql_A_i, min(qA, qh_A_i))  # Clamp to bounds
                    if target_A != qA:
                        if VERBOSE:
                            print(f"ðŸ”„ Rebalancing: Side A has {qA} contracts, bounds are [{ql_A_i}, {qh_A_i}], target: {target_A}")
                        # This would trigger a hedge order - but we'll let the main loop handle it
                        # by marking this as needing rebalancing
                        for pos in side_A_positions:
                            pos["needs_rebalance"] = True
                            pos["rebalance_target"] = target_A
        
        # Check if side B is outside bounds
        price_B_mid = market_yes_mid(market_B)
        if price_B_mid:
            price_B_mid = max(0.01, min(0.99, float(price_B_mid)))
            bands_B = hedge_qty_bounds_target_roi(qA, pA, price_B_mid, MIN_HEDGE_RETURN)
            if bands_B:
                ql_B, qh_B = bands_B
                ql_B_i, qh_B_i = int(math.ceil(ql_B)), int(math.floor(qh_B))
                
                if qB < ql_B_i or qB > qh_B_i:
                    # Side B is outside bounds - need to rebalance
                    target_B = max(ql_B_i, min(qB, qh_B_i))  # Clamp to bounds
                    if target_B != qB:
                        if VERBOSE:
                            print(f"ðŸ”„ Rebalancing: Side B has {qB} contracts, bounds are [{ql_B_i}, {qh_B_i}], target: {target_B}")
                        for pos in side_B_positions:
                            pos["needs_rebalance"] = True
                            pos["rebalance_target"] = target_B

def both_sides_open_and_active(evt: str) -> bool:
    evt_norm = normalize_event_ticker(evt)
    yes_positions = [
        p for p in positions
        if normalize_event_ticker(p.get("event_ticker","")) == evt_norm
        and p.get("side") == "yes"
        and p.get("stake", 0) > 0
    ]
    mkts = list({p["market_ticker"] for p in yes_positions})
    if len(mkts) < 2:
        return False

    kalshi = get_kalshi_markets(evt, force_live=True) or []
    active_tickers = {
        m.get("ticker") for m in kalshi
        if m.get("status") == "active" and (m.get("yes_bid") or m.get("yes_ask"))
    }
    return all(t in active_tickers for t in mkts[:2])

def persist_event_locks():
    """Write EVENT_LOCKED_TILL_HEDGE to disk safely."""
    try:
        event_locks_path = os.path.join(BASE_DIR, "event_locks.json")
        with open(event_locks_path, "w") as f:
            json.dump(list(EVENT_LOCKED_TILL_HEDGE), f, indent=2)
    except Exception as e:
        print(f"âš ï¸ Could not persist event locks: {e}")

def persist_stop_lossed_events():
    """Write EVENT_STOP_LOSSED to disk safely with timestamps and entry prices."""
    global EVENT_STOP_LOSSED
    try:
        event_stop_lossed_path = os.path.join(BASE_DIR, "event_stop_lossed.json")
        # Convert to format: {event_ticker: {"timestamp": iso_string, "entry_price": float}}
        data = {}
        for key, value in EVENT_STOP_LOSSED.items():
            if isinstance(value, dict):
                # New format with timestamp and entry_price
                entry_data = {}
                timestamp = value.get("timestamp")
                if isinstance(timestamp, (int, float)):
                    entry_data["timestamp"] = datetime.fromtimestamp(timestamp, tz=UTC).isoformat()
                elif isinstance(timestamp, datetime):
                    entry_data["timestamp"] = timestamp.isoformat()
                else:
                    entry_data["timestamp"] = timestamp
                entry_data["entry_price"] = value.get("entry_price")
                data[key] = entry_data
            elif isinstance(value, (int, float)):
                # Old format: just timestamp, convert to new format (entry_price will be None)
                data[key] = {
                    "timestamp": datetime.fromtimestamp(value, tz=UTC).isoformat(),
                    "entry_price": None
                }
            elif isinstance(value, datetime):
                data[key] = {
                    "timestamp": value.isoformat(),
                    "entry_price": None
                }
            else:
                data[key] = value
        with open(event_stop_lossed_path, "w") as f:
            json.dump(data, f, indent=2)
    except Exception as e:
        print(f"âš ï¸ Could not persist stop-lossed events: {e}")

def mark_event_stop_lossed(event_ticker: str, entry_price: Optional[float] = None):
    """Mark an event as stop-lossed with current timestamp and original entry price to prevent re-entry until price recovers."""
    global EVENT_STOP_LOSSED
    key = event_key(event_ticker)
    current_time = time.time()
    EVENT_STOP_LOSSED[key] = {
        "timestamp": current_time,
        "entry_price": entry_price
    }
    persist_stop_lossed_events()
    entry_price_str = f" (entry price: {entry_price:.2%})" if entry_price is not None else ""
    print(f"ðŸš« Event {event_ticker} marked as stop-lossed at {datetime.fromtimestamp(current_time, tz=UTC).isoformat()}{entry_price_str} - cooldown active until price recovers past entry price")

def persist_7pct_exited_events():
    """Write EVENT_7PCT_EXITED to disk safely."""
    global EVENT_7PCT_EXITED
    try:
        event_7pct_exited_path = os.path.join(BASE_DIR, "event_7pct_exited.json")
        with open(event_7pct_exited_path, "w") as f:
            json.dump(list(EVENT_7PCT_EXITED), f, indent=2)
    except Exception as e:
        print(f"âš ï¸ Could not persist 7% exited events: {e}")

def mark_event_7pct_exited(event_ticker: str):
    """Mark an event as 7% exited to permanently prevent new entries."""
    global EVENT_7PCT_EXITED
    key = event_key(event_ticker)
    EVENT_7PCT_EXITED.add(key)
    persist_7pct_exited_events()
    print(f"ðŸš« Event {event_ticker} marked as 7% exited - no new entries allowed")

def is_event_in_stop_loss_cooldown(event_ticker: str, current_price: Optional[float] = None, cooldown_minutes: float = 180.0) -> bool:
    """
    Check if event was stop-lossed and is still in cooldown period.
    If current_price is provided and price has recovered past original entry price, allow re-entry.
    """
    global EVENT_STOP_LOSSED
    key = event_key(event_ticker)
    if key not in EVENT_STOP_LOSSED:
        return False
    
    stop_loss_data = EVENT_STOP_LOSSED[key]
    
    # Handle old format (just timestamp) - convert to new format
    if isinstance(stop_loss_data, (int, float)):
        stop_loss_data = {"timestamp": stop_loss_data, "entry_price": None}
        EVENT_STOP_LOSSED[key] = stop_loss_data
    elif isinstance(stop_loss_data, datetime):
        stop_loss_data = {"timestamp": stop_loss_data.timestamp(), "entry_price": None}
        EVENT_STOP_LOSSED[key] = stop_loss_data
    elif not isinstance(stop_loss_data, dict):
        # Invalid format, remove it
        del EVENT_STOP_LOSSED[key]
        return False
    
    # Extract timestamp
    stop_loss_time = stop_loss_data.get("timestamp")
    entry_price = stop_loss_data.get("entry_price")
    
    # Handle different timestamp formats
    if isinstance(stop_loss_time, (int, float)):
        timestamp = stop_loss_time
    elif isinstance(stop_loss_time, datetime):
        timestamp = stop_loss_time.timestamp()
    elif isinstance(stop_loss_time, str):
        try:
            dt = datetime.fromisoformat(stop_loss_time.replace('Z', '+00:00'))
            timestamp = dt.timestamp()
        except Exception:
            return False  # Invalid format, assume not in cooldown
    else:
        return False
    
    # âœ… NEW: Check if price has recovered past original entry price (if enabled)
    if ALLOW_STOP_LOSS_PRICE_RECOVERY and current_price is not None and entry_price is not None and entry_price > 0:
        if current_price >= entry_price:
            # Price has recovered past original entry price - allow re-entry
            print(f"âœ… Event {event_ticker} price recovered: {current_price:.2%} >= {entry_price:.2%} (original entry) - allowing re-entry")
            # Remove from stop loss tracking since price has recovered
            del EVENT_STOP_LOSSED[key]
            persist_stop_lossed_events()
            return False  # Not in cooldown anymore
    
    # Check time-based cooldown
    elapsed_minutes = (time.time() - timestamp) / 60.0
    in_cooldown = elapsed_minutes < cooldown_minutes
    
    if in_cooldown:
        remaining_seconds = int((cooldown_minutes - elapsed_minutes) * 60)
        entry_price_str = f" (entry: {entry_price:.2%})" if entry_price is not None else ""
        current_price_str = f", current: {current_price:.2%}" if current_price is not None else ""
        print(f"â³ Event {event_ticker} in stop-loss cooldown: {remaining_seconds}s remaining{entry_price_str}{current_price_str}")
    
    return in_cooldown

def prune_event_locks():
    """Drop event locks that have no corresponding open positions."""
    valid_keys = {
        event_key(p.get("event_ticker"))
        for p in positions
        if p.get("stake", 0) > 0 and not p.get("settled", False)
    }
    stale = {key for key in EVENT_LOCKED_TILL_HEDGE if key not in valid_keys}
    if stale:
        EVENT_LOCKED_TILL_HEDGE.difference_update(stale)
        persist_event_locks()
        print(f"ðŸ”“ Cleared {len(stale)} stale event locks.")

def update_event_lock(event_ticker: str):
    key = event_key(event_ticker)
    if both_sides_open_and_active(event_ticker):
        EVENT_LOCKED_TILL_HEDGE.discard(key)
    else:
        EVENT_LOCKED_TILL_HEDGE.add(key)
    persist_event_locks()

def set_event_neutralization_flags(evt: str):
    is_neut = event_is_neutralized(evt)
    evt_key = event_key(evt)
    for p in positions:
        if event_key(p.get("event_ticker")) == evt_key:
            p["neutralized"] = is_neut

def run_engine(overlaps):

        # âœ… Helper: compute first-entry quantity (NON-HEDGE)
    def compute_first_entry_quantity(kelly_fraction, kalshi_price, odds_prob, capital):
        # Kelly-based dollar allocation (scaled by KELLY_FRACTION)
        kelly_dollars = capital * kelly_fraction * KELLY_FRACTION
        # Respect the stake cap for first entries (MAX_STAKE_PCT)
        max_dollars = capital * MAX_STAKE_PCT
        dollars_for_trade = min(kelly_dollars, max_dollars)
        # Convert dollars into contracts at this price
        qty = max_qty_with_cap(dollars_for_trade, kalshi_price)
        return int(qty) if qty >= 1 else None

    # âœ… Helper: compute hedge quantity (guarantee +ROI both sides)
    # âœ… Helper: compute hedge quantity (guarantee â‰¥ $0 profit both outcomes)
    def compute_hedge_quantity(existing_pos, hedge_price, odds_prob, capital):
        """
        Size the hedge using the actual entry price (kalshi_price) for sizing calculations.
        This ensures sizing matches the price we'll actually pay.
        
        For hedges, we skip Kelly checks - ROI bands ensure combined position profitability.
        Standalone Kelly is meaningless for hedges since we're not making a standalone trade.
        """
        pB = float(hedge_price)  # Use actual entry price (kalshi_price from aggressiveness logic)

        if not (HEDGE_PRICE_MIN <= pB <= HEDGE_PRICE_MAX):
            return None

        # Capital cap - primary constraint for hedges
        dollars_cap = capital * HEDGE_MAX_STAKE_PCT
        max_qty_capital = max_qty_with_cap(dollars_cap, pB)

        # For hedges, skip Kelly check - ROI bands ensure profitability
        # If Kelly is positive, use it for sizing guidance, but don't block if it's negative/low
        # Note: compute_hedge_quantity doesn't have market data, so default to taker (conservative)
        fee_pc = kalshi_fee_per_contract(pB, is_maker=False)
        kelly_h = kelly_yes_with_costs(odds_prob, pB, rt_cost=fee_pc)
        
        if kelly_h >= MIN_KELLY:
            # Kelly is positive - use it for sizing guidance
            kelly_dollars = capital * kelly_h * HEDGE_TRADE_FRACTIONAL_KELLY
            max_qty_kelly = max_qty_with_cap(kelly_dollars, pB)
            # Use the minimum of capital cap and Kelly-based sizing
            max_qty = min(max_qty_capital, max_qty_kelly)
        else:
            # Kelly is negative/low - just use capital cap (ROI bands will ensure profitability)
            max_qty = max_qty_capital

        # Divide by 2 to ensure minimum quantity of 2 contracts (scaling requirement)
        # This ensures we start with at least 1 contracts and scale from there
        return max(1, max_qty // 2)


    global capital_sim, positions, wins, losses, realized_pnl

    # âœ… ADD THIS HERE â€” so it's available anywhere inside run_engine()
    def _find_market_for(label: str, kalshi_markets=None):
        """
        Match odds-feed team name (label) to Kalshi market.
        Uses ticker suffix (e.g. '-AFA', '-LIU') and yes_sub_title ('Air Force', 'LIU')
        for robust mapping.

        Assumes exactly two YES markets per event (home/away moneyline). If Kalshi
        introduces alternates (e.g., spreads), callers must guard accordingly.
        """
        if not kalshi_markets:
            return None

        label_norm = (label or "").lower().strip()
        label_tokens = normalize_tokens(label_norm)

        # Build a map of Kalshi market abbreviations and sub_titles
        for m in kalshi_markets:
            yes_sub = (m.get("yes_sub_title") or "").lower()
            ticker = m.get("ticker", "").lower()

            # Extract final team code from ticker suffix
            # Example: 'KXNCAAMBGAME-25NOV11LIUAFA-AFA' â†’ 'afa'
            ticker_suffix = ticker.split("-")[-1] if "-" in ticker else ""
            ticker_suffix = ticker_suffix.strip().lower()

            yes_tokens = normalize_tokens(yes_sub)
            yes_tokens.add(ticker_suffix)  # âœ… include suffix as token

            # bidirectional match between label + Kalshi tokens
            if label_tokens & yes_tokens or yes_tokens & label_tokens:
                return m

        return None

    print(f"\nðŸ” Evaluating {len(overlaps)} overlapping matches...")

    # Determine balance source
    if PLACE_LIVE_KALSHI_ORDERS == "YES":
        capital = get_kalshi_balance()
        print(f"ðŸ’° Using LIVE Kalshi balance for Kelly sizing: ${capital:.2f}")
    else:
       capital = capital_sim

    # Safety check: ensure capital is valid
    if capital is None or capital <= 0:
        print(f"âš ï¸ Invalid capital ({capital}) â€” skipping engine run")
        return

    if not overlaps:
        print("No new overlaps â€” continuing to monitor and will rescan.")
        return  # (we keep this return, but ensure main loop still runs quickly)

    for match in overlaps:
        ticker = match["ticker"]
        ticker_key = event_key(ticker)
        home = match["home"]
        away = match["away"]

        # âœ… Always refresh Kalshi markets in real time
        kalshi = get_kalshi_markets(ticker, force_live=True)
        # Handle rate limiting (None) or empty markets
        if not kalshi:  # None (rate limited) or [] (no markets)
            print(f"âš ï¸ No Kalshi markets returned for {ticker}. Retrying next loop.")
            continue

        match["kalshi"] = kalshi

        # âœ… Volume filter: Skip games with insufficient trading volume
        total_volume = get_event_total_volume(ticker, markets=kalshi)
        if total_volume is None:
            print(f"âš ï¸ Skipping {match['match']} â€” could not determine trading volume.")
            continue
        if total_volume < MIN_TRADING_VOLUME_PER_EVENT:
            print(f"ðŸ“Š Skipping {match['match']} â€” volume {total_volume:,} < {MIN_TRADING_VOLUME_PER_EVENT:,} threshold (BLOCKED)")
            continue
        if VERBOSE:
            print(f"âœ… {match['match']} â€” volume {total_volume:,} meets threshold ({MIN_TRADING_VOLUME_PER_EVENT:,})")

        odds_snapshot = match.get("odds_feed") or {}
        home_prob = odds_snapshot.get("home_prob")
        away_prob = odds_snapshot.get("away_prob")
        odds_last_ts = odds_snapshot.get("last_update_ts")
        score_snapshot = odds_snapshot.get("score_snapshot")
        period_clock = odds_snapshot.get("period_clock")

        if home_prob is None or away_prob is None:
            print(f"âš ï¸ Skipping {match['match']} â€” odds-feed probabilities unavailable.")
            continue

        # âœ… Check if odds have been updated on this turn before allowing trades
        # Compare both timestamp AND odds values to prevent duplicate trades when odds are unchanged
        odds_updated = False
        if odds_last_ts is not None and home_prob is not None and away_prob is not None:
            last_processed = _LAST_PROCESSED_ODDS.get(ticker_key)
            
            if last_processed is None:
                # First time processing this event - allow trading
                odds_updated = True
                _LAST_PROCESSED_ODDS[ticker_key] = {
                    "timestamp": odds_last_ts,
                    "home_prob": home_prob,
                    "away_prob": away_prob
                }
            else:
                # Check if timestamp is newer or equal (odds were freshly fetched in this cycle)
                last_ts = last_processed.get("timestamp", 0)
                timestamp_newer_or_equal = odds_last_ts >= last_ts
                timestamp_newer = odds_last_ts > last_ts
                
                # Check if odds values have changed (with tolerance for floating point)
                last_home = last_processed.get("home_prob")
                last_away = last_processed.get("away_prob")
                home_changed = (last_home is None or abs(home_prob - last_home) > ODDS_CHANGE_TOLERANCE)
                away_changed = (last_away is None or abs(away_prob - last_away) > ODDS_CHANGE_TOLERANCE)
                odds_values_changed = home_changed or away_changed
                
                # Odds are considered updated if:
                # (1) Timestamp is newer (different refresh cycle) - always allow (freshly fetched)
                # (2) Timestamp matches (same refresh cycle) - allow (same refresh, can process both sides)
                # (3) Timestamp is older - block (stale data from previous cycle)
                if timestamp_newer_or_equal:
                    # Timestamp is newer or same - this is a fresh or current refresh cycle
                    # Allow trading (can process both sides in same cycle)
                    odds_updated = True
                    _LAST_PROCESSED_ODDS[ticker_key] = {
                        "timestamp": odds_last_ts,
                        "home_prob": home_prob,
                        "away_prob": away_prob
                    }
                else:
                    # Timestamp is older - stale data from previous cycle, block
                    odds_updated = False
                    if VERBOSE:
                        time_since_update = time.time() - odds_last_ts
                        time_since_processed = time.time() - last_ts
                        print(f"â¸ï¸ Skipping {match['match']} â€” odds timestamp is older than last processed "
                              f"(last processed: {time_since_processed:.1f}s ago, current: {time_since_update:.1f}s ago, "
                              f"values: home={home_prob:.4f}â‰ˆ{last_home:.4f}, away={away_prob:.4f}â‰ˆ{last_away:.4f})")
        else:
            # No timestamp or odds available - allow trading but warn
            if VERBOSE:
                print(f"âš ï¸ {match['match']} â€” no odds timestamp/values available, allowing trades (may be stale)")
            odds_updated = True
        
        # Set flag to skip new entries if odds haven't updated (hedging will bypass this)
        match["_skip_new_entries"] = not odds_updated

        # Stale odds check removed - user wants to use odds even if stale
        
        # Format score and time info for display
        score_time_info = ""
        if score_snapshot:
            score_time_info += f" | Score: {score_snapshot}"
        if period_clock:
            score_time_info += f" | Clock: {period_clock}"

        # Show odds-API probs for this overlap
        # === 2b. Market comparison table (REPLACE this whole block) ===
        if PRINT_MARKET_TABLE:
            print(f"\nðŸŽ¾ {match['match']} ({ticker})")
            print("")
            print(f"{'Side':<25} {'Odds Prob':>14} {'Kalshi Price':>12} {'EV (% Ret)':>14} {'EV($/ct)':>10}")
            print("-" * 80)

            for label, prob in [(home, home_prob), (away, away_prob)]:
                # ðŸ”’ Hard event lock: stop first-side repeats before hedge
                if ticker_key in EVENT_LOCKED_TILL_HEDGE and not event_is_neutralized(ticker):
                    if VERBOSE:
                        print(f"ðŸš« Event {ticker} locked â€” first-side already open, waiting for hedge.")
                    continue

                m = _find_market_for(label, kalshi)
                if not m:
                    continue

                yes_bid = format_price(m.get("yes_bid"))
                yes_ask = format_price(m.get("yes_ask"))
                if yes_bid is None and yes_ask is None:
                    continue

                yes_price = (
                    (yes_bid + yes_ask) / 2.0
                    if (yes_bid is not None and yes_ask is not None)
                    else (yes_ask if yes_ask is not None else yes_bid)
                )

                yb_raw = m.get("yes_bid")
                ya_raw = m.get("yes_ask")
                spread = (
                    max(0.0, ((ya_raw or 0) - (yb_raw or 0)) / 100.0)
                    if (ya_raw is not None and yb_raw is not None)
                    else 0.0
                )

                edge_yes = ((prob - yes_price) / max(yes_price, 1e-6)) - (0.5 * spread) / max(yes_price, 1e-6)
                ev_yes = ev_per_contract(prob, yes_price)

                print(f"{label:<25} {prob:>14.2%} {yes_price:>12.2%} {edge_yes:>10.2%} {ev_yes:>10.3f}")

            print("-" * 78)



        # Identify Kalshi YES markets for both sides
        # âœ… Identify Kalshi YES markets for both sides (alias-aware)
        home_market = _find_market_for(home, kalshi)
        away_market = _find_market_for(away, kalshi)

        if not home_market or not away_market:
            # Normalized debug view (uses the same canonical tokenizer for both)
            home_norm = list(normalize_tokens(home))
            away_norm = list(normalize_tokens(away))
            kalshi_titles = [list(normalize_tokens(m.get("yes_sub_title"))) for m in kalshi]

            print(f"âš ï¸ Skipping {match['match']} â€” could not align both Kalshi markets.")
            print(f"    â†’ home_norm={home_norm}, away_norm={away_norm}, kalshi_titles={kalshi_titles}")
            continue

        # === Vulture Finisher Exit Logic ===
        # Process exits for all open positions on this event
            ticker_key = event_key(ticker)
            evt_norm = normalize_event_ticker(ticker)
            event_positions = [
                p for p in positions
                if normalize_event_ticker(p.get("event_ticker", "")) == evt_norm
                and not p.get("settled", False)
            ]
        
        # Clean up pending exit tracker if position is gone
        global _exit_orders_pending
        for t in list(_exit_orders_pending):
            pos = next((p for p in event_positions if p.get("market_ticker") == t), None)
            if not pos or pos.get("stake", 0) <= 0:
                _exit_orders_pending.discard(t)
        
        timestamp = now_utc()
        home_ask = safe_float(home_market.get("yes_ask"))
        away_ask = safe_float(away_market.get("yes_ask"))
        home_bid = safe_float(home_market.get("yes_bid"))
        away_bid = safe_float(away_market.get("yes_bid"))
        
        for pos in event_positions:
            market_ticker = pos.get("market_ticker")
            stake = pos.get("stake", 0)
            if stake <= 0:
                    continue
            
            # Prevent double-submission
            if market_ticker in _exit_orders_pending:
                    continue
            
            # Get entry info
            entry_data = _active_positions.get(market_ticker)
            if not entry_data:
                # Fallback to position data
                entry_data = {
                    'price': pos.get("entry_price", 0),
                    'time': parse_iso_utc(pos.get("entry_time", "")) or timestamp
                }
            
            entry_price = entry_data['price']
            entry_time = entry_data['time']
            if isinstance(entry_time, str):
                entry_time = parse_iso_utc(entry_time) or timestamp
            
            # Determine current bid price
            if market_ticker == home_market.get("ticker"):
                current_bid = home_bid
            elif market_ticker == away_market.get("ticker"):
                current_bid = away_bid
            else:
                continue
            
            if current_bid is None:
                continue
            
            # Current Profit
            profit_pct = (current_bid - entry_price) / entry_price if entry_price > 0 else 0
            minutes_held = (timestamp - entry_time).total_seconds() / 60.0 if isinstance(entry_time, datetime) else 0
            
            # Grace Period: Hold for at least min_hold_minutes to survive initial volatility/spread
            # Unless we hit the Settlement Threshold (Winning Big)
            if minutes_held < min_hold_minutes and current_bid < SETTLEMENT_HOLD_THRESHOLD:
                continue
            
            # A. THE FINISHER (Hold to Settlement)
            # If we are deep ITM (> 88c), don't sell. Let it expire at $1.00.
            if current_bid > SETTLEMENT_HOLD_THRESHOLD:
                if VERBOSE:
                    print(f"ðŸ† FINISHER: Holding {market_ticker} to settlement (price: {current_bid:.2%} > {SETTLEMENT_HOLD_THRESHOLD:.2%})")
                continue
            
            # B. Stop Loss
            if current_bid < (entry_price - STOP_LOSS_AMT):
                print(f"ðŸ›‘ STOP LOSS: {market_ticker} | Entry: {entry_price:.2%} â†’ Current: {current_bid:.2%} (Loss: {entry_price - current_bid:.2%})")
                sell_price = max(0.01, current_bid - (2 * TICK))
                try:
                    sell_resp = prepare_kalshi_order(
                        market_ticker=market_ticker,
                        side="yes",
                        price=sell_price,
                        quantity=int(stake),
                        action="sell"
                    )
                    sell_order_id, sell_client_oid = _extract_order_id(sell_resp)
                    if sell_order_id:
                        sell_status, sell_filled_qty = wait_for_fill_or_cancel(
                            sell_order_id,
                            client_order_id=sell_client_oid,
                            timeout_s=ORDER_FILL_TIME,
                            poll_s=1.0,
                            expected_count=int(stake),
                            require_full=False,
                            verify_ticker=market_ticker,
                            verify_side="yes"
                        )
                        if sell_filled_qty > 0:
                            pos["stake"] = max(0, pos.get("stake", 0) - sell_filled_qty)
                            if pos["stake"] <= 0:
                                pos["settled"] = True
                            _exit_orders_pending.discard(market_ticker)
                            save_positions()
                                except Exception as e:
                    print(f"âš ï¸ Error executing stop-loss: {e}")
                continue
            
            # C. Time Stop
            if TIME_STOP_ENABLED and minutes_held > TIME_STOP_MINUTES:
                print(f"â° TIME STOP: {market_ticker} | Held for {minutes_held:.1f} minutes (limit: {TIME_STOP_MINUTES:.1f})")
                sell_price = max(0.01, current_bid - (2 * TICK))
                try:
                    sell_resp = prepare_kalshi_order(
                        market_ticker=market_ticker,
                        side="yes",
                        price=sell_price,
                        quantity=int(stake),
                        action="sell"
                    )
                    sell_order_id, sell_client_oid = _extract_order_id(sell_resp)
                    if sell_order_id:
                        sell_status, sell_filled_qty = wait_for_fill_or_cancel(
                            sell_order_id,
                            client_order_id=sell_client_oid,
                            timeout_s=ORDER_FILL_TIME,
                            poll_s=1.0,
                            expected_count=int(stake),
                            require_full=False,
                            verify_ticker=market_ticker,
                            verify_side="yes"
                        )
                        if sell_filled_qty > 0:
                            pos["stake"] = max(0, pos.get("stake", 0) - sell_filled_qty)
                            if pos["stake"] <= 0:
                                pos["settled"] = True
                            _exit_orders_pending.discard(market_ticker)
                            save_positions()
                                        except Exception as e:
                    print(f"âš ï¸ Error executing time stop: {e}")
                continue
            
            # D. Standard Profit Target
            # Sell if price hits target AND we haven't reached "Finisher" zone
            if current_bid >= (entry_price + PROFIT_TARGET):
                # One last check: Are we actually up significantly? (Min Profit Check)
                if profit_pct > MIN_PROFIT_PCT_TO_SELL:
                    print(f"âœ… PROFIT TARGET: {market_ticker} | Entry: {entry_price:.2%} â†’ Current: {current_bid:.2%} (Profit: {current_bid - entry_price:.2%})")
                    sell_price = max(0.01, current_bid - (2 * TICK))
                    try:
                                    sell_resp = prepare_kalshi_order(
                            market_ticker=market_ticker,
                                        side="yes",
                            price=sell_price,
                            quantity=int(stake),
                                        action="sell"
                                    )
                                    sell_order_id, sell_client_oid = _extract_order_id(sell_resp)
                                    if sell_order_id:
                                        sell_status, sell_filled_qty = wait_for_fill_or_cancel(
                                            sell_order_id,
                                            client_order_id=sell_client_oid,
                                            timeout_s=ORDER_FILL_TIME,
                                            poll_s=1.0,
                                expected_count=int(stake),
                                            require_full=False,
                                verify_ticker=market_ticker,
                                            verify_side="yes"
                                        )
                                        if sell_filled_qty > 0:
                                pos["stake"] = max(0, pos.get("stake", 0) - sell_filled_qty)
                                if pos["stake"] <= 0:
                                    pos["settled"] = True
                                _exit_orders_pending.discard(market_ticker)
                                            save_positions()
                                except Exception as e:
                        print(f"âš ï¸ Error executing profit target: {e}")
                                continue

        # === Vulture Finisher Entry Logic ===
        # Evaluate both sides
        # Evaluate both sides â€“ now allow YES entries on both home and away
        rt_ev = None
        
        # Format score/time info for match header
        score_time_str = ""
        if score_time_info:
            if "Score:" in score_time_info:
                score_part = score_time_info.split("Score:")[1].split("|")[0].strip()
                score_time_str += f"Score: {score_part} "
            if "Clock:" in score_time_info:
                clock_part = score_time_info.split("Clock:")[1].strip()
                score_time_str += f"| {clock_part}"
        
        # Print match header once
        match_header = f"{match['match']}"
        if score_time_str:
            match_header += f" ({score_time_str})"
        print(f"\n{'â•' * 120}")
        print(f"ðŸ“Š {match_header}")
        print(f"{'â•' * 120}")
        
        # === Vulture Finisher Entry Logic ===
        # Scan both teams to detect wounded state
        home_ticker = home_market.get("ticker") if home_market else None
        away_ticker = away_market.get("ticker") if away_market else None
        home_ask = safe_float(home_market.get("yes_ask")) if home_market else None
        away_ask = safe_float(away_market.get("yes_ask")) if away_market else None
        
        timestamp = now_utc()
        
        # Scan both teams for wounded detection
        for ticker_mkt, ask_price, opp_ticker_mkt, opp_ask_price in [
            (home_ticker, home_ask, away_ticker, away_ask),
            (away_ticker, away_ask, home_ticker, home_ask)
        ]:
            if not ticker_mkt or ask_price is None:
                continue

            state = _game_state[ticker_mkt]
            event_id = extract_event_id(ticker_mkt)
            
            # Initialize game start time (use first ticker seen for this event)
            if state['game_start_time'] is None:
                state['game_start_time'] = timestamp
            
            # Time Filter - check from game start
            elapsed = (timestamp - state['game_start_time']).total_seconds() / 60.0
            if elapsed > MAX_GAME_TIME_ELAPSED_MIN:
                continue

            # Track Start Price (first price seen for this ticker)
            if state['start_price'] is None:
                state['start_price'] = ask_price
                state['high_water_mark'] = ask_price
            
            # Filter: Only trade games that started competitive (Coin Flip Range)
            if not (CF_MIN_START_PRICE <= state['start_price'] <= CF_MAX_START_PRICE):
                continue

            # Update high water mark
            if ask_price > state['high_water_mark']:
                state['high_water_mark'] = ask_price
                state['high_water_time'] = timestamp
            
            # Check for Wounded State (Drop from START PRICE)
            drop = state['start_price'] - ask_price
            
            # If price recovers above start_price, reset plateau tracking
            if ask_price >= state['start_price']:
                state['plateau_start_time'] = None
                state['plateau_base_price'] = None
                continue
            
            # Check if wounded enough (drop > 20c from start)
            if drop < DROP_TRIGGER:
                # Not wounded enough - reset plateau tracking
                state['plateau_start_time'] = None
                state['plateau_base_price'] = None
                continue
            
            # WOUNDED (Drop > 20c from start) - Start tracking plateau
            wounded_threshold = state['start_price'] - DROP_TRIGGER
            
            # Ensure price stays below wounded threshold during plateau
            if ask_price > wounded_threshold:
                # Price recovered above wounded threshold - reset plateau
                state['plateau_start_time'] = None
                state['plateau_base_price'] = None
                continue
            
            # Start tracking plateau if not already tracking
            if state['plateau_start_time'] is None:
                state['plateau_start_time'] = timestamp
                state['plateau_base_price'] = ask_price
                continue
            
            # Check if price is still within tolerance (plateau stability)
            if state['plateau_base_price'] is not None:
                deviation = abs(ask_price - state['plateau_base_price'])
                if deviation > PLATEAU_TOLERANCE:
                    # Price moved outside tolerance - reset plateau
                    state['plateau_start_time'] = timestamp
                    state['plateau_base_price'] = ask_price
                    continue
            
            # Check Duration (Plateau must last for required time)
            plateau_duration = (timestamp - state['plateau_start_time']).total_seconds() / 60.0
            
            if plateau_duration >= PLATEAU_DURATION_MIN:
                # CONFIRMED BLEEDING - STRIKE!
                
                # One-Shot Rule per GAME
                if event_id in _traded_games:
                    continue
                
                target_ticker = opp_ticker_mkt
                target_price = opp_ask_price
                
                if not target_ticker or target_price is None:
                    continue
                
                # Get the target market
                target_market = home_market if target_ticker == home_ticker else away_market
                if not target_market:
                    continue
                
                # Filters
                if not (UNIVERSE_MIN_PRICE <= target_price <= UNIVERSE_MAX_PRICE):
                    continue
                if target_price > 0.85:
                    continue  # Verified Safety Filter
                
                # Validations
                if len([p for p in positions if not p.get("settled", False)]) >= MAX_POSITIONS:
                    continue
                
                # Check if we already have a position on this market
                existing_pos = next(
                    (p for p in positions
                     if p.get("market_ticker") == target_ticker
                     and not p.get("settled", False)),
                    None
                )
                if existing_pos:
                    continue  # Already have position
                
                # Execute entry
                cash = get_kalshi_balance() if PLACE_LIVE_KALSHI_ORDERS == "YES" else capital
                if cash <= 0:
                continue

                val = cash * POSITION_SIZE_PCT
                cost_per_contract = target_price + kalshi_fee_per_contract(target_price, is_maker=False)
                if cost_per_contract <= 0:
                        continue

                quantity = int(val / cost_per_contract)
                if quantity <= 0:
                    continue
                
                # Place order
                print(f"ðŸ¦… VULTURE STRIKE: {match['match']} | Wounded: {ticker_mkt} (drop: {drop:.2%}) | Buying: {target_ticker} @ {target_price:.2%} | Qty: {quantity}")
                
                try:
                    resp = safe_prepare_kalshi_order(
                        market_ticker=target_ticker,
                        side="yes",
                        price=target_price,
                        quantity=quantity,
                        max_total_contracts=quantity,
                        action="buy"
                    )
                    
                    order_id, client_oid = _extract_order_id(resp)
                    if not order_id:
                        print(f"âš ï¸ Could not parse order_id for {target_ticker}")
                continue
            
                    # Wait for fill
                    status, filled_qty = wait_for_fill_or_cancel(
                        order_id,
                        client_order_id=client_oid,
                        timeout_s=ORDER_FILL_TIME,
                        poll_s=1.0,
                        expected_count=quantity,
                        require_full=False,
                        verify_ticker=target_ticker,
                        verify_side="yes"
                    )
                    
                    if filled_qty > 0:
                        # Create position record
                        side_name = home if target_ticker == home_ticker else away
                        position = {
                            "match": match["match"],
                            "side": "yes",
                            "side_name": side_name,
                            "event_ticker": ticker.upper(),
                            "event_id": match.get("id"),
                            "market_ticker": target_ticker,
                            "entry_price": target_price,
                            "odds_prob": home_prob if target_ticker == home_ticker else away_prob,
                            "entry_time": timestamp.isoformat(),
                            "effective_entry": target_price,
                            "max_price": target_price,
                            "stake": filled_qty,
                            "peak_pnl_pct": 0.0,
                            "peak_hit_ts": None,
                            "breakeven_armed": False,
                            "next_exit_after": timestamp.isoformat(),
                            "yes_sub_title": target_market.get("yes_sub_title"),
                        }
                        
                        commit_trade_and_persist(position, order_id, filled_qty)
                        
                        # Track in _active_positions
                        _active_positions[target_ticker] = {
                            'price': target_price,
                            'time': timestamp
                        }
                        _traded_games.add(event_id)
                        
                        # Consume Signal - reset state for this ticker
                        state['high_water_mark'] = ask_price
                        state['plateau_start_time'] = None
                        state['plateau_base_price'] = None
                        
                        print(f"âœ… VULTURE ENTRY FILLED: {match['match']} | {target_ticker} x{filled_qty} @ {target_price:.2%}")
                    else:
                        print(f"âš ï¸ Vulture entry order not filled: {status}")
                except Exception as e:
                    print(f"âš ï¸ Error executing vulture entry: {e}")
                    import traceback
                    traceback.print_exc()
        
        # Close table for this match
        print(f"{'â•' * 120}\n")
        
        # Old entry loop removed - replaced with Vulture Finisher above
        # Continue to next match

    # === Exit logic with Profit Protection ===
    # === Profit Protection: Max Profit Detection + Trailing Stop (Pyramiding-Aware) ===
    
    # Create mapping from event_ticker to match data for period_clock and match_name lookup
    event_to_match = {}
    for match in overlaps:
        ticker = match.get("ticker")
        if ticker:
            evt_key = event_key(ticker)
            event_to_match[evt_key] = {
                "match_name": match.get("match"),
                "period_clock": (match.get("odds_feed") or {}).get("period_clock")
            }
    
    new_positions = []
    positions_to_close = []
    positions_to_close_keys = set()
    
    # Group positions by event (including already-flagged closes so we can retry/finish them)
    events_dict = {}
    for pos in positions:
        if pos.get("settled", False):
            continue
        # âœ… Skip positions that are already being closed (prevent double-selling)
        if pos.get("closing_in_progress", False):
            continue
        evt_key = event_key(pos.get("event_ticker"))
        if evt_key not in events_dict:
            events_dict[evt_key] = []
        events_dict[evt_key].append(pos)
    
    # Get market data for all events needing checks
    kalshi_markets_cache = {}
    for evt_key in events_dict.keys():
        # Get event ticker from first position in event
        if events_dict[evt_key]:
            evt_ticker_str = events_dict[evt_key][0].get("event_ticker")
            if evt_ticker_str:
                try:
                    mkts = get_kalshi_markets(evt_ticker_str, force_live=True)
                    if mkts:
                        kalshi_markets_cache[evt_key] = mkts
                except Exception as e:
                    if VERBOSE:
                        print(f"âš ï¸ Could not fetch markets for profit protection check on {evt_ticker_str}: {e}")
    
    # Check each event for profit protection
    for evt_key, event_positions in events_dict.items():
        # Find the two sides (markets)
        markets_by_ticker = {}
        for pos in event_positions:
            mkt_ticker = pos.get("market_ticker")
            if mkt_ticker not in markets_by_ticker:
                markets_by_ticker[mkt_ticker] = []
            markets_by_ticker[mkt_ticker].append(pos)
        
        market_tickers = list(markets_by_ticker.keys())

        # If this event is already in closing state (e.g., partial fills, restart), re-queue closes now
        event_has_closing_flag = any(p.get("closing_in_progress", False) for p in event_positions)
        if event_has_closing_flag:
            markets = kalshi_markets_cache.get(evt_key, [])
            # Require fresh market data and both sides to justify selling; otherwise clear flag and keep evaluating
            if len(market_tickers) >= 2 and markets:
                side_A_ticker = market_tickers[0]
                side_B_ticker = market_tickers[1]
                side_A_market = next((m for m in markets if m.get("ticker") == side_A_ticker), None)
                side_B_market = next((m for m in markets if m.get("ticker") == side_B_ticker), None)
                side_A_bid = format_price(side_A_market.get("yes_bid")) if side_A_market else None
                side_B_bid = format_price(side_B_market.get("yes_bid")) if side_B_market else None

                if side_A_bid is not None and side_B_bid is not None:
                    side_A_sell_price = max(0.01, side_A_bid - TICK)
                    side_B_sell_price = max(0.01, side_B_bid - TICK)
                    
                    # Get ask prices for spread check
                    side_A_ask = format_price(side_A_market.get("yes_ask")) if side_A_market else None
                    side_B_ask = format_price(side_B_market.get("yes_ask")) if side_B_market else None
                    
                    # Get match data for time restrictions
                    match_data = event_to_match.get(evt_key, {})
                    period_clock = match_data.get("period_clock")
                    match_name = match_data.get("match_name")
                    
                    check_result = check_profit_protection(
                        event_positions[0].get("event_ticker", ""),
                        markets_by_ticker.get(side_A_ticker, []),
                        markets_by_ticker.get(side_B_ticker, []),
                        side_A_ticker,
                        side_B_ticker,
                        side_A_sell_price,
                        side_B_sell_price,
                        side_A_ask=side_A_ask,
                        side_B_ask=side_B_ask,
                        side_A_bid=side_A_bid,
                        side_B_bid=side_B_bid,
                        match_name=match_name
                    )
                    if not check_result.get("should_close", False):
                        # Clear stale closing flags; keep positions active
                        for pos in event_positions:
                            pos["closing_in_progress"] = False
                            pos.pop("closing_check_result", None)
                            pos.pop("closing_initiated_at", None)
                        new_positions.extend(event_positions)
                        continue
                    
                    # Check if this is a partial exit
                    partial_exit_side = check_result.get("partial_exit_side")
                    if partial_exit_side:
                        # Partial exit: only mark the specified side for closing
                        side_to_close_ticker = side_A_ticker if partial_exit_side == "A" else side_B_ticker
                        positions_to_close_list = markets_by_ticker.get(side_to_close_ticker, [])
                        positions_to_keep_list = markets_by_ticker.get(side_B_ticker, []) if partial_exit_side == "A" else markets_by_ticker.get(side_A_ticker, [])
                        
                        # Mark ALL positions on the side to close (in case of multiple entries from pyramiding)
                        for pos in positions_to_close_list:
                            if pos.get("market_ticker") not in positions_to_close_keys:
                                pos["closing_in_progress"] = True
                                pos["closing_check_result"] = check_result
                                pos["closing_initiated_at"] = now_utc().isoformat()
                                positions_to_close.append(pos)
                                positions_to_close_keys.add(pos.get("market_ticker"))
                        
                        # Keep positions on the other side active
                        new_positions.extend(positions_to_keep_list)
                    else:
                        # Full exit: mark all positions for closing
                        for pos in event_positions:
                            if pos.get("market_ticker") not in positions_to_close_keys:
                                pos["closing_in_progress"] = True
                                pos["closing_check_result"] = check_result
                                pos["closing_initiated_at"] = now_utc().isoformat()
                                positions_to_close.append(pos)
                                positions_to_close_keys.add(pos.get("market_ticker"))
                else:
                    # Missing market data - clear closing flags and keep positions active
                    for pos in event_positions:
                        pos["closing_in_progress"] = False
                        pos.pop("closing_check_result", None)
                        pos.pop("closing_initiated_at", None)
                    new_positions.extend(event_positions)
        else:
            # No closing flag - evaluate positions normally
            markets = kalshi_markets_cache.get(evt_key, [])
            if len(market_tickers) < 2 or not markets:
                # Missing market data - keep positions active
                new_positions.extend(event_positions)
                continue
            
            side_A_ticker = market_tickers[0]
            side_B_ticker = market_tickers[1]
            side_A_market = next((m for m in markets if m.get("ticker") == side_A_ticker), None)
            side_B_market = next((m for m in markets if m.get("ticker") == side_B_ticker), None)
            side_A_bid = format_price(side_A_market.get("yes_bid")) if side_A_market else None
            side_B_bid = format_price(side_B_market.get("yes_bid")) if side_B_market else None
            
            if side_A_bid is None or side_B_bid is None:
                # Missing bid data - keep positions active
                new_positions.extend(event_positions)
                continue
            
            side_A_sell_price = max(0.01, side_A_bid - TICK)
            side_B_sell_price = max(0.01, side_B_bid - TICK)
            
            # Get ask prices for spread check
            side_A_ask = format_price(side_A_market.get("yes_ask")) if side_A_market else None
            side_B_ask = format_price(side_B_market.get("yes_ask")) if side_B_market else None
            
            # Get match data for time restrictions
            match_data = event_to_match.get(evt_key, {})
            period_clock = match_data.get("period_clock")
            match_name = match_data.get("match_name")
            
            check_result = check_profit_protection(
                event_positions[0].get("event_ticker", ""),
                markets_by_ticker.get(side_A_ticker, []),
                markets_by_ticker.get(side_B_ticker, []),
                side_A_ticker,
                side_B_ticker,
                side_A_sell_price,
                side_B_sell_price,
                side_A_ask=side_A_ask,
                side_B_ask=side_B_ask,
                side_A_bid=side_A_bid,
                side_B_bid=side_B_bid,
                match_name=match_name
            )
            
            if check_result.get("should_close", False):
                # Mark positions for closing
                partial_exit_side = check_result.get("partial_exit_side")
                if partial_exit_side:
                    # Partial exit
                    side_to_close_ticker = side_A_ticker if partial_exit_side == "A" else side_B_ticker
                    positions_to_close_list = markets_by_ticker.get(side_to_close_ticker, [])
                    positions_to_keep_list = markets_by_ticker.get(side_B_ticker, []) if partial_exit_side == "A" else markets_by_ticker.get(side_A_ticker, [])
                    
                    for pos in positions_to_close_list:
                        if pos.get("market_ticker") not in positions_to_close_keys:
                            pos["closing_in_progress"] = True
                            pos["closing_check_result"] = check_result
                            pos["closing_initiated_at"] = now_utc().isoformat()
                            positions_to_close.append(pos)
                            positions_to_close_keys.add(pos.get("market_ticker"))
                    
                    new_positions.extend(positions_to_keep_list)
                else:
                    # Full exit
                    for pos in event_positions:
                        if pos.get("market_ticker") not in positions_to_close_keys:
                            pos["closing_in_progress"] = True
                            pos["closing_check_result"] = check_result
                            pos["closing_initiated_at"] = now_utc().isoformat()
                            positions_to_close.append(pos)
                            positions_to_close_keys.add(pos.get("market_ticker"))
            else:
                # Keep positions active
                new_positions.extend(event_positions)
    
    # Process positions to close
    for pos in positions_to_close:
        if pos.get("settled", False):
            continue
        
        market_ticker = pos.get("market_ticker")
        if not market_ticker:
            continue
        
        # Get current market data
        evt_key = event_key(pos.get("event_ticker"))
        markets = kalshi_markets_cache.get(evt_key, [])
        if not markets:
            try:
                evt_ticker_str = pos.get("event_ticker")
                if evt_ticker_str:
                    markets = get_kalshi_markets(evt_ticker_str, force_live=True)
                    if markets:
                        kalshi_markets_cache[evt_key] = markets
            except Exception as e:
                if VERBOSE:
                    print(f"âš ï¸ Could not fetch markets for closing position {market_ticker}: {e}")
                continue
        
        market = next((m for m in markets if m.get("ticker") == market_ticker), None)
        if not market:
            if VERBOSE:
                print(f"âš ï¸ Could not find market {market_ticker} for closing position")
            continue
        
        current_bid = format_price(market.get("yes_bid"))
        if current_bid is None:
            if VERBOSE:
                print(f"âš ï¸ No bid available for {market_ticker}, skipping close")
            continue
        
        entry_price = pos.get("entry_price", 0)
        entry_time_str = pos.get("entry_time")
        entry_time = datetime.fromisoformat(entry_time_str) if entry_time_str else None
        timestamp = now_utc()
        
        if entry_price <= 0 or entry_time is None:
            if VERBOSE:
                print(f"âš ï¸ Invalid entry data for {market_ticker}, skipping close")
            continue
        
        # Current Profit
        profit_pct = (current_bid - entry_price) / entry_price if entry_price > 0 else 0
        minutes_held = (timestamp - entry_time).total_seconds() / 60.0 if isinstance(entry_time, datetime) else 0
        
        # Grace Period: Hold for at least min_hold_minutes to survive initial volatility/spread
        # Unless we hit the Settlement Threshold (Winning Big)
        if minutes_held < min_hold_minutes and current_bid < SETTLEMENT_HOLD_THRESHOLD:
            continue
        
        # A. THE FINISHER (Hold to Settlement)
        # If we are deep ITM (> 88c), don't sell. Let it expire at $1.00.
        if current_bid > SETTLEMENT_HOLD_THRESHOLD:
            if VERBOSE:
                print(f"ðŸ† FINISHER: Holding {market_ticker} to settlement (price: {current_bid:.2%} > {SETTLEMENT_HOLD_THRESHOLD:.2%})")
            continue
        
        # B. Stop Loss
        if current_bid < (entry_price - STOP_LOSS_AMT):
            print(f"ðŸ›‘ STOP LOSS: {market_ticker} | Entry: {entry_price:.2%} â†’ Current: {current_bid:.2%} (Loss: {entry_price - current_bid:.2%})")
            sell_price = max(0.01, current_bid - (2 * TICK))
            try:
                sell_resp = prepare_kalshi_order(
                    market_ticker=market_ticker,
                    side="yes",
                    price=sell_price,
                    quantity=pos.get("stake", 0),
                    action="sell"
                )
                if sell_resp:
                    order_id, _ = _extract_order_id(sell_resp)
                    if order_id:
                        status, filled_qty = wait_for_fill_or_cancel(
                            order_id,
                            timeout_s=ORDER_FILL_TIME,
                            poll_s=1.0,
                            expected_count=pos.get("stake", 0),
                            require_full=False
                        )
                        if filled_qty > 0:
                            pos["stake"] = filled_qty
                            pos["settled"] = True
                            print(f"âœ… STOP LOSS FILLED: {market_ticker} x{filled_qty} @ {sell_price:.2%}")
            except Exception as e:
                print(f"âš ï¸ Error executing stop loss for {market_ticker}: {e}")
            continue
        
        # C. Profit Target
        if current_bid >= (entry_price + PROFIT_TARGET):
            print(f"ðŸ’° PROFIT TARGET: {market_ticker} | Entry: {entry_price:.2%} â†’ Current: {current_bid:.2%} (Profit: {current_bid - entry_price:.2%})")
            sell_price = max(0.01, current_bid - (2 * TICK))
            try:
                sell_resp = prepare_kalshi_order(
                    market_ticker=market_ticker,
                    side="yes",
                    price=sell_price,
                    quantity=pos.get("stake", 0),
                    action="sell"
                )
                if sell_resp:
                    order_id, _ = _extract_order_id(sell_resp)
                    if order_id:
                        status, filled_qty = wait_for_fill_or_cancel(
                            order_id,
                            timeout_s=ORDER_FILL_TIME,
                            poll_s=1.0,
                            expected_count=pos.get("stake", 0),
                            require_full=False
                        )
                        if filled_qty > 0:
                            pos["stake"] = filled_qty
                            pos["settled"] = True
                            print(f"âœ… PROFIT TARGET FILLED: {market_ticker} x{filled_qty} @ {sell_price:.2%}")
            except Exception as e:
                print(f"âš ï¸ Error executing profit target for {market_ticker}: {e}")
            continue
        
        # D. Time Stop
        if TIME_STOP_ENABLED and minutes_held >= TIME_STOP_MINUTES:
            # Check if we're up enough to justify selling
            if profit_pct >= MIN_PROFIT_PCT_TO_SELL:
                print(f"â° TIME STOP: {market_ticker} | Held for {minutes_held:.1f} minutes, profit: {profit_pct:.2%}")
                sell_price = max(0.01, current_bid - (2 * TICK))
                try:
                    sell_resp = prepare_kalshi_order(
                        market_ticker=market_ticker,
                        side="yes",
                        price=sell_price,
                        quantity=pos.get("stake", 0),
                        action="sell"
                    )
                    if sell_resp:
                        order_id, _ = _extract_order_id(sell_resp)
                        if order_id:
                            status, filled_qty = wait_for_fill_or_cancel(
                                order_id,
                                timeout_s=ORDER_FILL_TIME,
                                poll_s=1.0,
                                expected_count=pos.get("stake", 0),
                                require_full=False
                            )
                            if filled_qty > 0:
                                pos["stake"] = filled_qty
                                pos["settled"] = True
                                print(f"âœ… TIME STOP FILLED: {market_ticker} x{filled_qty} @ {sell_price:.2%}")
                except Exception as e:
                    print(f"âš ï¸ Error executing time stop for {market_ticker}: {e}")
            else:
                if VERBOSE:
                    print(f"â° TIME STOP: {market_ticker} | Held for {minutes_held:.1f} minutes, but profit {profit_pct:.2%} < {MIN_PROFIT_PCT_TO_SELL:.0%} threshold, holding")
            continue
    
    # Update positions list
    positions = new_positions
    
    # Save updated positions
    try:
        save_positions()
    except Exception as e:
        print(f"âš ï¸ Could not save positions: {e}")


# === MAIN LOOP ===
                    # Get the opposite side position
                    opposite_side_ticker = existing_opposite.get("market_ticker") if existing_opposite else None
                    current_side_ticker = market.get("ticker")
                    
                    if opposite_side_ticker and current_side_ticker and kalshi_price and kalshi_price > 0:
                        # Aggregate current quantities and prices for both sides
                        event_positions = [p for p in positions if event_key(p.get("event_ticker")) == ticker_key and not p.get("settled", False)]
                        
                        # Current side (the one we're considering adding to)
                        qA_current, pA_current, _ = aggregate_positions_on_side(event_positions, current_side_ticker)
                        
                        # Opposite side
                        qB_current, pB_current, _ = aggregate_positions_on_side(event_positions, opposite_side_ticker)
                        
                        if qA_current > 0 and qB_current > 0 and pA_current > 0 and pB_current > 0:
                            # Calculate what NEW quantity would be after adding pyramid amount
                            # Estimate provisional add quantity based on current capital allocation
                            provisional_add_qty = max(1, int(capital * kelly_fraction_dbg / kalshi_price))
                            
                            # Proposed new quantities
                            qA_proposed = qA_current + provisional_add_qty
                            pA_weighted_new = (qA_current * pA_current + provisional_add_qty * kalshi_price) / qA_proposed
                            
                            # Check if proposed quantities maintain MIN_HEDGE_RETURN
                            roi_A_check, roi_B_check = hedge_outcome_rois(qA_proposed, pA_weighted_new, qB_current, pB_current)
                            
                            if roi_A_check >= MIN_HEDGE_RETURN and roi_B_check >= MIN_HEDGE_RETURN:
                                allow_add_on_entry = True
                                if VERBOSE:
                                    print(f"âœ… Pyramid after hedge allowed: ROI A={roi_A_check:.2%}, B={roi_B_check:.2%} (min={MIN_HEDGE_RETURN:.2%})")
                            else:
                                if VERBOSE:
                                    print(f"ðŸš« Pyramid after hedge BLOCKED: Would break hedge ROI (A={roi_A_check:.2%}, B={roi_B_check:.2%}, min={MIN_HEDGE_RETURN:.2%})")
                                allow_add_on_entry = False
                        else:
                            # Can't validate - be conservative and block
                            if VERBOSE:
                                print(f"ðŸš« Pyramid after hedge BLOCKED: Could not validate hedge quantities (qA={qA_current}, qB={qB_current})")
                            allow_add_on_entry = False
                    else:
                        # Missing ticker info - be conservative
                        if VERBOSE:
                            print(f"ðŸš« Pyramid after hedge BLOCKED: Missing ticker/price information")
                        allow_add_on_entry = False

            # ðŸš« Absolute block: never add to same side until event is hedged
            if pending_same_side_block and not allow_add_on_entry:
                if VERBOSE:
                    print(f"âš ï¸ {match['match']} {side} â€” waiting for opposite hedge before re-entering same side.")
                continue

            if one_sided_exposure and not allow_add_on_entry and not is_hedge_context:
                if VERBOSE:
                    print(f"ðŸš« {match['match']} â€” already long this side; skipping any add-ons until hedge exists.")
                continue

            # and can add more Home under the normal first-entry EV/Kelly rules + exposure caps.

            # --- EV gating: different rules for first-entry vs. hedge ---
            ###
            # --- EV gating (use fair_ev everywhere) ---
            if fair_ev is None:
                if VERBOSE:
                    print("â­ï¸ Skip â€” fair_ev is None")
                continue

            hedge_band_for_new_pos = None

            hedge_ev_context = is_hedge_context

            if hedge_ev_context:  # HEDGE MODE
                # Skip EV check for hedges - ROI bands already ensure combined position profitability
                # Standalone EV is meaningless for hedges since we're not making a standalone trade
                # The ROI bands calculate based on total cost (both positions) and total payout
                if VERBOSE:
                    kalshi_prob = (mid if (mid is not None) else kalshi_price)
                    edge_pct = (odds_prob - (kalshi_prob or 0.0)) * 100.0
                    print(
                        f"â„¹ï¸ Hedge mode â€” skipping standalone EV check (ROI bands ensure combined position profitability) "
                        f"(odds={odds_prob:.2%} kalshi={kalshi_prob:.2%} edge={edge_pct:.2f}% kelly={kelly_fraction_dbg:.3f})"
                    )
            else:  # FIRST ENTRY MODE
                # Calculate EV threshold (dynamic if enabled)
                ev_threshold = FIRST_ENTRY_EV_THRESHOLD
                if DYNAMIC_EV_ENABLED:
                    # Adjust threshold based on spread and volatility
                    spread_factor = min(1.0, spread / SCALP_VOL_SPREAD) if spread else 1.0
                    # Wider spreads require higher EV
                    ev_threshold = FIRST_ENTRY_EV_THRESHOLD * (1.0 + spread_factor * 0.5)
                
                if fair_ev < ev_threshold:
                    if VERBOSE:
                        kalshi_prob = (mid if (mid is not None) else kalshi_price)
                        edge_pct = (odds_prob - (kalshi_prob or 0.0)) * 100.0
                        print(
                            f"â­ï¸ Skip first entry â€” ev={fair_ev:.2%} < {ev_threshold:.2%} (threshold) | "
                            f"odds={odds_prob:.2%} kalshi={kalshi_prob:.2%} edge={edge_pct:.2f}% kelly={kelly_fraction_dbg:.3f}{score_time_info}"
                        )
                    continue


            ####


            #####
            # Adjust edge for half-spread slippage
            yes_ask_formatted_here = format_price(market.get("yes_ask"))
            is_maker_entry = (yes_ask_formatted_here is not None and entry_price < yes_ask_formatted_here)
            cost_buffer = kalshi_fee_per_contract(entry_price, is_maker=is_maker_entry) + 0.5 * spread

            # Skip if round-trip EV is not positive enough
            # Stage 1: provisional fee â†’ provisional Kelly
            # (We recompute more accurate fee after we know quantity.)
            is_maker_provisional_here = (yes_ask_formatted_here is not None and kalshi_price < yes_ask_formatted_here)
            # Fix: Maker orders still have fees (just lower), so always calculate fee properly
            provisional_fee_pc = kalshi_fee_per_contract(kalshi_price, is_maker=is_maker_provisional_here)
            if side_choice == "yes":
                kelly_fraction = kelly_yes_with_costs(odds_prob, kalshi_price, rt_cost=provisional_fee_pc)
            else:
                kelly_fraction = kelly_yes_with_costs(1 - odds_prob, 1 - kalshi_price, rt_cost=provisional_fee_pc)

            # ðŸ“Š Debug snapshot: odds prob, kalshi prob, edge, ev, kelly
            kalshi_prob = (mid if (mid is not None) else kalshi_price)
            edge_pct = (odds_prob - (kalshi_prob or 0.0)) * 100.0
            mode = "HEDGE" if is_hedge_context else "ENTRY"
            spread_dbg = (abs((ya or 0.0) - (yb or 0.0)) if (ya is not None and yb is not None) else 0.0)
            
            # Print formatted table row
            side_name = side  # Use actual team name
            print(
                f"{side_name:<6} | {mode:<6} | {odds_prob:>7.2%} | {kalshi_prob:>7.2%} | "
                f"{edge_pct:>7.2f}% | {fair_ev:>7.2%} | {kelly_fraction:>6.3f} | "
                f"{kalshi_price:>7.2%} | {spread_dbg:>7.2%}"
            )


            # âœ… Skip tiny Kelly values
            # âœ… At this point, we know:
            # - kelly_fraction is valid
            # - is_hedge_context tells us if we should hedge or first-enter

            if (not is_hedge_context) and (kelly_fraction < MIN_KELLY):
                if VERBOSE:
                    print(f"â­ï¸ Skip first entry â€” Kelly {kelly_fraction:.4f} < MIN_KELLY {MIN_KELLY:.4f}")
                continue


            bands_dirty = False

            if is_hedge_context:
                if existing_opposite.get("market_ticker") == market.get("ticker"):
                    if VERBOSE:
                        print("âš ï¸ Hedge attempt requires opposite market â€” waiting for other side quotes.")
                    continue
                # ðŸ’¡ You already have one side â†’ must calculate hedge quantity
                # Use kalshi_price (aggressive pricing) for hedge sizing to match actual entry price
                # kalshi_price is already calculated above using aggressiveness logic
                if kalshi_price is None or kalshi_price <= 0:
                    if VERBOSE:
                        print("ðŸš« Hedge impossible â€” kalshi_price is invalid")
                    continue

                # Ensure price is in valid range for calculations (kalshi_price should already be in [0,1] from aggressiveness calc)
                hedge_price = max(0.01, min(0.99, float(kalshi_price)))
                
                # Check price range before proceeding (use original kalshi_price for consistency)
                if not (HEDGE_PRICE_MIN <= kalshi_price <= HEDGE_PRICE_MAX):
                    if VERBOSE:
                        print(f"ðŸš« Hedge price {kalshi_price:.2%} outside [{HEDGE_PRICE_MIN:.2%}, {HEDGE_PRICE_MAX:.2%}] â€” skip")
                    METRICS["missed_hedge_band"] += 1
                    continue

                # For hedges, skip Kelly check - ROI bands ensure combined position profitability
                # Standalone Kelly is meaningless for hedges since we're not making a standalone trade
                quantity = compute_hedge_quantity(
                    existing_opposite,
                    hedge_price,  # Use clamped price for safety in calculations
                    odds_prob,
                    capital
                )

                if quantity is None:
                    if VERBOSE:
                        pB = float(hedge_price)
                        # Check why it failed - could be price range or capital constraint
                        if not (HEDGE_PRICE_MIN <= pB <= HEDGE_PRICE_MAX):
                            print(f"ðŸš« Hedge price {pB:.2%} outside [{HEDGE_PRICE_MIN:.2%}, {HEDGE_PRICE_MAX:.2%}] â€” skip")
                            METRICS["missed_hedge_band"] += 1
                        else:
                            dollars_cap = capital * HEDGE_MAX_STAKE_PCT
                            max_qty_capital = max_qty_with_cap(dollars_cap, pB)
                            if max_qty_capital < 1:
                                print(f"ðŸš« Hedge impossible â€” insufficient capital (cap_qty={max_qty_capital:.1f}, capital=${capital:.2f})")
                                METRICS["missed_hedge_cap"] += 1
                            else:
                                print(f"ðŸš« Hedge impossible â€” unknown constraint (cap_qty={max_qty_capital:.1f}, capital=${capital:.2f})")
                                METRICS["missed_hedge_band"] += 1
                    else:
                        # Track even if not verbose
                        pB = float(hedge_price)
                        if not (HEDGE_PRICE_MIN <= pB <= HEDGE_PRICE_MAX):
                            METRICS["missed_hedge_band"] += 1
                        else:
                            dollars_cap = capital * HEDGE_MAX_STAKE_PCT
                            max_qty_capital = max_qty_with_cap(dollars_cap, pB)
                            if max_qty_capital < 1:
                                METRICS["missed_hedge_cap"] += 1
                            else:
                                METRICS["missed_hedge_band"] += 1
                    continue

            else:
                # ðŸ’¡ No opposite side exists â†’ this is a new first-entry attempt
                quantity = compute_first_entry_quantity(
                    kelly_fraction,
                    kalshi_price,
                    odds_prob,
                    capital
                )
                if quantity is None:
                    # Not good enough for first entry
                    continue
                if (not has_event_position):
                    scale = max(1.0, capital / FIRST_ENTRY_MIN_CAPITAL)
                    min_qty_required = max(FIRST_ENTRY_MIN_QTY, int(math.ceil(FIRST_ENTRY_MIN_QTY * scale)))
                    if quantity < min_qty_required:
                        if VERBOSE:
                            print(
                                f"â­ï¸ Skip first entry â€” Kelly sizing {quantity} < MIN {min_qty_required} contracts."
                            )
                        continue
            # Initialize variables for hedge context (needed for later calculations)
            total_hedge_stake_existing = 0.0
            total_hedge_cost_existing = 0.0
            
            # âœ… Final hedge clamp just before placing (quotes can change)
            if is_hedge_context:
                # Use kalshi_price for band calculation to match actual entry price
                price_for_band = kalshi_price
                if price_for_band is None:
                    if VERBOSE: print("ðŸš« Hedge impossible â€” kalshi_price is None")
                    continue
                
                # âœ… AGGREGATE all positions on the opposite side (not just one!)
                # Find all positions on the opposite side (same event, different market_ticker)
                opposite_side_positions = [
                    p for p in event_positions
                    if p.get("market_ticker") != market.get("ticker")
                    and not p.get("settled", False)
                ]
                
                if not opposite_side_positions:
                    if VERBOSE:
                        print("ðŸš« No opposite side positions found â€” skip hedge")
                    continue
                
                # Aggregate opposite side: sum quantities and calculate weighted average entry price
                total_opp_stake = 0.0
                total_opp_cost = 0.0  # sum of (quantity * entry_price) for weighted average
                
                for opp_pos in opposite_side_positions:
                    try:
                        qty = float(opp_pos.get("stake", 0))
                        price = float(opp_pos.get("entry_price", 0))
                        if qty > 0 and price > 0:
                            total_opp_stake += qty
                            total_opp_cost += qty * price
                    except (TypeError, ValueError):
                        continue
                
                if total_opp_stake <= 0:
                    if VERBOSE:
                        print("ðŸš« Invalid aggregated opposite side stake â€” skip hedge")
                    continue
                
                # Calculate weighted average entry price for opposite side
                weighted_avg_opp_entry = total_opp_cost / total_opp_stake
                
                # âœ… AGGREGATE all positions on the hedge side (to account for mixed entry prices)
                # Find all positions on the hedge side (same event, same market_ticker)
                hedge_side_positions = [
                    p for p in event_positions
                    if p.get("market_ticker") == market.get("ticker")
                    and not p.get("settled", False)
                ]
                
                # Calculate weighted average entry price for existing hedge side positions
                total_hedge_stake_existing = 0.0
                total_hedge_cost_existing = 0.0
                
                for hedge_pos in hedge_side_positions:
                    try:
                        qty = float(hedge_pos.get("stake", 0))
                        price = float(hedge_pos.get("entry_price", 0))
                        if qty > 0 and price > 0:
                            total_hedge_stake_existing += qty
                            total_hedge_cost_existing += qty * price
                    except (TypeError, ValueError):
                        continue
                
                # Use aggregated values for hedge band calculation
                opp_stake = total_opp_stake
                opp_entry = weighted_avg_opp_entry
                
                # Calculate held quantity using aggregated value (accounts for multiple positions)
                held_qty_hedge_side = int(round(total_hedge_stake_existing))
                
                # Calculate bands using NEW entry price (this tells us what total we'd need at new price)
                # We'll validate with actual weighted average later
                band_now = hedge_qty_bounds_target_roi(
                    opp_stake,
                    opp_entry,
                    float(price_for_band),
                    r=MIN_HEDGE_RETURN
                )

                if not band_now or band_now[0] is None or band_now[1] is None:
                    if VERBOSE: print("ðŸš« Band vanished just before place â€” skip")
                    METRICS["missed_hedge_band"] += 1
                    continue
                ql, qh = band_now
                ql_i, qh_i = int(math.ceil(ql)), int(math.floor(qh))
                
                # Handle invalid bands (qh_i < ql_i) - happens when one side is over-levered
                invalid_bands = (qh_i < ql_i)
                use_fallback_balance = False
                fallback_target_qty = None
                
                if invalid_bands:
                    # Check if we're clearly over-levered to one side and should still try to balance
                    # Use probability-weighted exposure to account for market probabilities
                    opp_exposure = total_opp_stake * weighted_avg_opp_entry
                    current_side_avg_price = (total_hedge_cost_existing / total_hedge_stake_existing) if total_hedge_stake_existing > 0 else kalshi_price
                    current_side_exposure = total_hedge_stake_existing * current_side_avg_price
                    
                    # Get opposite side's probability (if current side is home, opposite is away, and vice versa)
                    # odds_prob is the probability for the current side being evaluated
                    current_side_prob = odds_prob
                    # Opposite side probability is 1 - current_side_prob (since probabilities sum to 1)
                    opp_side_prob = 1.0 - current_side_prob
                    
                    # Calculate probability-weighted exposure (risk-weighted)
                    # Risk-weighted = exposure Ã— probability of LOSING (expected loss if that side loses)
                    # Higher probability of winning = lower probability of losing = lower risk
                    # For opposite side: prob of losing = current_side_prob (if current wins, opposite loses)
                    # For current side: prob of losing = 1 - current_side_prob = opp_side_prob
                    opp_risk_weighted = opp_exposure * current_side_prob  # Expected loss if opposite side loses
                    current_risk_weighted = current_side_exposure * opp_side_prob  # Expected loss if current side loses
                    
                    # Calculate exposure ratio using risk-weighted values
                    if current_risk_weighted > 0:
                        exposure_ratio = opp_risk_weighted / current_risk_weighted
                    else:
                        exposure_ratio = float('inf') if opp_risk_weighted > 0 else 1.0
                    
                    # CRITICAL: Only buy more of the UNDER-levered side, never the over-levered side
                    # If current side has MORE risk-weighted exposure than opposite, skip buying more
                    # (We only want to buy more of the side that has LESS exposure to balance)
                    if current_risk_weighted > opp_risk_weighted:
                        if VERBOSE:
                            print(f"ðŸš« Invalid bands but current side is OVER-levered (risk-weighted ${current_risk_weighted:.2f} > ${opp_risk_weighted:.2f})")
                            print(f"   Skipping fallback - should buy more of opposite side instead")
                        METRICS["missed_hedge_band"] += 1
                        continue
                    
                    # If opposite side has >60% more risk-weighted exposure, use fallback balance strategy
                    # This means current side is UNDER-levered, so we should buy more of it
                    if exposure_ratio > 1.6:
                        use_fallback_balance = True
                        if VERBOSE:
                            print(f"âš ï¸ Invalid bands but over-leverage detected:")
                            print(f"   Dollar exposure: opposite ${opp_exposure:.2f} vs current ${current_side_exposure:.2f}")
                            print(f"   Risk-weighted: opposite ${opp_risk_weighted:.2f} (prob={opp_side_prob:.1%}) vs current ${current_risk_weighted:.2f} (prob={current_side_prob:.1%})")
                            print(f"   Risk-weighted ratio={exposure_ratio:.2f}")
                            print(f"   Using fallback balance strategy to reduce imbalance")
                        
                        # Fallback: target equal risk-weighted exposure (not just dollar exposure)
                        # Calculate target dollar exposure needed to match opposite side's risk-weighted exposure
                        # target_risk_weighted = opp_risk_weighted (equal risk)
                        # target_risk_weighted = target_exposure * opp_side_prob  # Risk-weighted for current side
                        # target_exposure = opp_risk_weighted / opp_side_prob
                        # But cap at 80% of opposite dollar exposure to avoid over-leveraging
                        # Note: opp_side_prob is already calculated above (line 5079)
                        target_exposure_by_risk = opp_risk_weighted / max(0.01, opp_side_prob) if opp_side_prob > 0 else opp_exposure * 0.8
                        target_exposure_by_dollar = opp_exposure * 0.8
                        target_exposure = min(target_exposure_by_risk, target_exposure_by_dollar)
                        # Safety check: ensure kalshi_price is valid for division
                        if kalshi_price <= 0.01 or kalshi_price >= 0.99:
                            if VERBOSE:
                                print(f"ðŸš« Fallback balance blocked â€” invalid kalshi_price {kalshi_price:.2%}")
                            METRICS["missed_hedge_band"] += 1
                            continue
                        target_qty = max(1, int(target_exposure / kalshi_price))
                        quantity_needed = max(0, target_qty - total_hedge_stake_existing)
                        
                        if quantity_needed > 0:
                            # Set up fake bands for the rest of the logic to work
                            ql_i = total_hedge_stake_existing  # Current position
                            qh_i = target_qty  # Target position
                            # Store the target quantity for later use
                            fallback_target_qty = target_qty
                            if VERBOSE:
                                print(f"   Fallback rebalance: current={total_hedge_stake_existing}, target={target_qty}, buying {quantity_needed} contracts")
                        else:
                            if VERBOSE:
                                print("ðŸš« Band invalid and already balanced enough â€” skip")
                            METRICS["missed_hedge_band"] += 1
                            continue
                    else:
                        if VERBOSE: 
                            print(f"ðŸš« Band invalid at place time (ratio={exposure_ratio:.2f}) â€” skip")
                    METRICS["missed_hedge_band"] += 1
                    continue
                
                # âœ… SIMPLIFIED: Removed rebalancing - just check if we're at max hedge
                # If we're already at or above max band, don't add more (profit protection will exit when profitable)
                if held_qty_hedge_side >= qh_i:
                    if VERBOSE: print(f"ðŸš« Already have {held_qty_hedge_side} contracts, at/above max band {qh_i} â€” no incremental hedge needed")
                    continue
                
                existing_opposite["q_low"] = ql_i
                existing_opposite["q_high"] = qh_i
                hedge_band_for_new_pos = (ql_i, qh_i)
                bands_dirty = True
                
                # âœ… SIMPLIFIED: Hedge sizing without rebalancing complexity
                # Determine if this is first hedge for this event
                is_first_hedge = (held_qty_hedge_side == 0)
                
                # Handle fallback balance case (invalid bands but over-levered)
                if use_fallback_balance:
                    # For fallback, we already calculated target_qty above
                    if fallback_target_qty is None or fallback_target_qty <= 0:
                        if VERBOSE:
                            print("ðŸš« Fallback balance failed â€” invalid target quantity")
                        METRICS["missed_hedge_band"] += 1
                        continue
                    quantity = fallback_target_qty
                    if VERBOSE:
                        print(f"âœ… Fallback balance: setting quantity to {quantity} (incremental: {quantity - total_hedge_stake_existing})")
                elif is_first_hedge:
                    # First hedge: use q_high of band (TOTAL quantity)
                    quantity = qh_i
                else:
                    # Subsequent hedge: use Kelly clamped to band (TOTAL quantity)
                    # Determine maker/taker based on kalshi_price vs yes_ask
                    yes_ask_formatted_live = format_price(market.get("yes_ask"))
                    is_maker_live = (yes_ask_formatted_live is not None and kalshi_price < yes_ask_formatted_live)
                    fee_pc_live = kalshi_fee_per_contract(kalshi_price, is_maker=is_maker_live)
                    kelly_h_live = kelly_yes_with_costs(odds_prob, kalshi_price, rt_cost=fee_pc_live)
                    kelly_h_live = max(0.0, min(kelly_h_live, KELLY_HARD_CAP))
                    kelly_dollars_live = capital * kelly_h_live * HEDGE_TRADE_FRACTIONAL_KELLY
                    max_qty_kelly_live = max_qty_with_cap(kelly_dollars_live, kalshi_price)
                    
                    # Clamp Kelly target to band [ql_i, qh_i]
                    kelly_target_clamped = max(ql_i, min(max_qty_kelly_live, qh_i))
                    
                    # If Kelly suggests buying, scale up to Kelly target (clamped to band)
                    # Otherwise stay at current holdings
                    if kelly_h_live > 0 and kelly_target_clamped > held_qty_hedge_side:
                        target_total_qty = kelly_target_clamped
                    else:
                        # Kelly doesn't suggest adding, stay at current
                        target_total_qty = held_qty_hedge_side
                    
                    quantity = target_total_qty
                
                # Validate that total quantity is within band (incremental validation happens later)
                # Skip validation for fallback balance case (bands are fake)
                if not use_fallback_balance:
                    if quantity < ql_i or quantity > qh_i:
                        if VERBOSE:
                            print(f"ðŸš« Total quantity {quantity} outside band [{ql_i}, {qh_i}] â€” skip")
                        METRICS["missed_hedge_band"] += 1
                        continue
                
                # âœ… CRITICAL: Validate profitability with ACTUAL weighted average entry price
                # When we have existing positions at different prices, the actual cost basis is different
                # Calculate what the weighted average entry price would be after adding new contracts
                # Skip strict ROI validation for fallback balance case (we're explicitly balancing despite invalid bands)
                if not use_fallback_balance and total_hedge_stake_existing > 0 and quantity > total_hedge_stake_existing and quantity > 0:
                    # We're adding incremental contracts
                    incremental_qty_estimate = quantity - total_hedge_stake_existing
                    total_cost_after = total_hedge_cost_existing + (incremental_qty_estimate * float(price_for_band))
                    actual_weighted_avg_price = total_cost_after / quantity
                    
                    # Re-validate bands using actual weighted average price
                    band_validation = hedge_qty_bounds_target_roi(
                        opp_stake,
                        opp_entry,
                        actual_weighted_avg_price,
                        r=MIN_HEDGE_RETURN
                    )
                    
                    if band_validation:
                        ql_val, qh_val = band_validation
                        ql_val_i, qh_val_i = int(math.ceil(ql_val)), int(math.floor(qh_val))
                        
                        # Clamp quantity to validated bands (don't just block if outside)
                        # If target is above max, use max. If below min, use min.
                        quantity_clamped = max(ql_val_i, min(quantity, qh_val_i))
                        
                        if quantity_clamped != quantity:
                            if VERBOSE:
                                print(f"ðŸ” Clamping quantity {quantity} to validated band [{ql_val_i}, {qh_val_i}] â†’ {quantity_clamped}")
                            quantity = quantity_clamped
                            
                            # Recalculate weighted average with clamped quantity
                            incremental_qty_clamped = quantity - total_hedge_stake_existing
                            if incremental_qty_clamped > 0 and quantity > 0:
                                total_cost_after = total_hedge_cost_existing + (incremental_qty_clamped * float(price_for_band))
                                actual_weighted_avg_price = total_cost_after / quantity
                        
                        # Validate that clamped quantity is within bands
                        if quantity < ql_val_i or quantity > qh_val_i:
                            if VERBOSE:
                                print(f"ðŸš« Clamped quantity {quantity} still outside validated band [{ql_val_i}, {qh_val_i}] "
                                      f"(actual weighted avg price {actual_weighted_avg_price:.2%}) â€” skip")
                            METRICS["missed_hedge_band"] += 1
                            continue
                        
                        # Also validate that both outcomes are profitable with clamped quantity
                        roi_A, roi_B = hedge_outcome_rois(opp_stake, opp_entry, quantity, actual_weighted_avg_price)
                        if roi_A < MIN_HEDGE_RETURN or roi_B < MIN_HEDGE_RETURN:
                            if VERBOSE:
                                print(f"ðŸš« Actual ROI below minimum: A={roi_A:.2%}, B={roi_B:.2%} (min={MIN_HEDGE_RETURN:.0%}) â€” skip")
                            METRICS["missed_hedge_band"] += 1
                            continue

                if bands_dirty:
                    try:
                        save_positions()
                    except Exception as e:
                        print(f"âš ï¸ Could not persist hedge bands: {e}")

            # âœ… Case 1: Safe to do first entries (no hedge context, no previous exposure)
            # âœ… Case 1: Safe to do first entries (no hedge context, no previous exposure)
            if (
                not is_hedge_context
                and (
                    (not has_event_position and ticker_key not in EVENT_LOCKED_TILL_HEDGE)
                    or allow_add_on_entry
                )
            ):

                # âœ… 5.0 Trading restriction: Game state check with 70-minute fallback
                if not has_event_position:  # True first trade (not add-on)
                    # Note: Stop-loss check is done at the beginning of the side loop to block ALL entries
                    
                    # First, check if game is too early (block early Q1 trading)
                    match_name = match.get("match")
                    early_game_block = _should_block_early_game_trading(period_clock, match_name)
                    
                    if early_game_block is True:
                        # Game is too early - block trading
                        parsed = _parse_period_clock(period_clock)
                        if parsed:
                            period, minutes_remaining = parsed
                            is_womens = "(W)" in str(match_name) if match_name else False
                            game_type = "women's" if is_womens else "men's"
                            threshold = 5.0 if is_womens else 15.0
                            print(f"â±ï¸ Trading blocked: {game_type} game in Q1 with {minutes_remaining:.1f} minutes remaining (wait until â‰¤{threshold:.0f} min remaining)", flush=True)
                        else:
                            # Fallback if parsing fails
                            print(f"â±ï¸ Trading blocked: game too early in Q1 (period_clock: {period_clock})", flush=True)
                        continue
                    elif early_game_block is None and VERBOSE:
                        # Debug: Show why block check returned None
                        print(f"ðŸ” Early game block check returned None (period_clock: {period_clock}, match_name: {match_name})", flush=True)
                    
                    # Then, try late game state-based restriction
                    game_state_block = _should_block_trading_by_game_time(period_clock, match_name)
                    
                    if game_state_block is True:
                        # Game state indicates we should block trading
                        if VERBOSE:
                            parsed = _parse_period_clock(period_clock)
                            if parsed:
                                period, minutes_remaining = parsed
                                is_womens = "(W)" in str(match_name) if match_name else False
                                game_type = "women's" if is_womens else "men's"
                                period_label = "4th quarter" if is_womens else "2nd half"
                                print(f"â±ï¸ Trading blocked: {game_type} game in {period_label} with {minutes_remaining:.1f} minutes remaining (â‰¤8 min limit)")
                        continue
                    elif game_state_block is None:
                        # Game state unavailable - fall back to 70-minute time-based restriction
                        first_detection = get_first_detection_time(ticker)
                        if first_detection:
                            current_time = now_utc()
                            elapsed_seconds = (current_time - first_detection).total_seconds()
                            window_seconds = FIRST_TRADE_WINDOW_MINUTES * 60
                            remaining_seconds = window_seconds - elapsed_seconds
                            
                            if elapsed_seconds > window_seconds:
                                if VERBOSE:
                                    elapsed_min = elapsed_seconds / 60.0
                                    print(f"â±ï¸ First trade window expired: {elapsed_min:.1f} minutes elapsed since first detection (fallback: game state unavailable)")
                                continue
                            
                            # Display time info
                            elapsed_min = elapsed_seconds / 60.0
                            remaining_min = remaining_seconds / 60.0
                            first_detection_str = first_detection.strftime('%H:%M:%S')
                            print(f"â±ï¸ First trade window (fallback): {elapsed_min:.1f} min elapsed, {remaining_min:.1f} min remaining (first detected: {first_detection_str})")
                        else:
                            if VERBOSE:
                                print(f"âš ï¸ Could not determine first detection time for {ticker} â€” allowing trade (game state unavailable)")

                # 5.1 Minimum Kalshi execution price for first entries (won't enter below this)
                if kalshi_price < FIRST_ENTRY_KALSHI_PRICE_MIN:
                    if VERBOSE:
                        print(f"â­ï¸ Skip first entry â€” price {kalshi_price:.2%} < {FIRST_ENTRY_KALSHI_PRICE_MIN:.0%} min{score_time_info}")
                    continue

                # 5.1b Maximum Kalshi execution price for first entries (actual order price cap)
                if kalshi_price > FIRST_ENTRY_KALSHI_PRICE_MAX:
                    if VERBOSE:
                        print(f"â­ï¸ Skip first entry â€” Kalshi execution price {kalshi_price:.2%} > {FIRST_ENTRY_KALSHI_PRICE_MAX:.0%} max (won't place order above this price){score_time_info}")
                    continue

                # 5.2 EV threshold for first entry (e.g. >1%)
                if fair_ev is None or fair_ev < FIRST_ENTRY_EV_THRESHOLD:
                    if VERBOSE:
                        print(f"â­ï¸ Skip first entry â€” fair EV {fair_ev:.2%} < {FIRST_ENTRY_EV_THRESHOLD:.2%}{score_time_info}")
                    continue

                # 5.3 Kelly sizing for first entry
                quantity = compute_first_entry_quantity(
                    kelly_fraction=kelly_fraction,
                    kalshi_price=kalshi_price,
                    odds_prob=odds_prob,
                    capital=capital
                )
                if not quantity:
                    continue
                if (not has_event_position) and quantity < FIRST_ENTRY_MIN_QTY:
                    if VERBOSE:
                        print(
                            f"â­ï¸ Skip first entry â€” Kelly sizing {quantity} < MIN {FIRST_ENTRY_MIN_QTY} contracts."
                        )
                    continue
                if allow_add_on_entry:
                    if remaining_qty_cap < 1:
                        if VERBOSE:
                            print("ðŸš« Add-on blocked â€” no remaining capacity under MAX_STAKE_PCT.")
                        continue
                    if quantity > remaining_qty_cap:
                        if VERBOSE:
                            print("ðŸ” Trimming add-on size to stay under MAX_STAKE_PCT cap.")
                        quantity = remaining_qty_cap
                    
                    # âœ… SIMPLIFIED: Removed ROI bounds check for add-ons
                    # Add-ons now only respect exposure caps (MAX_STAKE_PCT)
                    # Profit protection will exit when combined position is profitable

                # âœ… Finalize â€” we place this first-side trade here
                # (place order code continues...)

            # âœ… Case 2: You already have one side (e.g. Norrie) and no hedge yet â€” stop first entries
            elif not is_hedge_context and one_sided_exposure and not allow_add_on_entry:
                if VERBOSE:
                    print(f"âš ï¸ {match['match']}: Already holding this side â€” add-ons disabled. Waiting for hedge/opposite setup.")
                continue

            # ðŸŽ¯ Convert desired sizing into incremental contracts (subtract what we already hold)
            try:
                target_qty_total = int(quantity)
            except (TypeError, ValueError):
                if VERBOSE:
                    print("âš ï¸ Invalid quantity computed â€” skipping trade sizing.")
                continue
            if target_qty_total <= 0:
                if VERBOSE:
                    print("âš ï¸ Non-positive target size â€” skipping.")
                continue

            # Calculate held quantity (for hedges, use aggregated value if available)
            # For hedges, we already calculated total_hedge_stake_existing which aggregates all positions
            if is_hedge_context and total_hedge_stake_existing > 0:
                # Use aggregated quantity for hedges (accounts for multiple positions)
                held_qty_this_market = int(round(total_hedge_stake_existing))
            else:
                # For first entries, use single position quantity
                held_qty_this_market = 0
                if existing_pos and not existing_pos.get("settled", False):
                    try:
                        held_qty_this_market = int(round(float(existing_pos.get("stake", 0))))
                    except (TypeError, ValueError):
                        held_qty_this_market = 0

            incremental_qty = target_qty_total if held_qty_this_market <= 0 else target_qty_total - held_qty_this_market
            if incremental_qty <= 0:
                if VERBOSE:
                    print(
                        f"âš–ï¸ {match['match']} {side_choice.upper()} â€” already holding "
                        f"{held_qty_this_market} contracts (target {target_qty_total}). No order needed."
                    )
                continue

            quantity = incremental_qty

            # 4) Exposure cap enforcement
            # --- Exposure cap enforcement with hedge exception ---
            violates, reason = exposure_violation(
                market_ticker=market.get("ticker"),
                event_ticker=ticker,
                added_qty=quantity,
                entry_price=kalshi_price,
                capital=capital,
                is_hedge_trade=is_hedge_context
            )
            if violates:
                if VERBOSE:
                    print(f"ðŸš« Skipping â€” exposure violation: {reason}")
                continue


            # Compute exit proxy for a YES entry: you'd sell NO at the NO bid
            yes_bid_f = format_price(market.get("yes_bid"))
            yes_ask_f = format_price(market.get("yes_ask"))
            no_bid_f  = (1.0 - yes_ask_f) if (yes_ask_f is not None) else ((1.0 - yes_bid_f) if (yes_bid_f is not None) else None)
            # Choose proper exit proxy for print/debug
            if side_choice == "yes":
                exit_proxy = no_bid_f


            # Debug print (round-trip aware)
            exit_proxy_str = "_" if exit_proxy is None else f"{exit_proxy:.2%}"
            if rt_ev is None:
                rt_ev_str = "nan"
            else:
                rt_ev_str = f"${rt_ev:.3f}" if USE_CONSERVATIVE_EV else f"{rt_ev:.2%}"

            qty_note = ""
            if held_qty_this_market > 0:
                qty_note = f" (target {target_qty_total})"

            print(
                f"odds_prob={odds_prob:.2%}, side={side_choice}, "
                f"entry={kalshi_price:.2%}, "
                f"exit_proxy={exit_proxy_str}, "
                f"rtEV={rt_ev_str}, "
                f"Kelly={kelly_fraction:.3f}, qty={quantity}{qty_note}"
            )

            log_eval({
                "event_ticker": ticker.upper(),
                "event_id": match.get("id"),  # Store event_id for odds lookup
                "market_ticker": market.get("ticker"),
                "match": match["match"],
                "side_label": side,  # Use actual team name
                "odds_prob": odds_prob,
                "yes_bid": format_price(market.get("yes_bid")),
                "yes_ask": format_price(market.get("yes_ask")),
                "kalshi_price": kalshi_price,
                "edge": "",
                "kelly_fraction": kelly_fraction,
                "spread": (
                    ((market.get("yes_ask") or 0) - (market.get("yes_bid") or 0)) / 100.0
                    if (market.get("yes_ask") is not None and market.get("yes_bid") is not None)
                    else None
                ),
                "cost_buffer": cost_buffer,
                "decision": side_choice or "pass"
            })

            books_used_list = match.get("books_used") or []
            books_weight_str = " | ".join(f"{name}:{_book_weight(name):.2f}" for name in books_used_list) if books_used_list else ""
            odds_snapshot = match.get("odds_feed") or {}
            log_backtest_feed({
                "match": match["match"],
                "event_ticker": ticker.upper(),
                "market_ticker": market.get("ticker"),
                "side_label": side,  # Use actual team name
                "books_used": " | ".join(books_used_list),
                "books_weights": books_weight_str,
                "books_sampled": odds_snapshot.get("books_sampled", ""),
                "home_prob": odds_snapshot.get("home_prob", ""),
                "away_prob": odds_snapshot.get("away_prob", ""),
                "odds_prob": odds_prob,
                "yes_bid": yes_bid_f,
                "yes_ask": yes_ask_f,
                "kalshi_mid": mid,
                "kalshi_price": kalshi_price,
                "spread": spread,
                "edge_pct": edge_pct,
                "fair_ev": fair_ev,
                "cons_ev": cons_ev,
                "rt_ev": rt_ev,
                "kelly_fraction": kelly_fraction,
                "volatility_mode": volatility_mode,
                "capital": capital,
                "min_qty_required": min_qty_required or "",
                "planned_qty": quantity,
                "has_event_position": has_event_position,
                "is_hedge": is_hedge_context,
                "decision": side_choice or "pass",
                "cost_buffer": cost_buffer,
            })

            # === Entry condition ===
            # === Entry condition ===
            # === Entry condition ===

            # === HEDGING: Prevent Over-Exposure on One Side ===
            # === HEDGING: Prevent Over-Exposure on One Side ===
            # === HEDGING: Prevent Over-Exposure on One Side ===
            # === HEDGING: Prevent Over-Exposure on One Side (Clean Version) ===
            # No fee added at entry; handled later in EV and PnL calculations
            if side_choice == "yes":
                effective_entry = kalshi_price
            else:
                effective_entry = 1 - kalshi_price

                ######
                # ðŸ›’ Try passive entry first (sit on bid/ask Â±1Â¢)
            ######
            # ðŸ›’ Passive entry â€” sit *behind* current top of book (1Â¢ below bid)
            # --- Volatility-based entry price ---

            # Clamp to [0,1]
            entry_price = max(0.0, min(1.0, entry_price))

            def fmt_pct(x):
                return f"{x:.2%}" if isinstance(x, (float, int)) else "N/A"

            print(
                f"ðŸ›’ Posting *behind* top-of-book {side_choice.upper()} order "
                f"@ {fmt_pct(entry_price)} (bid={fmt_pct(yb)}, ask={fmt_pct(ya)})"
            )

            # ðŸš« Final safety: only allow YES entries
            if side_choice.lower() != "yes":
                print(f"â›” Blocked non-YES order attempt for {match['match']} (side={side_choice})")
                continue

            # ðŸš¨ FINAL SAFETY: Block any new trade if event already has one side open and no hedge
            event_positions = [
                p for p in positions
                if normalize_event_ticker(p.get("event_ticker", "")) == normalize_event_ticker(ticker)
                and not p.get("settled", False)
            ]

            # If exactly one side open and it's not neutralized â†’ block
            if (
                len(event_positions) == 1
                and not event_is_neutralized(ticker)
                and not is_hedge_context
                and not allow_add_on_entry
            ):
                print(f"ðŸš« FINAL BLOCK â€” {match['match']} already has one open side ({event_positions[0]['market_ticker']}), no hedge yet.")
                continue

            
            # ðŸ”¸ PART 6: After we have previously neutralized this event, re-apply directional cap to any new one-sided add
            evt_neutralized = any(
                p.get("neutralized") for p in positions if event_key(p.get("event_ticker")) == ticker_key
            )
            # Check if event is hedged (both sides exist) - more robust check
            event_is_hedged = event_is_neutralized(ticker)
            
            # Block one-sided additions to hedged positions if pyramiding is disabled
            # When event is already hedged (both sides exist), we're adding to existing hedge, not creating new one
            # Check if we already have a position on this side (meaning we're adding to existing, not creating hedge)
            has_position_on_this_side = any(
                p.get("market_ticker") == market.get("ticker")
                for p in event_positions
            )
            
            # If event is hedged AND we already have a position on this side, it's a one-sided add to existing hedge
            if (evt_neutralized or event_is_hedged) and has_position_on_this_side:
                # Check master pyramiding flag
                if not PYRAMIDING_ENABLED:
                    if VERBOSE:
                        print(f"ðŸš« Skip add-on â€” PYRAMIDING_ENABLED=False (preventing all pyramiding)")
                    continue
                
                # Block if pyramiding after hedge is disabled
                if not ALLOW_PYRAMID_AFTER_HEDGE:
                    if VERBOSE:
                        print(f"ðŸš« Skip add-on â€” already hedged (event has both sides) and position exists on this side. ALLOW_PYRAMID_AFTER_HEDGE=False (preventing one-sided additions to hedged positions)")
                    continue
                
                existing_exposure_evt = sum(
                    p["stake"] * p["entry_price"]
                    for p in positions
                    if event_key(p.get("event_ticker")) == ticker_key
                )
                future_exposure_evt = existing_exposure_evt + (quantity * kalshi_price)
                max_allowed_evt = capital * MAX_TOTAL_EXPOSURE_PCT
                if future_exposure_evt > max_allowed_evt:
                    if VERBOSE:
                        print(f"ðŸš« Skip add-on â€” post-hedge directional cap exceeded "
                            f"(${future_exposure_evt:.2f} > ${max_allowed_evt:.2f})")
                    continue

            # âœ… Exposure check before submitting any order
            # âœ… Exposure check before submitting any order (hedge-aware)
            violates, reason = exposure_violation(
                market_ticker=market.get("ticker"),
                event_ticker=ticker,
                added_qty=quantity,
                entry_price=kalshi_price,
                capital=capital,
                is_hedge_trade=is_hedge_context
            )
            if violates:
                if VERBOSE:
                    print(f"ðŸš« Skipping â€” exposure violation: {reason}")
                continue

            # âœ… Spread validation: Check if spread is too wide before placing order
            # Recalculate spread from current market data to ensure it's fresh
            yb_check = format_price(market.get("yes_bid"))
            ya_check = format_price(market.get("yes_ask"))
            if yb_check is not None and ya_check is not None:
                current_spread = abs(ya_check - yb_check)
                if current_spread > MAX_SPREAD:
                    if VERBOSE:
                        print(f"ðŸš« Skipping â€” spread too wide: {current_spread:.2%} > {MAX_SPREAD:.2%} "
                              f"(bid={yb_check:.2%}, ask={ya_check:.2%}, entry_price={kalshi_price:.2%})")
                    METRICS["missed_wide_spread"] += 1
                    continue
            elif yb_check is None or ya_check is None:
                # Missing bid or ask - skip to avoid placing orders in illiquid markets
                if VERBOSE:
                    print(f"ðŸš« Skipping â€” missing bid/ask (bid={yb_check}, ask={ya_check})")
                continue

            # Price range already checked earlier for hedges, but double-check as safety
            if is_hedge_context and not (HEDGE_PRICE_MIN <= kalshi_price <= HEDGE_PRICE_MAX):
                if VERBOSE:
                    print(
                        f"ðŸš« Hedge price {kalshi_price:.2%} outside [{HEDGE_PRICE_MIN:.2%}, {HEDGE_PRICE_MAX:.2%}] â€” skip (safety check)"
                    )
                METRICS["missed_hedge_band"] += 1
                continue

            filled_qty = 0
            # Use the actual team name (side contains the team name like "Duke" or "UNC")
            side_name = side  # e.g., "Duke" or "UNC"
            position = {
                "match": match["match"],
                "side": side_choice,
                "side_name": side_name,  # Actual team name
                "event_ticker": ticker.upper(),
                "event_id": match.get("id"),  # Store event_id for odds lookup
                "market_ticker": market.get("ticker"),
                "entry_price": kalshi_price,
                "odds_prob": odds_prob,
                "entry_time": now_utc().isoformat(),
                "effective_entry": effective_entry,
                "max_price": kalshi_price,
                "stake": filled_qty,
                "peak_pnl_pct": 0.0,
                "peak_hit_ts": None,
                "breakeven_armed": False,
                "next_exit_after": now_utc().isoformat(),
                "yes_sub_title": market.get("yes_sub_title"),
            }
            if hedge_band_for_new_pos:
                ql_i, qh_i = hedge_band_for_new_pos
                position["q_low"] = ql_i
                position["q_high"] = qh_i

            _bump_fill("placed")

            # ðŸ›¡ï¸ FINAL SAFETY CHECK: Verify position state before placing order
            # Get fresh live positions to ensure we're not about to create a duplicate
            if PLACE_LIVE_KALSHI_ORDERS == "YES":
                try:
                    live_check_positions = get_live_positions()
                    live_qty_on_market = sum(
                        p["contracts"] for p in live_check_positions 
                        if p["ticker"] == market.get("ticker") and p["side"] == "yes"
                    )
                    
                    # Calculate what we think we should have based on local positions
                    local_qty_on_market = sum(
                        p.get("stake", 0) for p in positions
                        if p.get("market_ticker") == market.get("ticker") 
                        and p.get("side") == "yes"
                        and not p.get("settled", False)
                    )
                    
                    # If live quantity already matches or exceeds our target, skip this order
                    if live_qty_on_market >= target_qty_total:
                        print(f"ðŸ›¡ï¸ DUPLICATE PREVENTION: Already have {live_qty_on_market} contracts on {market.get('ticker')} "
                              f"(target was {target_qty_total}). Skipping order to prevent duplicate trade.")
                        continue
                    
                    # If there's a mismatch between local and live, warn but allow (could be pending fill)
                    if local_qty_on_market != live_qty_on_market:
                        print(f"âš ï¸ Position mismatch detected: Local={local_qty_on_market}, Live={live_qty_on_market} for {market.get('ticker')}")
                        # Adjust quantity to match what we actually need
                        adjusted_qty = target_qty_total - live_qty_on_market
                        if adjusted_qty <= 0:
                            print(f"ðŸ›¡ï¸ Already at target quantity on live exchange. Skipping order.")
                            continue
                        if adjusted_qty != quantity:
                            print(f"ðŸ“Š Adjusting order quantity from {quantity} to {adjusted_qty} to match live state")
                            quantity = adjusted_qty
                
                except Exception as e:
                    print(f"âš ï¸ Could not verify live positions before order: {e}")
                    # Continue with order anyway - don't block on verification errors

            # âœ… Check if odds have been updated on this turn before placing new entry orders
            # (Allow exits/stop-losses and hedging even if odds haven't updated, but block new first entries)
            if REQUIRE_ODDS_UPDATE_FOR_TRADES and match.get("_skip_new_entries", False) and not is_hedge_context:
                if VERBOSE:
                    print(f"â¸ï¸ Skipping new entry order for {match['match']} â€” odds not updated on this turn (hedging allowed)")
                continue

            # Use safe_prepare_kalshi_order to guard against accidental oversizing if
            # prior orders filled while cancels were in-flight. Cap total live size
            # on this market at target_qty_total.
            resp = safe_prepare_kalshi_order(
                market_ticker=market.get("ticker"),
                side="yes",   # force YES explicitly
                price=kalshi_price,
                quantity=quantity,              # final contract size for this attempt
                max_total_contracts=target_qty_total,
                action="buy",
            )

            order_id, client_oid = _extract_order_id(resp)
            if not order_id:
                print("âš ï¸ Could not parse order_id; skipping position.")
                continue

            # Wait for fill or cancel â€” do NOT cross if unfilled
            status, filled_qty = wait_for_fill_or_cancel(
                order_id,
                client_order_id=client_oid,
                timeout_s=ORDER_FILL_TIME,
                poll_s=1.0,
                expected_count=quantity,
                require_full=False,
                verify_ticker=market.get("ticker"),
                verify_side="yes"
            )

            if filled_qty <= 0:
                _bump_fill("timeout_cancel")
                print("âš ï¸ Passive entry not filled â€” cancelling and waiting for next recalculation.")
                continue

            if status == "filled" and filled_qty > 0:
                _bump_fill("filled")
            else:
                _bump_fill("timeout_cancel")
                print("âš ï¸ Passive entry not filled â€” cancelling and waiting for next recalculation.")
                continue

            # --- Slippage measurement (mid vs filled) ---
            mid = ((yb if yb is not None else kalshi_price) + (ya if ya is not None else kalshi_price)) / 2.0
            filled_price = kalshi_price  # unless you parse avg fill from response
            slip_bps = 10000.0 * (filled_price - mid)
            METRICS["avg_slippage_bps_sum"] += slip_bps
            METRICS["avg_slippage_bps_n"] += 1
            # --------------------------------------------

            ####################
            position["stake"] = filled_qty
            commit_trade_and_persist(position, order_id, filled_qty)
            set_event_neutralization_flags(position["event_ticker"])
            update_event_lock(position["event_ticker"])
            print(f"âœ… LIVE TRADE RECORDED â€” {match['match']} {side_name} x{filled_qty} @ {kalshi_price:.2%}")
            report_event_hedge_bands(position["event_ticker"], kalshi, match["match"])

            ####################

            log_backtest_metrics({
                "match": match["match"],
                "market_ticker": market.get("ticker"),
                "side": side_choice,
                "entry_price": kalshi_price,
                "odds_prob": odds_prob,
                "spread": spread,
                "fair_ev": fair_ev,
                "kelly_fraction": kelly_fraction,
                "volatility_mode": volatility_mode,
                "stake": filled_qty
            })

            # âœ… Cross-verify it really exists on Kalshi right now
            try:
                live_positions = get_live_positions()
                found = next(
                    (p for p in live_positions
                    if p["ticker"] == position["market_ticker"] and p["side"] == position["side"]),
                    None
                )
                if found:
                    print(f"ðŸ” Verified live fill on Kalshi: {found['ticker']} | {found['side']} x{found['contracts']} @ {found['avg_price']:.2%}")
                else:
                    print("âš ï¸ Not yet visible in live positions (may take a few seconds). Will reconcile soon.")
            except Exception as e:
                print(f"âš ï¸ Live verification failed: {e}")

    # Check each event for profit protection
    for evt_key, event_positions in events_dict.items():
        # Find the two sides (markets)
        markets_by_ticker = {}
        for pos in event_positions:
            mkt_ticker = pos.get("market_ticker")
            if mkt_ticker not in markets_by_ticker:
                markets_by_ticker[mkt_ticker] = []
            markets_by_ticker[mkt_ticker].append(pos)
        
        market_tickers = list(markets_by_ticker.keys())

        # If this event is already in closing state (e.g., partial fills, restart), re-queue closes now
        event_has_closing_flag = any(p.get("closing_in_progress", False) for p in event_positions)
        if event_has_closing_flag:
            markets = kalshi_markets_cache.get(evt_key, [])
            # Require fresh market data and both sides to justify selling; otherwise clear flag and keep evaluating
            if len(market_tickers) >= 2 and markets:
                side_A_ticker = market_tickers[0]
                side_B_ticker = market_tickers[1]
                side_A_market = next((m for m in markets if m.get("ticker") == side_A_ticker), None)
                side_B_market = next((m for m in markets if m.get("ticker") == side_B_ticker), None)
                side_A_bid = format_price(side_A_market.get("yes_bid")) if side_A_market else None
                side_B_bid = format_price(side_B_market.get("yes_bid")) if side_B_market else None

                if side_A_bid is not None and side_B_bid is not None:
                    side_A_sell_price = max(0.01, side_A_bid - TICK)
                    side_B_sell_price = max(0.01, side_B_bid - TICK)
                    
                    # Get ask prices for spread check
                    side_A_ask = format_price(side_A_market.get("yes_ask")) if side_A_market else None
                    side_B_ask = format_price(side_B_market.get("yes_ask")) if side_B_market else None
                    
                    # Get match data for time restrictions
                    match_data = event_to_match.get(evt_key, {})
                    period_clock = match_data.get("period_clock")
                    match_name = match_data.get("match_name")
                    
                    check_result = check_profit_protection(
                        event_positions[0].get("event_ticker", ""),
                        markets_by_ticker.get(side_A_ticker, []),
                        markets_by_ticker.get(side_B_ticker, []),
                        side_A_ticker,
                        side_B_ticker,
                        side_A_sell_price,
                        side_B_sell_price,
                        side_A_ask=side_A_ask,
                        side_B_ask=side_B_ask,
                        side_A_bid=side_A_bid,
                        side_B_bid=side_B_bid,
                        period_clock=period_clock,
                        match_name=match_name
                    )
                    if not check_result.get("should_close", False):
                        # Clear stale closing flags; keep positions active
                        for pos in event_positions:
                            pos["closing_in_progress"] = False
                            pos.pop("closing_check_result", None)
                            pos.pop("closing_initiated_at", None)
                        new_positions.extend(event_positions)
                        continue
                    
                    # Check if this is a partial exit
                    partial_exit_side = check_result.get("partial_exit_side")
                    if partial_exit_side:
                        # Partial exit: only mark the specified side for closing
                        side_to_close_ticker = side_A_ticker if partial_exit_side == "A" else side_B_ticker
                        positions_to_close_list = markets_by_ticker.get(side_to_close_ticker, [])
                        positions_to_keep_list = markets_by_ticker.get(side_B_ticker, []) if partial_exit_side == "A" else markets_by_ticker.get(side_A_ticker, [])
                        
                        # Mark ALL positions on the side to close (in case of multiple entries from pyramiding)
                        # The live position check will ensure we don't sell more than available
                        for pos in positions_to_close_list:
                            pos["closing_in_progress"] = True
                            pos.setdefault("closing_initiated_at", time.time())
                            pos["closing_check_result"] = check_result.copy()
                            key = (pos.get("market_ticker"), pos.get("side"))
                            # Add to queue even if key exists (multiple positions on same side need all to be closed)
                            # The live position check will prevent double-selling
                            if key not in positions_to_close_keys:
                                positions_to_close_keys.add(key)
                            positions_to_close.append(pos)
                        
                        # Keep the other side open
                        for pos in positions_to_keep_list:
                            pos["closing_in_progress"] = False
                            pos.pop("closing_check_result", None)
                            pos.pop("closing_initiated_at", None)
                        new_positions.extend(positions_to_keep_list)
                        
                        save_positions()
                        continue
                else:
                    # Missing bids - cannot safely justify selling; clear flags
                    for pos in event_positions:
                        pos["closing_in_progress"] = False
                        pos.pop("closing_check_result", None)
                        pos.pop("closing_initiated_at", None)
                    new_positions.extend(event_positions)
                    continue

            # Full exit (not partial) - check if we should still close all
            shared_check = next((p.get("closing_check_result") for p in event_positions if p.get("closing_check_result")), None)
            if shared_check and shared_check.get("partial_exit_side"):
                # This was a partial exit - handle it separately
                partial_exit_side = shared_check.get("partial_exit_side")
                side_to_close_ticker = side_A_ticker if partial_exit_side == "A" else side_B_ticker
                positions_to_close_list = markets_by_ticker.get(side_to_close_ticker, [])
                positions_to_keep_list = markets_by_ticker.get(side_B_ticker, []) if partial_exit_side == "A" else markets_by_ticker.get(side_A_ticker, [])
                
                # Mark ALL positions on the side to close (in case of multiple entries from pyramiding)
                # The live position check will ensure we don't sell more than available
                for pos in positions_to_close_list:
                    pos["closing_in_progress"] = True
                    pos.setdefault("closing_initiated_at", time.time())
                    if not pos.get("closing_check_result"):
                        pos["closing_check_result"] = shared_check.copy()
                    key = (pos.get("market_ticker"), pos.get("side"))
                    # Add to queue even if key exists (multiple positions on same side need all to be closed)
                    # The live position check will prevent double-selling
                    if key not in positions_to_close_keys:
                        positions_to_close_keys.add(key)
                    positions_to_close.append(pos)
                
                # Keep the other side open
                for pos in positions_to_keep_list:
                    pos["closing_in_progress"] = False
                    pos.pop("closing_check_result", None)
                    pos.pop("closing_initiated_at", None)
                new_positions.extend(positions_to_keep_list)
                save_positions()
                continue
            
            # Full exit - close all positions
            for pos in event_positions:
                # Ensure flags/timestamps exist so stale detection works
                pos["closing_in_progress"] = True
                pos.setdefault("closing_initiated_at", time.time())
                if shared_check and not pos.get("closing_check_result"):
                    pos["closing_check_result"] = shared_check.copy()
                key = (pos.get("market_ticker"), pos.get("side"))
                if key not in positions_to_close_keys:
                    positions_to_close_keys.add(key)
                    positions_to_close.append(pos)
            save_positions()
            continue
        
        if len(market_tickers) < 2:
            # Not hedged, keep position (or use other exit logic if needed)
            new_positions.extend(event_positions)
            continue
        
        # We have both sides (hedged) - check profit protection
        side_A_ticker = market_tickers[0]
        side_B_ticker = market_tickers[1]
        side_A_positions = markets_by_ticker[side_A_ticker]
        side_B_positions = markets_by_ticker[side_B_ticker]
        
        # Get current market prices
        evt_ticker_str = event_positions[0].get("event_ticker")
        markets = kalshi_markets_cache.get(evt_key, [])
        
        if not markets:
            # Can't check without market data, keep positions
            new_positions.extend(event_positions)
            continue
        
        side_A_market = next((m for m in markets if m.get("ticker") == side_A_ticker), None)
        side_B_market = next((m for m in markets if m.get("ticker") == side_B_ticker), None)
        
        if not side_A_market or not side_B_market:
            # Can't check without market data, keep positions
            new_positions.extend(event_positions)
            continue
        
        side_A_bid = format_price(side_A_market.get("yes_bid"))
        side_B_bid = format_price(side_B_market.get("yes_bid"))

        # Track max live price achieved (use bid as the sellable price proxy)
        if side_A_bid is not None:
            for p in side_A_positions:
                p["max_price"] = max(p.get("max_price", 0.0), float(side_A_bid))
        if side_B_bid is not None:
            for p in side_B_positions:
                p["max_price"] = max(p.get("max_price", 0.0), float(side_B_bid))
        
        if side_A_bid is None or side_B_bid is None:
            # Can't calculate profit without prices, keep positions
            new_positions.extend(event_positions)
            continue
        
        # Calculate actual sell prices (bid - 1 tick) - what we'd actually get when selling
        side_A_sell_price = max(0.01, side_A_bid - TICK) if side_A_bid is not None else None
        side_B_sell_price = max(0.01, side_B_bid - TICK) if side_B_bid is not None else None
        
        # Get ask prices for spread check
        side_A_ask = format_price(side_A_market.get("yes_ask"))
        side_B_ask = format_price(side_B_market.get("yes_ask"))
        
        # Get match data for time restrictions
        match_data = event_to_match.get(evt_key, {})
        period_clock = match_data.get("period_clock")
        match_name = match_data.get("match_name")
        
        # Run profit protection check (using actual sell prices - what you'd get when selling)
        check_result = check_profit_protection(
            evt_ticker_str,
            side_A_positions,
            side_B_positions,
            side_A_ticker,
            side_B_ticker,
            side_A_sell_price,
            side_B_sell_price,
            side_A_ask=side_A_ask,
            side_B_ask=side_B_ask,
            side_A_bid=side_A_bid,
            side_B_bid=side_B_bid,
            period_clock=period_clock,
            match_name=match_name
        )
        
        # Log status (even if not closing) - Enhanced display with full breakdown
        if VERBOSE and check_result:  # Show always, even if negative
            current = check_result['current_profit_pct']
            peak = check_result.get('peak_profit_pct', 0)
            max_pct = check_result.get('max_profit_pct', 0)
            settlement = check_result.get('settlement_roi', 0)
            settlement_min = check_result.get('settlement_roi_min', 0)
            
            # Calculate ratio to max
            ratio_to_max = (current / max_pct * 100) if max_pct > 0 else 0
            
            # Get probability breakdown
            prob_A = check_result.get('prob_A', 0)
            prob_B = check_result.get('prob_B', 0)
            roi_A = check_result.get('roi_A', 0)
            roi_B = check_result.get('roi_B', 0)
            
            # Get target prices
            target_A = check_result.get("target_price_A")
            target_B = check_result.get("target_price_B")
            
            # Build detailed log
            print(f"ðŸ’° {evt_key}:")
            print(f"   Current: {current:.2%} (peak: {peak:.2%}, {ratio_to_max:.0f}% of max)")
            print(f"   Settlement: {settlement:.2%} weighted (min: {settlement_min:.2%})")
            print(f"   Outcomes: A={roi_A:.2%} ({prob_A:.1%} likely), B={roi_B:.2%} ({prob_B:.1%} likely)")
            if target_A is not None and target_B is not None:
                print(f"   Target prices for max: A={target_A:.2%}, B={target_B:.2%}")
            print(f"   Pyramiding: {'YES' if check_result.get('is_pyramiding') else 'NO'}")
        
        if check_result.get("should_close", False):
            # Check if this is a partial exit (odds feed rule) or full exit
            partial_exit_side = check_result.get("partial_exit_side")
            
            if partial_exit_side:
                # Partial exit: only close the specified side (A or B)
                side_to_close_ticker = side_A_ticker if partial_exit_side == "A" else side_B_ticker
                positions_to_close_list = side_A_positions if partial_exit_side == "A" else side_B_positions
                positions_to_keep_list = side_B_positions if partial_exit_side == "A" else side_A_positions
                
                # Mark ALL positions on the side to close (in case of multiple entries from pyramiding)
                # The live position check will ensure we don't sell more than available
                for pos in positions_to_close_list:
                    # 7% exit bypasses unhedged hold time check - it should execute immediately
                    is_7pct_exit = check_result.get("kalshi_price_triggered", False)
                    
                    # Check if position is unhedged and hasn't been held for minimum time
                    # Skip this check for 7% exits (they should execute no matter what)
                    pos_is_hedged = pos.get("neutralized", False) or event_is_neutralized(evt_ticker_str)
                    if not pos_is_hedged and not is_7pct_exit:
                        entry_time_str = pos.get("entry_time")
                        if entry_time_str:
                            try:
                                entry_time = parse_iso_utc(entry_time_str)
                                if entry_time:
                                    entry_ts = entry_time.timestamp()
                                    current_ts = time.time()
                                    hold_duration = current_ts - entry_ts
                                    
                                    if hold_duration < MIN_HOLD_BEFORE_SELL_UNHEDGED_SECONDS:
                                        remaining_seconds = int(MIN_HOLD_BEFORE_SELL_UNHEDGED_SECONDS - hold_duration)
                                        if VERBOSE:
                                            print(f"ðŸš« Cannot sell unhedged position {pos.get('market_ticker')} - only held for {hold_duration:.0f}s, need {MIN_HOLD_BEFORE_SELL_UNHEDGED_SECONDS}s minimum ({remaining_seconds}s remaining)")
                                        # Skip this position - don't mark for closing
                                        continue
                            except Exception as e:
                                if VERBOSE:
                                    print(f"âš ï¸ Error checking entry time for {pos.get('market_ticker')}: {e}")
                                # If we can't parse time, be conservative and allow (don't block)
                    
                    if not pos.get("closing_in_progress", False):
                        pos["closing_in_progress"] = True
                    pos.setdefault("closing_initiated_at", time.time())
                    pos["closing_check_result"] = check_result.copy()
                    key = (pos.get("market_ticker"), pos.get("side"))
                    # Add to queue even if key exists (multiple positions on same side need all to be closed)
                    # The live position check will prevent double-selling
                    if key not in positions_to_close_keys:
                        positions_to_close_keys.add(key)
                    positions_to_close.append(pos)
                
                # Keep the other side open
                new_positions.extend(positions_to_keep_list)
                
                # Save immediately to persist closing flags
                save_positions()
                reason = check_result.get("reason", "odds_feed_partial_exit")
                side_name = "A" if partial_exit_side == "A" else "B"
                other_side_name = "B" if partial_exit_side == "A" else "A"
                
                # Record which market ticker exited at 7% to disable stop loss on the other side
                if check_result.get("kalshi_price_triggered", False):
                    exited_ticker = side_to_close_ticker  # Store the actual market ticker that exited
                    EVENT_7PCT_EXITED_SIDE[evt_key] = exited_ticker
                    if VERBOSE:
                        print(f"ðŸ“ Recorded 7% exit on market {exited_ticker} (side {partial_exit_side}) for event {evt_key} - stop loss disabled on other side")
                
                print(f"ðŸ”’ ODDS FEED PARTIAL EXIT for {evt_key}: {reason} - closing side {side_name} only, keeping side {other_side_name} open")
            else:
                # Full exit: close both sides (normal profit protection)
                for pos in event_positions:
                    # Check if position is unhedged and hasn't been held for minimum time
                    pos_is_hedged = pos.get("neutralized", False) or event_is_neutralized(evt_ticker_str)
                    if not pos_is_hedged:
                        entry_time_str = pos.get("entry_time")
                        if entry_time_str:
                            try:
                                entry_time = parse_iso_utc(entry_time_str)
                                if entry_time:
                                    entry_ts = entry_time.timestamp()
                                    current_ts = time.time()
                                    hold_duration = current_ts - entry_ts
                                    
                                    if hold_duration < MIN_HOLD_BEFORE_SELL_UNHEDGED_SECONDS:
                                        remaining_seconds = int(MIN_HOLD_BEFORE_SELL_UNHEDGED_SECONDS - hold_duration)
                                        if VERBOSE:
                                            print(f"ðŸš« Cannot sell unhedged position {pos.get('market_ticker')} - only held for {hold_duration:.0f}s, need {MIN_HOLD_BEFORE_SELL_UNHEDGED_SECONDS}s minimum ({remaining_seconds}s remaining)")
                                        # Skip this position - don't mark for closing
                                        continue
                            except Exception as e:
                                if VERBOSE:
                                    print(f"âš ï¸ Error checking entry time for {pos.get('market_ticker')}: {e}")
                                # If we can't parse time, be conservative and allow (don't block)
                    
                    if not pos.get("closing_in_progress", False):
                        pos["closing_in_progress"] = True
                    pos.setdefault("closing_initiated_at", time.time())  # Track when closing started
                    pos["closing_check_result"] = check_result.copy()  # Store check result for re-validation
                    key = (pos.get("market_ticker"), pos.get("side"))
                    if key not in positions_to_close_keys:
                        positions_to_close_keys.add(key)
                        positions_to_close.append(pos)
                # Save immediately to persist closing flags (prevents double-selling on restart)
                save_positions()
                reason = check_result.get("reason", "profit_protection")
                print(f"ðŸ”’ Closing hedged position for {evt_key}: {reason} "
                      f"(profit={check_result['current_profit_pct']:.2%})")
                # Clean up peak tracking when closing positions
                peak_key = f"{evt_key}_peak"
                if peak_key in _PEAK_PROFITS:
                    del _PEAK_PROFITS[peak_key]
        else:
            # Keep positions
            new_positions.extend(event_positions)
    
    # Execute closes - place actual sell orders at bid - 1 tick for aggressive fill
    for pos in positions_to_close:
        # Double-selling protection: verify position is still marked as closing
        if not pos.get("closing_in_progress", False):
            if VERBOSE:
                print(f"âš ï¸ Skipping {pos.get('market_ticker')} - closing flag was cleared")
            continue
        
        # Additional safety check: prevent selling unhedged positions before minimum hold time
        evt_ticker = pos.get("event_ticker")
        if evt_ticker:
            pos_is_hedged = pos.get("neutralized", False) or event_is_neutralized(evt_ticker)
            if not pos_is_hedged:
                # Position is unhedged - check minimum hold time
                entry_time_str = pos.get("entry_time")
                if entry_time_str:
                    try:
                        entry_time = parse_iso_utc(entry_time_str)
                        if entry_time:
                            entry_ts = entry_time.timestamp()
                            current_ts = time.time()
                            hold_duration = current_ts - entry_ts
                            
                            if hold_duration < MIN_HOLD_BEFORE_SELL_UNHEDGED_SECONDS:
                                remaining_seconds = int(MIN_HOLD_BEFORE_SELL_UNHEDGED_SECONDS - hold_duration)
                                if VERBOSE:
                                    print(f"ðŸš« BLOCKED: Cannot sell unhedged position {pos.get('market_ticker')} - only held for {hold_duration:.0f}s, need {MIN_HOLD_BEFORE_SELL_UNHEDGED_SECONDS}s minimum ({remaining_seconds}s remaining)")
                                pos["closing_in_progress"] = False
                                pos.pop("closing_check_result", None)
                                pos.pop("closing_initiated_at", None)
                                continue
                    except Exception as e:
                        if VERBOSE:
                            print(f"âš ï¸ Error checking entry time for {pos.get('market_ticker')}: {e}")
                        # If we can't parse time, allow the sell (don't block on errors)
        
        # Check for stale closing flags (older than 5 minutes - likely from previous run)
        closing_initiated_at = pos.get("closing_initiated_at")
        if closing_initiated_at:
            age_seconds = time.time() - closing_initiated_at
            if age_seconds > 300:  # 5 minutes
                if VERBOSE:
                    print(f"âš ï¸ Skipping {pos.get('market_ticker')} - closing flag is stale ({age_seconds:.0f}s old)")
                pos["closing_in_progress"] = False
                pos.pop("closing_check_result", None)
                pos.pop("closing_initiated_at", None)
                continue
        
        market_ticker = pos.get("market_ticker")
        stake_to_sell = int(pos.get("stake", 0))
        
        if stake_to_sell <= 0:
            # Already closed or invalid
            pos["settled"] = True
            pos["closing_in_progress"] = False  # Clear flag
            continue
        
        # CRITICAL: Refresh market prices right before selling (don't use stale cache)
        evt_key = event_key(pos.get("event_ticker"))
        evt_ticker_str = pos.get("event_ticker")
        
        try:
            # Fetch fresh market data - don't use stale cache
            fresh_markets = get_kalshi_markets(evt_ticker_str, force_live=True)
            if not fresh_markets:
                if VERBOSE:
                    print(f"âš ï¸ Cannot close {market_ticker}: could not fetch fresh market data")
                pos["closing_in_progress"] = False  # Clear flag to allow retry
                continue
            
            market = next((m for m in fresh_markets if m.get("ticker") == market_ticker), None)
        except Exception as e:
            if VERBOSE:
                print(f"âš ï¸ Error fetching fresh markets for {market_ticker}: {e}")
            pos["closing_in_progress"] = False
            continue
        
        if not market:
            if VERBOSE:
                print(f"âš ï¸ Cannot close {market_ticker}: market not found in fresh data")
            pos["closing_in_progress"] = False
            continue
        
        # Get FRESH current bid price
        current_bid = format_price(market.get("yes_bid"))
        if current_bid is None:
            if VERBOSE:
                print(f"âš ï¸ Cannot close {market_ticker}: no bid price in fresh data")
            pos["closing_in_progress"] = False
            continue
        
        # RE-VALIDATE: Check if selling is still better than holding (prices may have changed)
        stored_check_result = pos.get("closing_check_result")
        if stored_check_result:
            # SKIP re-validation for 7% absolute exit - it should execute no matter what
            if stored_check_result.get("kalshi_price_triggered"):
                # 7% exit bypasses all re-validation - proceed directly to sell
                if VERBOSE:
                    print(f"âœ… 7% absolute exit - skipping re-validation, executing immediately")
            else:
                # Re-validation for other exit reasons (profit protection, max profit, trailing stop, etc.)
                try:
                    # Get all positions for this event to find both sides
                    evt_key = event_key(pos.get("event_ticker"))
                    event_positions_all = [p for p in positions if event_key(p.get("event_ticker")) == evt_key and not p.get("settled", False)]
                    
                    # Find both sides
                    side_A_ticker = None
                    side_B_ticker = None
                    for p in event_positions_all:
                        if p.get("market_ticker") == market_ticker:
                            # Find the other side
                            for other_pos in event_positions_all:
                                if other_pos.get("market_ticker") != market_ticker:
                                    side_A_ticker = market_ticker
                                    side_B_ticker = other_pos.get("market_ticker")
                                    break
                            break
                    
                    if side_A_ticker and side_B_ticker:
                        side_A_market_fresh = next((m for m in fresh_markets if m.get("ticker") == side_A_ticker), None)
                        side_B_market_fresh = next((m for m in fresh_markets if m.get("ticker") == side_B_ticker), None)
                        side_A_positions = [p for p in event_positions_all if p.get("market_ticker") == side_A_ticker]
                        side_B_positions = [p for p in event_positions_all if p.get("market_ticker") == side_B_ticker]
                        
                        if side_A_market_fresh and side_B_market_fresh:
                            side_A_bid_fresh = format_price(side_A_market_fresh.get("yes_bid"))
                            side_B_bid_fresh = format_price(side_B_market_fresh.get("yes_bid"))
                            
                            if side_A_bid_fresh and side_B_bid_fresh:
                                # Keep max_price tracking updated during closing flows
                                for p in side_A_positions:
                                    p["max_price"] = max(p.get("max_price", 0.0), float(side_A_bid_fresh))
                                for p in side_B_positions:
                                    p["max_price"] = max(p.get("max_price", 0.0), float(side_B_bid_fresh))

                                # Re-calculate sell prices
                                side_A_sell_fresh = max(0.01, side_A_bid_fresh - TICK)
                                side_B_sell_fresh = max(0.01, side_B_bid_fresh - TICK)
                                
                                # Re-calculate current profit with fresh prices
                                qty_A, entry_A, _ = aggregate_positions_on_side(side_A_positions, side_A_ticker)
                                qty_B, entry_B, _ = aggregate_positions_on_side(side_B_positions, side_B_ticker)
                                
                                if qty_A > 0 and qty_B > 0:
                                    _, current_profit_pct_fresh, roi_A, roi_B = calculate_current_profit_mtm(
                                        qty_A, entry_A, qty_B, entry_B,
                                        side_A_sell_fresh, side_B_sell_fresh
                                    )
                                    
                                    # Calculate settlement ROI using WEIGHTED AVERAGE (same as main decision logic)
                                    # This ensures re-validation is consistent with the exit decision
                                    roi_A_settle, roi_B_settle = hedge_outcome_rois(qty_A, entry_A, qty_B, entry_B)
                                    
                                    # Calculate probabilities from fresh prices (market's current view)
                                    total_price_fresh = side_A_sell_fresh + side_B_sell_fresh
                                    if total_price_fresh > 0:
                                        prob_A_fresh = side_A_sell_fresh / total_price_fresh
                                        prob_B_fresh = side_B_sell_fresh / total_price_fresh
                                    else:
                                        # Fallback to 50/50 if prices are invalid
                                        prob_A_fresh = 0.5
                                        prob_B_fresh = 0.5
                                    
                                    # Expected settlement ROI = probability-weighted average
                                    weighted_settlement_roi_fresh = (prob_A_fresh * roi_A_settle) + (prob_B_fresh * roi_B_settle)
                                    
                                    # Use calculate_theoretical_max_profit for consistency with decision phase
                                    _, max_settlement_roi = calculate_theoretical_max_profit(qty_A, entry_A, qty_B, entry_B)
                                    
                                    # Only proceed if still profitable vs WEIGHTED settlement
                                    if current_profit_pct_fresh < weighted_settlement_roi_fresh:
                                        if VERBOSE:
                                            print(f"âš ï¸ Canceling sell: Current profit {current_profit_pct_fresh:.2%} < weighted settlement {weighted_settlement_roi_fresh:.2%} "
                                                  f"(prob: {prob_A_fresh:.1%}/{prob_B_fresh:.1%}, outcomes: {roi_A_settle:.2%}/{roi_B_settle:.2%}) - prices changed unfavorably")
                                        pos["closing_in_progress"] = False
                                        pos.pop("closing_check_result", None)  # Remove stored check result
                                        continue
                                
                                # For max profit detection, re-check ratio
                                if stored_check_result.get("reason", "").startswith("max_profit"):
                                    max_profit_ratio_fresh = current_profit_pct_fresh / max_settlement_roi if max_settlement_roi > 0 else 0.0
                                    if max_profit_ratio_fresh < MAX_PROFIT_THRESHOLD:
                                        if VERBOSE:
                                            print(f"âš ï¸ Canceling sell: Ratio dropped to {max_profit_ratio_fresh:.0%} < {MAX_PROFIT_THRESHOLD:.0%} - prices changed unfavorably")
                                        pos["closing_in_progress"] = False
                                        pos.pop("closing_check_result", None)
                                        continue
                                
                                # For trailing stop, re-check drop from peak
                                if stored_check_result.get("reason", "").startswith("trailing_stop"):
                                    # Re-check if still below trailing stop threshold
                                    peak_profit_pct = stored_check_result.get("peak_profit_pct", 0)
                                    if peak_profit_pct > 0:
                                        drop_from_peak_fresh = max(0.0, peak_profit_pct - current_profit_pct_fresh)
                                        if peak_profit_pct >= TRAILING_STOP_TIGHTEN_THRESHOLD:
                                            stop_distance = TRAILING_STOP_TIGHTENED_PCT
                                        else:
                                            stop_distance = TRAILING_STOP_INITIAL_PCT
                                        
                                        if drop_from_peak_fresh < stop_distance:
                                            if VERBOSE:
                                                print(f"âš ï¸ Canceling sell: Drop from peak {drop_from_peak_fresh:.2%} < stop distance {stop_distance:.0%} - prices recovered")
                                            pos["closing_in_progress"] = False
                                            pos.pop("closing_check_result", None)
                                            continue
                except Exception as e:
                    if VERBOSE:
                        print(f"âš ï¸ Error re-validating prices for {market_ticker}: {e} - proceeding with caution")
                    # Continue with sell if re-validation fails (better to sell than get stuck)
        
        # Calculate actual sell price (use best bid for aggressive exit)
        # For odds feed or Kalshi price partial exits, use the actual best bid price
        stored_check_result = pos.get("closing_check_result", {})
        if stored_check_result.get("odds_feed_triggered") or stored_check_result.get("kalshi_price_triggered"):
            # Odds feed or Kalshi price exit: use best bid price (aggressive exit at threshold, default 10%)
            sell_price = max(0.01, current_bid)
        else:
            # Normal profit protection: use bid - 1 tick for guaranteed fill
            sell_price = max(0.01, current_bid - TICK)
        
        reason = pos.get("exit_reason", "profit_protection")
        side_display = pos.get('side_name', '')
        match_display = pos.get('match', '')
        side_info = f"{side_display} " if side_display else ""
        match_info = f"{match_display} " if match_display else ""
        print(f"ðŸ’° Selling {stake_to_sell} contracts of {match_info}{side_info}{market_ticker} at {sell_price:.2%} "
              f"(bid: {current_bid:.2%}) - {reason}")
        
        try:
            # ðŸ›¡ï¸ SAFETY CHECK: Verify we actually have the position before selling
            # Use local positions.json instead of live API check (live check doesn't work reliably)
            if PLACE_LIVE_KALSHI_ORDERS == "YES":
                try:
                    # Check local positions list instead of live API
                    local_pos = next(
                        (p for p in positions 
                         if p.get("market_ticker") == market_ticker 
                         and p.get("side", "").lower() == "yes"
                         and not p.get("settled", False)),
                        None
                    )
                    
                    if not local_pos:
                        print(f"ðŸ›¡ï¸ SELL PREVENTION: Cannot sell {stake_to_sell} contracts - no position found in positions.json for {market_ticker}")
                        # Clear closing flag since we don't have the position
                        pos["closing_in_progress"] = False
                        pos.pop("closing_check_result", None)
                        pos.pop("closing_initiated_at", None)
                        continue
                    
                    local_qty = int(local_pos.get("stake", 0))
                    if local_qty == 0:
                        print(f"ðŸ›¡ï¸ SELL PREVENTION: Cannot sell {stake_to_sell} contracts - position in positions.json has 0 stake for {market_ticker}")
                        pos["closing_in_progress"] = False
                        pos.pop("closing_check_result", None)
                        pos.pop("closing_initiated_at", None)
                        continue
                    
                    if local_qty < stake_to_sell:
                        print(f"âš ï¸ Adjusting profit protection sell quantity from {stake_to_sell} to {local_qty} (actual position in positions.json)")
                        stake_to_sell = local_qty
                except Exception as e:
                    print(f"âš ï¸ Could not verify position in positions.json before sell: {e}")
                    # Continue anyway - better to try to sell than get stuck
            
            # Place sell order
            sell_resp = prepare_kalshi_order(
                market_ticker=market_ticker,
                side="yes",
                price=sell_price,
                quantity=stake_to_sell,
                action="sell"
            )
            
            sell_order_id, sell_client_oid = _extract_order_id(sell_resp)
            if sell_order_id:
                # âœ… IMMEDIATELY reduce stake to 0 to prevent double-selling on next loop iteration
                # This prevents the position from being evaluated again before the fill completes
                pos["stake"] = 0
                pos["settled"] = True  # Mark as settled so it won't be shown in open positions
                save_positions()  # Save immediately to persist the change
                
                # Wait for fill
                sell_status, sell_filled_qty = wait_for_fill_or_cancel(
                    sell_order_id,
                    client_order_id=sell_client_oid,
                    timeout_s=ORDER_FILL_TIME,
                    poll_s=1.0,
                    expected_count=stake_to_sell,
                    require_full=False,
                    verify_ticker=market_ticker,
                    verify_side="yes"
                )
                
                if sell_filled_qty > 0:
                    side_display = pos.get('side_name', '')
                    match_display = pos.get('match', '')
                    side_info = f"{side_display} " if side_display else ""
                    match_info = f"{match_display} " if match_display else ""
                    print(f"âœ… Profit protection exit executed: Sold {match_info}{side_info}{sell_filled_qty} contracts at {sell_price:.2%}")
                    
                    # Mark event as 7% exited to prevent re-entry (if this was a 7% exit)
                    if stored_check_result.get("kalshi_price_triggered"):
                        evt_ticker = pos.get("event_ticker")
                        if evt_ticker:
                            mark_event_7pct_exited(evt_ticker)
                            # Record which market ticker exited at 7% to disable stop loss on the other side
                            evt_key_exit = event_key(evt_ticker)
                            partial_exit_side = stored_check_result.get("partial_exit_side")
                            if partial_exit_side:
                                # Store the market ticker of the position that exited
                                exited_ticker = pos.get("market_ticker")
                                if exited_ticker:
                                    EVENT_7PCT_EXITED_SIDE[evt_key_exit] = exited_ticker
                                    if VERBOSE:
                                        print(f"ðŸ“ Recorded 7% exit on market {exited_ticker} (side {partial_exit_side}) for event {evt_key_exit} - stop loss disabled on other side")
                    
                    # Update stake (reduce by sold amount)
                    pos["stake"] = max(0, pos.get("stake", 0) - sell_filled_qty)
                    if pos["stake"] <= 0:
                        pos["settled"] = True
                        pos["exit_reason"] = reason
                        pos["closing_in_progress"] = False  # Clear flag when fully closed
                    else:
                        # Partial fill - clear flags so next loop can re-evaluate and re-queue with fresh prices
                        if VERBOSE:
                            print(f"âš ï¸ Partial fill: {sell_filled_qty}/{stake_to_sell} contracts sold, {pos['stake']} remaining")
                        pos["closing_in_progress"] = False
                        pos.pop("closing_check_result", None)
                        pos.pop("closing_initiated_at", None)
                else:
                    print(f"âš ï¸ Profit protection sell order not filled: {sell_status}")
                    # Clear closing flag to allow retry on next loop
                    pos["closing_in_progress"] = False
                    pos.pop("closing_check_result", None)
                    pos.pop("closing_initiated_at", None)
                    # Don't mark as settled - will retry next loop
            else:
                print(f"âš ï¸ Could not extract order ID from profit protection sell order")
                # Clear closing flag to allow retry on next loop
                pos["closing_in_progress"] = False
                pos.pop("closing_check_result", None)
                pos.pop("closing_initiated_at", None)
# === MAIN LOOP ===
# === MAIN LOOP ===
# === MAIN LOOP ===
# === MAIN LOOP ===
if __name__ == "__main__":
    print("ðŸš€ Arbitrage bot starting...")

    # âœ… Resolve which positions.json we should keep in sync with
    POSITIONS_FILE = resolve_positions_file()

    # ðŸ§­ Auto-skip user prompt for AWS/unattended deployment
    # Note: Position cleanup happens automatically in the main loop every 5 minutes
    if os.path.exists(POSITIONS_FILE):
        print(f"ðŸ“‚ Found existing {POSITIONS_FILE} â€” will keep existing positions and auto-cleanup old ones.")
    else:
        print(f"ðŸ“­ No existing {POSITIONS_FILE} found â€” a new one will be created if needed.")    

    # âœ… Load existing positions once at startup
    if os.path.exists(POSITIONS_FILE):
        try:
            positions = load_positions() or []

            print(f"ðŸ’¾ Loaded {len(positions)} existing positions from {POSITIONS_FILE}")
            # ðŸ”§ NEW: normalize and deduplicate for hedge recognition
            normalize_loaded_positions()
            deduplicate_positions()  # optional, but strongly recommended
            
            # âœ… Sync with live Kalshi positions at startup to catch any manual trades or fills
            if PLACE_LIVE_KALSHI_ORDERS == "YES":
                print("ðŸ”„ Syncing positions with live Kalshi data at startup...")
                reconcile_positions()
                open_count = len([p for p in positions if not p.get('settled', False)])
                print(f"ðŸ“Š Positions after sync: {open_count} open")
        except Exception as e:
            print(f"âš ï¸ Failed to load {POSITIONS_FILE}: {e}")
            positions = []
    else:
        print(f"ðŸ“­ No existing {POSITIONS_FILE} found â€” creating new file.")
        positions = []
        # Optional: create an empty positions.json if it doesn't exist
        with open(POSITIONS_FILE, "w") as f:
            json.dump([], f, indent=2)
        
        # âœ… Sync with live Kalshi positions even if no local file exists (in case of manual trades)
        if PLACE_LIVE_KALSHI_ORDERS == "YES":
            print("ðŸ”„ Syncing with live Kalshi positions at startup...")
            reconcile_positions()
            open_count = len([p for p in positions if not p.get('settled', False)])
            print(f"ðŸ“Š Positions after sync: {open_count} open")
    
    # âœ… Load first detection times at startup
    print(f"ðŸ“‚ Using first detection times file: {FIRST_DETECTION_TIMES_FILE}")
    loaded_times = load_first_detection_times()
    if loaded_times:
        print(f"â±ï¸ Loaded {len(loaded_times)} first detection times from {FIRST_DETECTION_TIMES_FILE}")
    else:
        print(f"ðŸ“­ No existing first detection times found â€” will create on first match.")
    
    # ðŸ§­ Restore event locks between runs
    try:
        event_locks_path = os.path.join(BASE_DIR, "event_locks.json")
        if os.path.exists(event_locks_path):
            with open(event_locks_path, "r") as f:
                EVENT_LOCKED_TILL_HEDGE = {event_key(t) for t in json.load(f)}
            print(f"ðŸ”’ Restored {len(EVENT_LOCKED_TILL_HEDGE)} locked events from file.")
            prune_event_locks()
        else:
            EVENT_LOCKED_TILL_HEDGE = set()
    except Exception as e:
        print(f"âš ï¸ Could not load event locks: {e}")
        EVENT_LOCKED_TILL_HEDGE = set()
    
    # ðŸ§­ Stop-lossed events tracking with timestamps and entry prices (allows re-entry if price recovers)
    EVENT_STOP_LOSSED = {}  # Dict: {event_key: {"timestamp": ..., "entry_price": ...}}
    try:
        event_stop_lossed_path = os.path.join(BASE_DIR, "event_stop_lossed.json")
        if os.path.exists(event_stop_lossed_path):
            with open(event_stop_lossed_path, "r") as f:
                data = json.load(f)
                # Handle old format (list) and convert to new format
                if isinstance(data, list):
                    # Old format: convert to new format with current time
                    print(f"âš ï¸ Converting old event_stop_lossed.json format to new timestamp format")
                    current_time = time.time()
                    EVENT_STOP_LOSSED = {event_key(t): {"timestamp": current_time, "entry_price": None} for t in data}
                    persist_stop_lossed_events()  # Save in new format
                elif isinstance(data, dict):
                    # New format: load timestamps and entry prices
                    for key, value in data.items():
                        try:
                            if isinstance(value, dict):
                                # New format with timestamp and entry_price
                                timestamp_val = value.get("timestamp")
                                entry_price_val = value.get("entry_price")
                                
                                if isinstance(timestamp_val, (int, float)):
                                    EVENT_STOP_LOSSED[key] = {"timestamp": timestamp_val, "entry_price": entry_price_val}
                                elif isinstance(timestamp_val, str):
                                    # Parse ISO format
                                    dt = datetime.fromisoformat(timestamp_val.replace('Z', '+00:00'))
                                    EVENT_STOP_LOSSED[key] = {"timestamp": dt.timestamp(), "entry_price": entry_price_val}
                                else:
                                    print(f"âš ï¸ Could not parse timestamp for {key}: {timestamp_val}")
                            elif isinstance(value, (int, float)):
                                # Old format: just timestamp, convert to new format
                                EVENT_STOP_LOSSED[key] = {"timestamp": value, "entry_price": None}
                            elif isinstance(value, str):
                                # Old format: ISO string timestamp, convert to new format
                                dt = datetime.fromisoformat(value.replace('Z', '+00:00'))
                                EVENT_STOP_LOSSED[key] = {"timestamp": dt.timestamp(), "entry_price": None}
                        except Exception as e:
                            print(f"âš ï¸ Could not parse stop loss data for {key}: {e}")
                    
                    # Clean up expired entries (older than cooldown period)
                    current_time = time.time()
                    expired_keys = [
                        key for key, data in EVENT_STOP_LOSSED.items()
                        if isinstance(data, dict) and (current_time - data.get("timestamp", 0)) >= (MIN_LOCKOUT_PERIOD * 60)
                    ]
                    for key in expired_keys:
                        del EVENT_STOP_LOSSED[key]
                    if expired_keys:
                        persist_stop_lossed_events()
                    print(f"ðŸš« Restored {len(EVENT_STOP_LOSSED)} stop-lossed events from file (cooldown active until price recovers).")
                else:
                    EVENT_STOP_LOSSED = {}
        else:
            EVENT_STOP_LOSSED = {}
    except Exception as e:
        print(f"âš ï¸ Could not load stop-lossed events: {e}")
        EVENT_STOP_LOSSED = {}
    
    # âœ… Load 7% exited events at startup
    event_7pct_exited_path = os.path.join(BASE_DIR, "event_7pct_exited.json")
    if os.path.exists(event_7pct_exited_path):
        try:
            with open(event_7pct_exited_path, "r") as f:
                EVENT_7PCT_EXITED = {event_key(t) for t in json.load(f)}
            print(f"ðŸš« Restored {len(EVENT_7PCT_EXITED)} 7% exited events from file (no new entries allowed).")
        except Exception as e:
            print(f"âš ï¸ Could not load 7% exited events: {e}")
            EVENT_7PCT_EXITED = set()
    else:
        EVENT_7PCT_EXITED = set()


    # ðŸ“Š Verification block â€” show loaded trades
    print(f"ðŸ“‚ Using positions file: {POSITIONS_FILE}")
    if positions:
        # âœ… Only show open (non-settled) positions
        open_positions = [p for p in positions if not p.get("settled", False)]
        if open_positions:
            print(f"ðŸ“Š Loaded {len(open_positions)} open positions:")
            for p in open_positions:
                print(f"   - {p['match']} | {p['side'].upper()} x{p['stake']} @ {p['entry_price']:.2%}")
        else:
            print("ðŸ“­ No open positions found in file.")
    else:
        print("ðŸ“­ No existing positions found in file.")

    # âœ… Just announce mode â€” don't reload positions again
    if PLACE_LIVE_KALSHI_ORDERS == "YES":
        print("ðŸ”’ Live mode â€” preserving loaded positions.")
    else:
        print("ðŸ§ª Simulation mode â€” preserving loaded positions.")

    # âœ… Do NOT reset or reload positions again here
    # load_positions()      # âŒ REMOVE
    # reconcile_positions() # âŒ REMOVE

    # âœ… Start session with clean balance and portfolio value
    if PLACE_LIVE_KALSHI_ORDERS == "YES":
        SESSION_START_BAL = get_kalshi_balance(force=True)
        SESSION_START_PORTFOLIO_VALUE = get_kalshi_portfolio_value(force=True)
    else:
        SESSION_START_BAL = CAPITAL_SIM
        SESSION_START_PORTFOLIO_VALUE = None

    SESSION_START_TIME = now_utc()
    portfolio_msg = f" | starting portfolio value: ${SESSION_START_PORTFOLIO_VALUE:.2f}" if SESSION_START_PORTFOLIO_VALUE is not None else ""
    print(f"ðŸ•’ Session baseline set at {SESSION_START_TIME.isoformat()} â€” "
          f"starting balance: ${SESSION_START_BAL:.2f}{portfolio_msg}")

    last_positions_email_ts = 0.0
    if SEND_EMAIL_TURN_ON:
        send_positions_email(reason="startup / running now")
        last_positions_email_ts = time.time()

    # Reset metrics at session start
    for k in METRICS:
        if isinstance(METRICS[k], dict):
            METRICS[k].clear()
        else:
            METRICS[k] = 0 if not isinstance(METRICS[k], float) else 0.0

    # === Main loop: Check existing matches every 10s, discover new games every 5m ===
    ACTIVE_MATCH_REFRESH = 300  # 5 minutes for discovering new games
    LAST_DISCOVERY_TS = 0.0
    next_discovery_ts = 0.0
    active_matches: List[Dict[str, Any]] = []
    latest_raw_events: Optional[List[Dict[str, Any]]] = None

    try:
        while True:
            try:
                now = time.time()
                just_discovered = False  # Initialize flag for each iteration

                # ðŸ”„ Every 5 minutes, discover new overlaps
                if now >= next_discovery_ts:
                    print("ðŸ”Ž Refreshing active matches from Odds API + Kalshi...")
                    latest_raw_events = _fetch_odds_feed_live_events()
                    active_matches = get_overlapping_matches(preloaded_events=latest_raw_events)
                    discovery_ts = time.time()
                    LAST_DISCOVERY_TS = discovery_ts
                    if not active_matches:
                        next_discovery_ts = discovery_ts + NO_OVERLAP_SLEEP_SECS
                        minutes = int(NO_OVERLAP_SLEEP_SECS / 60)
                        print(f"ðŸ˜´ No overlapping matches found â€” sleeping for {minutes} minutes before next scan.")
                        time.sleep(NO_OVERLAP_SLEEP_SECS)
                        active_matches = []
                        continue
                    for match in active_matches:
                        match["discovered_ts"] = discovery_ts
                        match["last_seen_ts"] = discovery_ts
                        # âœ… Record first detection time for FIRST_TRADE_WINDOW_MINUTES constraint
                        ticker = match.get("ticker", "")
                        if ticker:
                            record_first_detection_time(ticker, now_utc())
                    next_discovery_ts = discovery_ts + ACTIVE_MATCH_REFRESH
                    # ðŸ§­ Refresh tracking of open positions against current active matches
                    refresh_position_tracking(active_matches)

                    # ðŸ§© Keep local positions clean unless manual-preserve is enabled
                    if PRESERVE_MANUAL_POSITIONS:
                        print("âš ï¸ Position purge skipped â€” preserving manual positions.json entries.")
                    else:
                        purge_old_positions()
                        purge_stale_positions(hours=4, active_matches=active_matches)
                        purge_stale_live_positions(hours=12)

                    # ðŸ”„ Always reconcile local positions with live Kalshi feed
                    if PLACE_LIVE_KALSHI_ORDERS == "YES":
                        live_positions = get_live_positions()
                        if live_positions:
                            print(f"ðŸ“Š Found {len(live_positions)} live Kalshi positions:")
                            for lp in live_positions:
                                print(f"   - {lp['ticker']} | {lp['side'].upper()} {lp['contracts']} @ {lp['avg_price']:.2%}")
                        else:
                            print("ðŸ“­ No live positions currently on Kalshi.")

                        # âœ… Replace local positions if they got lost
                        if not positions and live_positions:
                            print("ðŸ”„ Rebuilding local positions list from Kalshi...")
                            for lp in live_positions:
                                positions.append({
                                    "match": lp["ticker"],  # placeholder; you can refine mapping
                                    "side": lp["side"],
                                    "event_ticker": (lp.get("event_ticker") or "").upper(),
                                    "market_ticker": lp["ticker"],
                                    "entry_price": lp["avg_price"],
                                    "entry_time": now_utc().isoformat(),
                                    "stake": lp["contracts"],
                                    "effective_entry": lp["avg_price"],
                                    "odds_prob": 0.5,  # unknown, neutral placeholder
                                })
                    
                    # ðŸš€ Mark that we just discovered new matches
                    # Don't run engine yet - we'll refresh markets first then run engine once
                    just_discovered = True
                    print(f"ðŸš€ Discovered {len(active_matches)} new matches, will evaluate after market refresh...")
                    for match in active_matches:
                        log_snapshot_scan(match)
                else:
                    just_discovered = False

                if SEND_EMAIL_TURN_ON and (time.time() - last_positions_email_ts) >= EMAIL_INTERVAL_SECS:
                    send_positions_email(reason="hourly")
                    last_positions_email_ts = time.time()

                # ðŸ”„ Every 10 seconds: Re-evaluate all active matches (refresh odds/score and Kalshi markets)
                # This happens on every loop iteration, regardless of whether we discovered new matches
                if active_matches:
                    print(f"ðŸ”„ Checking {len(active_matches)} existing overlapping matches...")
                    # Refresh odds/score data and Kalshi markets for all active matches
                    for match in active_matches:
                        # Refresh odds, score, and clock data from BetsAPI
                        evt_id = match.get("id")
                        match_name = match.get("match", "Unknown")
                        if evt_id:
                            try:
                                # Always fetch fresh odds from BetsAPI (no caching)
                                # Cache-busting is handled in _betsapi_request
                                moneyline = fetch_event_moneyline(str(evt_id))
                                if moneyline:
                                    match.setdefault("odds_feed", {})
                                    
                                    # Get old values for comparison
                                    old_home_odds = match["odds_feed"].get("home_odds")
                                    old_away_odds = match["odds_feed"].get("away_odds")
                                    
                                    # Update odds (convert to float)
                                    home_odds_new = float(moneyline.get("home_odds", 0))
                                    away_odds_new = float(moneyline.get("away_odds", 0))
                                    
                                    if home_odds_new > 0 and away_odds_new > 0:
                                        # Convert decimal odds â†’ implied probabilities
                                        implied_home = 1.0 / home_odds_new
                                        implied_away = 1.0 / away_odds_new
                                        
                                        # Proportional devig (simple)
                                        fair_prop_home, fair_prop_away = devig_proportional([implied_home, implied_away])
                                        
                                        # Shin devig (advanced)
                                        fair_shin_home, fair_shin_away = devig_shin_two_way(home_odds_new, away_odds_new)
                                        
                                        # Use Shin devig by default (same as discovery)
                                        if USE_SHIN_DEVIG:
                                            home_prob_new = fair_shin_home
                                            away_prob_new = fair_shin_away
                                        else:
                                            home_prob_new = fair_prop_home
                                            away_prob_new = fair_prop_away
                                        
                                        # Always update odds and probabilities (even if same values)
                                        match["odds_feed"]["home_odds"] = home_odds_new
                                        match["odds_feed"]["away_odds"] = away_odds_new
                                        match["odds_feed"]["home_prob"] = home_prob_new
                                        match["odds_feed"]["away_prob"] = away_prob_new
                                        
                                        # Debug: show if odds changed
                                        if old_home_odds is not None and (abs(old_home_odds - home_odds_new) > 0.01 or abs(old_away_odds - away_odds_new) > 0.01):
                                            print(f"   ðŸ“Š {match_name}: Odds updated | Home: {old_home_odds:.2f}â†’{home_odds_new:.2f} | Away: {old_away_odds:.2f}â†’{away_odds_new:.2f}")
                                    else:
                                        print(f"   âš ï¸ {match_name}: Invalid odds from BetsAPI (home={home_odds_new}, away={away_odds_new})")
                                    
                                    # Update score and clock
                                    match["odds_feed"]["score_snapshot"] = moneyline.get("score_snapshot")
                                    match["odds_feed"]["period_clock"] = moneyline.get("period_clock")
                                    
                                    # Update last_update timestamp
                                    match["odds_feed"]["last_update_ts"] = time.time()
                                    match["odds_feed"]["last_update_iso"] = datetime.utcnow().isoformat() + "Z"
                                else:
                                    print(f"   âš ï¸ {match_name}: No odds returned from BetsAPI (using cached)")
                                
                                # Small delay to avoid rate limiting
                                time.sleep(0.1)
                            except Exception as e:
                                # Log fetch failures instead of silently ignoring
                                print(f"   âŒ {match_name}: Error fetching odds: {e} (using cached)")
                        
                        # Always refresh Kalshi markets to get latest prices
                        kalshi_markets = get_kalshi_markets(match["ticker"], force_live=True)
                        # Handle rate limiting (None) or filter active markets
                        if kalshi_markets:
                            match["kalshi"] = [
                                m for m in kalshi_markets
                                if m.get("status") == "active" and (m.get("yes_bid") or m.get("yes_ask"))
                            ]
                        else:
                            # Rate limited or no markets - keep existing or set to empty
                            match["kalshi"] = match.get("kalshi", [])
                    # Always re-evaluate all active matches every 10 seconds
                    for match in active_matches:
                        log_snapshot_scan(match)
                    
                    # âœ… Reconcile positions BEFORE running engine to ensure latest trades are visible
                    # This ensures positions placed by the bot (or manually) are synced into local state
                    # BEFORE the engine evaluates what to do next
                    if PLACE_LIVE_KALSHI_ORDERS == "YES":
                        reconcile_positions()
                    
                    run_engine(active_matches)

                # âœ… Reconcile again AFTER engine to catch any new fills from orders placed during engine run
                # This ensures positions placed by the bot (or manually) are synced into local state
                if PLACE_LIVE_KALSHI_ORDERS == "YES":
                    reconcile_positions()
                    realize_if_settled()
                else:
                    print("ðŸ›¡ï¸ Skipping reconcile_positions() and realize_if_settled() in SIM mode")
                
                # ðŸ›¡ï¸ Don't write to file if list is empty (prevents wiping manual JSON)
                if not positions:
                    print("âš ï¸ positions list empty â€” skipping save to protect manual positions.json")
                else:
                    print(f"ðŸ’¾ Saving {len(positions)} open positions")
                    save_positions()

                show_book()

                # ðŸš¨ Kill-switch check
                current_balance = get_kalshi_balance()
                if SESSION_START_BAL and SESSION_START_BAL > 0:
                    session_pnl = current_balance - SESSION_START_BAL
                    session_roi = session_pnl / SESSION_START_BAL
               
                _metrics_flush_periodic()

                time.sleep(REFRESH_ACTIVE if positions else REFRESH_IDLE)
            
            except Exception as loop_err:
                # Catch errors within loop iteration to prevent crash
                print(f"âš ï¸ Error in main loop iteration: {loop_err}")
                import traceback
                traceback.print_exc()
                # Save positions on error
                try:
                    save_positions()
                    print("ðŸ’¾ Positions saved after loop error.")
                except Exception as save_err:
                    print(f"âš ï¸ Failed to save positions: {save_err}")
                # Wait before retrying to avoid rapid error loops
                print("â³ Waiting 30 seconds before retrying loop...")
                time.sleep(30)
                continue  # Continue to next iteration

    except KeyboardInterrupt:
        print("ðŸ›‘ Bot stopped by user.")
        # Save positions before exiting
        try:
            save_positions()
            print("ðŸ’¾ Positions saved before exit.")
        except Exception as e:
            print(f"âš ï¸ Failed to save positions on exit: {e}")
        for trade in closed_trades:
            print(f"ðŸ“‹ {trade['match']} | PnL: ${trade['pnl']:.2f}")
    except Exception as e:
        # Catch any unexpected errors to prevent crash
        print(f"âŒ Unexpected error in main loop: {e}")
        import traceback
        traceback.print_exc()
        # Save positions before continuing
        try:
            save_positions()
            print("ðŸ’¾ Positions saved after error.")
        except Exception as save_err:
            print(f"âš ï¸ Failed to save positions after error: {save_err}")
        # Wait a bit before retrying to avoid rapid error loops
        print("â³ Waiting 60 seconds before retrying...")
        time.sleep(60)
