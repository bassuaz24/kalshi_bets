"""
OddsAPI client for fetching market data.
Data is separated by league for sports, by market otherwise.
"""

import os
import sys
import requests
import pandas as pd
from typing import Dict, List, Optional, Any, Tuple
from datetime import datetime, timedelta, date
import pytz
from pathlib import Path

# Add base directory to path
_BASE_ROOT = Path(__file__).parent.parent.absolute()
if str(_BASE_ROOT) not in sys.path:
    sys.path.insert(0, str(_BASE_ROOT))

from config import settings

UTC = pytz.utc
CST = pytz.timezone("America/Chicago")


def _as_cst_datetime(value) -> datetime:
    """Convert value to CST datetime."""
    if value is None:
        raise ValueError("Missing datetime value")
    if isinstance(value, datetime):
        dt = value
    else:
        dt = datetime.fromisoformat(str(value).replace("Z", "+00:00"))
    if dt.tzinfo is None:
        dt = UTC.localize(dt)
    return dt.astimezone(CST)


def convert_to_cst(value) -> str:
    """Convert datetime to CST string."""
    return _as_cst_datetime(value).strftime("%Y-%m-%d %H:%M:%S %Z")


def fetch_odds(sport_key: str) -> Optional[List[Dict[str, Any]]]:
    """Fetch odds from OddsAPI for a sport."""
    if not settings.ODDS_API_KEY:
        print(f"‚ö†Ô∏è ODDS_API_KEY not set, skipping fetch for {sport_key}")
        return None

    url = f"{settings.ODDS_API_BASE}/sports/{sport_key}/odds/"
    params = {
        "apiKey": settings.ODDS_API_KEY,
        "regions": settings.ODDS_API_REGION,
        "markets": settings.ODDS_API_MARKETS,
        "bookmakers": ",".join(settings.ODDS_API_BOOKMAKERS),
        "oddsFormat": "decimal",
        "dateFormat": "iso"
    }

    try:
        resp = requests.get(url, params=params, timeout=10)

        if resp.status_code != 200:
            print(f"‚ùå Error fetching {sport_key}: {resp.status_code} - {resp.text[:200]}")
            return None
        data = resp.json()

        # Debug: Log API response structure
        if settings.VERBOSE and data:
            print(f"üì° OddsAPI returned {len(data)} games for {sport_key}")
            if len(data) > 0:
                # Sample first game structure
                sample = data[0]
                print(f"   Sample game structure:")
                print(f"     - ID: {sample.get('id')}")
                print(f"     - Home: {sample.get('home_team')}")
                print(f"     - Away: {sample.get('away_team')}")
                print(f"     - Commence: {sample.get('commence_time')}")
                print(f"     - Bookmakers: {len(sample.get('bookmakers', []))}")
                if sample.get('bookmakers'):
                    for bm in sample.get('bookmakers', [])[:2]:  # First 2 bookmakers
                        print(f"       - {bm.get('title')}: {len(bm.get('markets', []))} markets")
        
        return data
    except Exception as e:
        print(f"‚ùå Exception fetching {sport_key}: {e}")
        return None


def fetch_kalshi_markets(event_ticker: Optional[str] = None) -> List[Dict[str, Any]]:
    """Fetch all active Kalshi markets, optionally filtered by event ticker."""
    from kalshi.markets import get_kalshi_markets
    
    if event_ticker:
        markets = get_kalshi_markets(event_ticker, force_live=True) or []
        return markets
    
    # If no event ticker, we'd need to fetch all events first
    # For now, return empty list - caller should provide event ticker
    return []


def normalize_odds_data(sport_name: str, games: List[Dict[str, Any]], target_dates: set) -> Tuple[Dict[str, List[Dict[str, Any]]], List[Dict[str, Any]]]:
    """Normalize OddsAPI data to rows organized by date and market.
    
    Returns:
        Tuple of (rows_by_date, skipped_games)
    """
    rows_by_date = {}
    skipped_games = []  # Track skipped games with details
    current_timestamp = datetime.now(CST).strftime("%Y-%m-%d %H:%M:%S %Z")
    
    # Track filtering statistics
    stats = {
        "total_games": len(games),
        "missing_commence_time": 0,
        "datetime_conversion_error": 0,
        "date_filtered": 0,
        "no_bookmakers": 0,
        "games_processed": 0,
        "games_with_no_rows": 0,  # Games that passed filters but produced no data
        "bookmakers_with_no_markets": 0,
        "markets_with_no_outcomes": 0,
        "outcomes_missing_price": 0,
        "rows_created": 0
    }

    for game in games:
        game_time = game.get("commence_time")
        home_team = game.get("home_team", "Unknown")
        away_team = game.get("away_team", "Unknown")
        game_id = game.get("id", "")
        sport_title = game.get("sport_title", "")
        bookmakers_count = len(game.get("bookmakers", []))
        
        if not game_time:
            stats["missing_commence_time"] += 1
            skipped_games.append({
                "timestamp": current_timestamp,
                "sport": sport_name,
                "league": sport_title,
                "game_id": game_id,
                "home_team": home_team,
                "away_team": away_team,
                "commence_time": "",
                "skip_reason": "missing_commence_time",
                "bookmakers_count": bookmakers_count,
                "details": "Game missing commence_time field"
            })

            continue
            
        try:
            game_time_cst = _as_cst_datetime(game_time)
            commence_time_str = convert_to_cst(game_time_cst)
        except Exception as e:
            stats["datetime_conversion_error"] += 1
            skipped_games.append({
                "timestamp": current_timestamp,
                "sport": sport_name,
                "league": sport_title,
                "game_id": game_id,
                "home_team": home_team,
                "away_team": away_team,
                "commence_time": str(game_time),
                "skip_reason": "datetime_conversion_error",
                "bookmakers_count": bookmakers_count,
                "details": f"Error converting datetime: {str(e)}"
            })
            if settings.VERBOSE:
                print(f"‚ö†Ô∏è Skipping game {home_team} vs {away_team}: datetime conversion error: {e}")
            continue
            
        game_date = game_time_cst.date()
        if game_date not in target_dates:
            stats["date_filtered"] += 1
            skipped_games.append({
                "timestamp": current_timestamp,
                "sport": sport_name,
                "league": sport_title,
                "game_id": game_id,
                "home_team": home_team,
                "away_team": away_team,
                "commence_time": commence_time_str,
                "skip_reason": "date_filtered",
                "bookmakers_count": bookmakers_count,
                "details": f"Game date {game_date} not in target dates {target_dates}"
            })
            continue

        bookmakers = game.get("bookmakers", [])
        if not bookmakers:
            stats["no_bookmakers"] += 1
            skipped_games.append({
                "timestamp": current_timestamp,
                "sport": sport_name,
                "league": sport_title,
                "game_id": game_id,
                "home_team": home_team,
                "away_team": away_team,
                "commence_time": commence_time_str,
                "skip_reason": "no_bookmakers",
                "bookmakers_count": 0,
                "details": "Game has no bookmakers available"
            })
            if settings.VERBOSE:
                print(f"‚ö†Ô∏è Skipping game {home_team} vs {away_team}: no bookmakers available")
            continue
        
        stats["games_processed"] += 1
        rows_before = stats["rows_created"]
        
        # Count markets and outcomes for diagnostics
        total_markets = 0
        total_outcomes = 0
        bookmaker_names = []

        for bookmaker in bookmakers:
            book_name = bookmaker["title"]
            bookmaker_names.append(book_name)
            markets = bookmaker.get("markets", [])
            if not markets:
                stats["bookmakers_with_no_markets"] += 1
                if settings.VERBOSE:
                    print(f"‚ö†Ô∏è Bookmaker {book_name} for {home_team} vs {away_team} has no markets")
                continue
                
            for market in markets:
                market_type = market.get("key")
                outcomes = market.get("outcomes", [])
                total_markets += 1
                
                if not outcomes:
                    stats["markets_with_no_outcomes"] += 1
                    if settings.VERBOSE:
                        print(f"‚ö†Ô∏è Market {market_type} from {book_name} for {home_team} vs {away_team} has no outcomes")
                    continue

                for outcome in outcomes:
                    price = outcome.get("price")
                    if price is None:
                        stats["outcomes_missing_price"] += 1
                        continue
                    total_outcomes += 1

                    rows_by_date.setdefault(game_date, []).append({
                        "sport": sport_name,
                        "league": sport_title,
                        "game_id": game_id,
                        "start_time": commence_time_str,
                        "bookmaker": book_name,
                        "market": market_type,
                        "team": outcome.get("name"),
                        "price": outcome.get("price"),
                        "point": outcome.get("point", None),
                        "home_team": home_team,
                        "away_team": away_team
                    })
                    stats["rows_created"] += 1
        
        # Check if this game produced any rows
        if stats["rows_created"] == rows_before:
            stats["games_with_no_rows"] += 1
            skipped_games.append({
                "timestamp": current_timestamp,
                "sport": sport_name,
                "league": sport_title,
                "game_id": game_id,
                "home_team": home_team,
                "away_team": away_team,
                "commence_time": commence_time_str,
                "skip_reason": "games_with_no_rows",
                "bookmakers_count": len(bookmakers),
                "bookmakers": ", ".join(bookmaker_names),
                "total_markets": total_markets,
                "total_outcomes": total_outcomes,
                "details": f"Game passed filters but produced no rows. Bookmakers: {len(bookmakers)}, Markets: {total_markets}, Outcomes: {total_outcomes}"
            })
            if settings.VERBOSE:
                print(f"‚ö†Ô∏è Game {home_team} vs {away_team} (ID: {game_id}) passed filters but produced no rows")
                print(f"   Bookmakers: {len(bookmakers)}, Markets per bookmaker: {[len(b.get('markets', [])) for b in bookmakers]}")
    
    # Print summary statistics
    if stats["total_games"] > 0:
        print(f"üìä OddsAPI filtering stats for {sport_name}:")
        print(f"   Total games: {stats['total_games']}")
        print(f"   Processed: {stats['games_processed']}")
        print(f"   Rows created: {stats['rows_created']}")
        if stats["missing_commence_time"] > 0:
            print(f"   ‚ö†Ô∏è Missing commence_time: {stats['missing_commence_time']}")
        if stats["datetime_conversion_error"] > 0:
            print(f"   ‚ö†Ô∏è Datetime conversion errors: {stats['datetime_conversion_error']}")
        if stats["date_filtered"] > 0:
            print(f"   ‚ö†Ô∏è Date filtered out: {stats['date_filtered']} (target dates: {target_dates})")
        if stats["no_bookmakers"] > 0:
            print(f"   ‚ö†Ô∏è No bookmakers: {stats['no_bookmakers']}")
        if stats["games_with_no_rows"] > 0:
            print(f"   ‚ö†Ô∏è Games with no rows (CRITICAL): {stats['games_with_no_rows']} - These games passed filters but produced no data!")
        if stats["bookmakers_with_no_markets"] > 0:
            print(f"   ‚ö†Ô∏è Bookmakers with no markets: {stats['bookmakers_with_no_markets']}")
        if stats["markets_with_no_outcomes"] > 0:
            print(f"   ‚ö†Ô∏è Markets with no outcomes: {stats['markets_with_no_outcomes']}")
        if stats["outcomes_missing_price"] > 0:
            print(f"   ‚ö†Ô∏è Outcomes missing price: {stats['outcomes_missing_price']}")

    return rows_by_date, skipped_games


def save_skipped_games(skipped_games: List[Dict[str, Any]], filepath: Path):
    """Save skipped games to CSV file."""
    if not skipped_games:
        return
    
    os.makedirs(filepath.parent, exist_ok=True)
    df = pd.DataFrame(skipped_games)
    
    # Ensure consistent column order
    columns = [
        "timestamp", "sport", "league", "game_id", "home_team", "away_team",
        "commence_time", "skip_reason", "bookmakers_count", "bookmakers",
        "total_markets", "total_outcomes", "details"
    ]
    
    # Only include columns that exist in the data
    existing_columns = [col for col in columns if col in df.columns]
    # Add any additional columns that weren't in the list
    for col in df.columns:
        if col not in existing_columns:
            existing_columns.append(col)
    
    df = df[existing_columns]
    
    # Append to existing file if it exists
    if filepath.exists():
        try:
            df_existing = pd.read_csv(filepath)
            df_combined = pd.concat([df_existing, df], ignore_index=True)
            # Remove duplicates based on game_id and timestamp
            df_combined = df_combined.drop_duplicates(subset=["game_id", "timestamp"], keep="last")  # type: ignore
            df_combined.to_csv(filepath, index=False)
        except Exception as e:
            # If append fails, just overwrite
            if settings.VERBOSE:
                print(f"‚ö†Ô∏è Failed to append to {filepath}: {e}, overwriting instead")
            df.to_csv(filepath, index=False)
    else:
        df.to_csv(filepath, index=False)


def save_market_data(
    data: List[Dict[str, Any]],
    filepath: Path,
    market_type: Optional[str] = None,
    append: bool = True,
    fetch_timestamp: Optional[datetime] = None,
):
    """Save market data to CSV file.
    
    Args:
        data: List of dictionaries to save
        filepath: Path to CSV file
        market_type: Optional market type (for logging)
        append: If True and file exists, append data (default: True)
        fetch_timestamp: Timestamp for this fetch (default: now in CST). Stored as ISO string.
    """
    if not data:
        return

    if fetch_timestamp is None:
        fetch_timestamp = datetime.now(CST)
    ts_str = fetch_timestamp.astimezone(CST).isoformat()

    os.makedirs(filepath.parent, exist_ok=True)
    df_new = pd.DataFrame(data)

    # Add fetch_timestamp to each row
    df_new["fetch_timestamp"] = ts_str

    columns = [
        "sport", "league", "game_id", "start_time",
        "bookmaker", "market", "team", "price", "point",
        "home_team", "away_team", "fetch_timestamp"
    ]

    # Only include columns that exist in the data
    existing_columns = [col for col in columns if col in df_new.columns]
    df_new = df_new[existing_columns]

    # Append to existing file if it exists and append=True (stack without deduplication)
    if append and filepath.exists():
        try:
            df_existing = pd.read_csv(filepath)
            df_combined = pd.concat([df_existing, df_new], ignore_index=True)
            df_combined.to_csv(filepath, index=False)
        except Exception as e:
            # If append fails, just overwrite
            if settings.VERBOSE:
                print(f"‚ö†Ô∏è Failed to append to {filepath}: {e}, overwriting instead")
            df_new.to_csv(filepath, index=False)
    else:
        df_new.to_csv(filepath, index=False)


def collect_data_running(output_dir: Optional[Path] = None, target_date: Optional[date] = None) -> Dict[str, Any]:
    """Collect market data when algorithm is running.
    
    Args:
        output_dir: Optional output directory (default: DATA_DIR / target_date)
        target_date: Optional target date (default: today)
    
    Returns:
        Dictionary with collected data organized by league/market.
    """
    if target_date is None:
        target_date = datetime.now(CST).date()
    
    if output_dir is None:
        output_dir = settings.DATA_DIR / target_date.strftime("%Y-%m-%d")
    output_dir.mkdir(parents=True, exist_ok=True)

    target_dates = {target_date}  # Only collect data for the specified date, not tomorrow

    collected_data = {}

    # Collect from OddsAPI (sports data by league)
    all_skipped_games = []  # Collect all skipped games across sports
    
    for sport_name, sport_key in settings.SPORT_KEYS.items():
        print(f"üì° Fetching odds for {sport_name} ({sport_key})...")
        data = fetch_odds(sport_key)

        if not data:
            continue

        rows_by_date, skipped_games = normalize_odds_data(sport_name, data, target_dates)

        all_skipped_games.extend(skipped_games)

        for game_date, rows in rows_by_date.items():
            # Only process rows for the target date, not tomorrow
            if game_date != target_date:
                continue

            if not rows:
                continue

            # Separate by market type
            df = pd.DataFrame(rows)
            for market_type in df["market"].unique():
                market_data = df[df["market"] == market_type].to_dict("records")  # type: ignore

                # Use sport name only (not sport_league) for filename
                key = f"{sport_name}_{market_type}"
                
                if key not in collected_data:
                    collected_data[key] = []
                collected_data[key].extend(market_data)

                # Save to file (only for the target date, not tomorrow)
                filename = f"{key.lower()}.csv"
                filepath = output_dir / filename

                save_market_data(
                    market_data,
                    filepath,
                    market_type,
                    fetch_timestamp=datetime.now(CST),
                )

        # Save skipped games to CSV (one file per day, in data_collection directory)
        if all_skipped_games:
            # Group skipped games by date
            skipped_by_date = {}
            for skipped in all_skipped_games:
                # Try to extract date from commence_time
                commence_time = skipped.get("commence_time", "")
                if commence_time:
                    try:
                        # Parse the commence_time string to get date
                        dt = _as_cst_datetime(commence_time)
                        skip_date = dt.date()
                    except:
                        # If we can't parse, use target_date
                        skip_date = target_date
                else:
                    skip_date = target_date
                
                skipped_by_date.setdefault(skip_date, []).extend([skipped])
            
            # Save skipped games for each date in skipped_games subdirectory
            # Only save skipped games for the target date
            skipped_dir = output_dir.parent / "skipped_games"  # data_collection/data_curr/skipped_games
            skipped_dir.mkdir(parents=True, exist_ok=True)
            for skip_date, skipped_list in skipped_by_date.items():
                # Only save skipped games for the target date
                if skip_date == target_date:
                    date_str = skip_date.strftime("%Y-%m-%d")
                    skipped_filepath = skipped_dir / f"skipped_games_{date_str}.csv"
                    save_skipped_games(skipped_list, skipped_filepath)
                    print(f"üìù Saved {len(skipped_list)} skipped games to {skipped_filepath.name}")

    # Collect Kalshi markets (non-sports: by market)
    # This would require event ticker discovery, which is handled in the main loop
    # For now, we just log that Kalshi data collection happens during main loop

    return collected_data


def collect_data_standalone(output_dir: Optional[Path] = None, target_date: Optional[date] = None):
    """Collect market data when algorithm is not running.
    
    This is a standalone function that can be called independently.
    
    Args:
        output_dir: Optional output directory (default: DATA_DIR / target_date)
        target_date: Optional target date (default: today)
    """
    return collect_data_running(output_dir, target_date)


if __name__ == "__main__":
    import argparse
    parser = argparse.ArgumentParser(description="Collect market data from OddsAPI")
    parser.add_argument(
        "--date",
        type=str,
        help="Target date in YYYY-MM-DD format (default: today). Output directory will be automatically set to data_collection/data_curr/{date}"
    )
    args = parser.parse_args()
    
    target_date = None
    if args.date:
        try:
            target_date = datetime.strptime(args.date, "%Y-%m-%d").date()
        except ValueError:
            print(f"‚ùå Invalid date format: {args.date}. Expected YYYY-MM-DD")
            sys.exit(1)
    
    # output_dir will be automatically set in collect_data_running based on target_date
    collect_data_standalone(None, target_date)