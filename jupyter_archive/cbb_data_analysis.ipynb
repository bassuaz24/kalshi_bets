{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "6dcca390",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from datetime import datetime\n",
    "import matplotlib.pyplot as plt\n",
    "import regex as re\n",
    "import math\n",
    "from collections import defaultdict\n",
    "import pytz\n",
    "import shin\n",
    "\n",
    "from scipy.stats import norm\n",
    "from scipy.optimize import brentq\n",
    "from scipy.special import expit, logit\n",
    "\n",
    "from rapidfuzz.fuzz import ratio"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73b77c83",
   "metadata": {},
   "source": [
    "things to look at: how accurate is the prematch probability when it ends (if a team has over 50% chance to win, how often do they actually win the game?)\n",
    "\n",
    "Todo:\n",
    "\n",
    "bets for totals markets\n",
    "\n",
    "api for event outcome to backtest and look at distributions of prematch probabilities to outcome\n",
    "\n",
    "bet again during halftime break\n",
    "\n",
    "automating daily report\n",
    "\n",
    "automate bet placements\n",
    "\n",
    "rerunning fetchers and jupyter for non-filled orders periodically"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "1b8cbd91",
   "metadata": {},
   "outputs": [],
   "source": [
    "date = '2025-12-15'\n",
    "odds_sport = 'nfl' #cbbm, cbbm2, cbbw2, cfb, cfb2, nba, nfl\n",
    "kalshi_sport = 'nfl' #ncaabm, ncaabw, ncaaf, nba, nfl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "62f1c279",
   "metadata": {},
   "outputs": [],
   "source": [
    "#betus good for nba, pinnacle, betonline best for everything, fanduel pretty good\n",
    "\n",
    "odds_df = pd.read_csv(f\"../data_collection/updated_scripts/oddsapi_outputs/{date}/{odds_sport}_odds.csv\")\n",
    "odds_df.drop(columns=['league'], inplace=True)\n",
    "odds_df.rename(columns={'price': 'odds'}, inplace=True)\n",
    "\n",
    "odds_df['vig_prob'] = 1 / odds_df['odds']\n",
    "\n",
    "def remove_vig_probs_add(df):\n",
    "    df = df.copy()\n",
    "    df['fair_prb'] = np.nan\n",
    "\n",
    "    grouped = df.groupby(['game_id', 'bookmaker', 'market'])\n",
    "\n",
    "    for _, group in grouped:\n",
    "        if len(group) < 2:\n",
    "            continue\n",
    "        probs = group['vig_prob']\n",
    "        total = probs.sum()\n",
    "        if total == 0:\n",
    "            continue\n",
    "        fair_probs = (probs / total).round(4)\n",
    "        df.loc[group.index, 'fair_prb'] = fair_probs\n",
    "\n",
    "    return df\n",
    "\n",
    "def remove_vig_probs_shin(df):\n",
    "    df = df.copy()\n",
    "    df['fair_prb'] = np.nan\n",
    "\n",
    "    grouped = df.groupby(['game_id', 'bookmaker', 'market'])\n",
    "\n",
    "    for _, group in grouped:\n",
    "        if len(group) < 2:\n",
    "            continue\n",
    "        odds = group['odds'].values\n",
    "        fair_probs = shin.calculate_implied_probabilities(odds)\n",
    "        df.loc[group.index, 'fair_prb'] = fair_probs\n",
    "\n",
    "    return df\n",
    "\n",
    "def devig_probit(p1, p2):\n",
    "    \"\"\"if p1 <= 0 or p2 <= 0 or p1 >= 1 or p2 >= 1:\n",
    "        total = p1 + p2\n",
    "        return p1 / total, p2 / total\n",
    "    if p1 + p2 <= 1:\n",
    "        total = p1 + p2\n",
    "        return p1 / total, p2 / total\"\"\"\n",
    "  \n",
    "    z1 = norm.ppf(p1)\n",
    "    z2 = norm.ppf(p2)\n",
    "    f = lambda lam: norm.cdf(z1 - lam) + norm.cdf(z2 - lam) - 1\n",
    "    lam = brentq(f, -15, 15)\n",
    "    \n",
    "    q1 = norm.cdf(z1 - lam)\n",
    "    q2 = norm.cdf(z2 - lam)\n",
    "    return q1, q2\n",
    "\n",
    "def remove_vig_probs_probit(df):\n",
    "    df = df.copy()\n",
    "    df['fair_prb'] = np.nan\n",
    "    grouped = df.groupby(['game_id', 'bookmaker', 'market'])\n",
    "    for _, group in grouped:\n",
    "        if len(group) != 2:\n",
    "            continue\n",
    "        p1, p2 = group['vig_prob'].values\n",
    "        q1, q2 = devig_probit(p1, p2)\n",
    "        df.loc[group.index, 'fair_prb'] = [q1, q2]\n",
    "    return df\n",
    "\n",
    "def devig_logit(p1, p2):\n",
    "    z1 = logit(p1)\n",
    "    z2 = logit(p2)\n",
    "    # Solve for λ such that logistic(z1 - λ) + logistic(z2 - λ) = 1\n",
    "    f = lambda lam: expit(z1 - lam) + expit(z2 - lam) - 1\n",
    "    lam = brentq(f, -50, 50)\n",
    "    q1 = expit(z1 - lam)\n",
    "    q2 = expit(z2 - lam)\n",
    "    return q1, q2\n",
    "\n",
    "def remove_vig_probs_logit(df):\n",
    "    df = df.copy()\n",
    "    df['fair_prb'] = np.nan\n",
    "    grouped = df.groupby(['game_id', 'bookmaker', 'market'])\n",
    "    for _, group in grouped:\n",
    "        if len(group) != 2:\n",
    "            continue\n",
    "        p1, p2 = group['vig_prob'].values\n",
    "        q1, q2 = devig_logit(p1, p2)\n",
    "        df.loc[group.index, 'fair_prb'] = [q1, q2]\n",
    "    return df\n",
    "\n",
    "odds_df = remove_vig_probs_logit(odds_df)\n",
    "\n",
    "\n",
    "odds_winners_df = odds_df[odds_df['market'] == 'h2h'].copy()\n",
    "odds_spreads_df = odds_df[odds_df['market'] == 'spreads'].copy()\n",
    "odds_spreads_df = odds_spreads_df.loc[(odds_spreads_df['point'].notna()) & (odds_spreads_df['point'] < 0)]\n",
    "odds_totals_df  = odds_df[odds_df['market'] == 'totals'].copy()\n",
    "\n",
    "# Average per-team fair probabilities across DraftKings/FanDuel/Pinnacle for winners_df\n",
    "WEIGHTS = {\n",
    "    \"Pinnacle\": 0.3,\n",
    "    \"BetOnline.ag\": 0.3,\n",
    "    \"BetUS\": 0.2,\n",
    "    \"FanDuel\": 0.2\n",
    "}\n",
    "\n",
    "def wavg(x, df):\n",
    "    idx = x.index\n",
    "    bookmakers = df.loc[idx, 'bookmaker']\n",
    "    w = np.array([WEIGHTS[b] for b in bookmakers])\n",
    "    return np.average(x.values, weights=w)\n",
    "\n",
    "mask = odds_winners_df['fair_prb'].notna()\n",
    "avg_by_team = (\n",
    "    odds_winners_df.loc[mask]\n",
    "    .groupby(['game_id', 'team'])['fair_prb']\n",
    "    .transform(lambda x: wavg(x, odds_winners_df))\n",
    "    .round(4)\n",
    ")\n",
    "odds_winners_df.loc[mask, 'avg_fair_prb'] = avg_by_team\n",
    "odds_winners_df.loc[~mask, 'avg_fair_prb'] = pd.NA\n",
    "\n",
    "#Average fair probabilities for spreads for same game, point spread, and team\n",
    "mask = odds_spreads_df['fair_prb'].notna()\n",
    "avg_by_point = (\n",
    "    odds_spreads_df.loc[mask]\n",
    "    .groupby(['game_id', 'point', 'team'])['fair_prb']\n",
    "    .transform(lambda x: wavg(x, odds_spreads_df))\n",
    "    .round(4)\n",
    ")\n",
    "odds_spreads_df['avg_fair_prb'] = avg_by_point\n",
    "\n",
    "#Average fair probabilities for totals for same game, point spread, direction (Over/Under)\n",
    "mask = odds_totals_df['fair_prb'].notna()\n",
    "avg_by_tot_point = (\n",
    "    odds_totals_df.loc[mask]\n",
    "    .groupby(['game_id', 'point', 'team'])['fair_prb']\n",
    "    .transform(lambda x: wavg(x, odds_totals_df))\n",
    "    .round(4)\n",
    ")\n",
    "odds_totals_df['avg_fair_prb'] = avg_by_tot_point"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "e4c49abf",
   "metadata": {},
   "outputs": [],
   "source": [
    "kalshi_winners_df = pd.read_csv(f\"../data_collection/updated_scripts/kalshi_data_logs/{date}/{kalshi_sport}_winners.csv\")\n",
    "if kalshi_sport != 'ncaabw':\n",
    "    kalshi_totals_df = pd.read_csv(f\"../data_collection/updated_scripts/kalshi_data_logs/{date}/{kalshi_sport}_totals.csv\")\n",
    "    kalshi_spreads_df = pd.read_csv(f\"../data_collection/updated_scripts/kalshi_data_logs/{date}/{kalshi_sport}_spreads.csv\")\n",
    "\n",
    "if (kalshi_sport == 'ncaaf') | (kalshi_sport == 'nfl'):\n",
    "    kalshi_spreads_df['points'] = kalshi_spreads_df['title'].str.extract(r'over ([\\d.]+) points\\?').astype(float)\n",
    "    kalshi_totals_df[\"points\"] = kalshi_totals_df[\"ticker\"].str.extract(r\"-([0-9.]+)$\").astype(float)\n",
    "elif (kalshi_sport == 'ncaab') | (kalshi_sport == 'ncaabm') | (kalshi_sport == 'ncaabw') | (kalshi_sport == 'nba'):\n",
    "    kalshi_spreads_df['points'] = kalshi_spreads_df['title'].str.extract(r'over ([\\d.]+) Points\\?').astype(float)\n",
    "    kalshi_totals_df[\"points\"] = kalshi_totals_df[\"ticker\"].str.extract(r\"-([0-9.]+)$\").astype(float)\n",
    "\n",
    "columns_to_drop = ['timestamp', 'market_type']\n",
    "kalshi_winners_df.drop(columns=columns_to_drop, inplace=True)\n",
    "if kalshi_sport != 'ncaabw':\n",
    "    kalshi_spreads_df.drop(columns=columns_to_drop, inplace=True)\n",
    "    kalshi_totals_df.drop(columns=columns_to_drop, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed0806b2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "7e31f62f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#get names from kalshi_winners_df\n",
    "def extract_teams_from_winners(title):\n",
    "    title = title.replace(\" Winner?\", \"\")\n",
    "    if \" at \" in title:\n",
    "        right, left = title.split(\" at \", 1)\n",
    "    elif \" vs \" in title:\n",
    "        right, left = title.split(\" vs \", 1)\n",
    "    else:\n",
    "        return pd.Series([None, None])  \n",
    "    left = re.sub(r'\\bSt\\.$', 'St', left.strip())\n",
    "    right = re.sub(r'\\bSt\\.$', 'St', right.strip())\n",
    "    return pd.Series([left, right])\n",
    "\n",
    "kalshi_winners_df[['home_team', 'away_team']] = kalshi_winners_df['title'].apply(extract_teams_from_winners)\n",
    "unique_rows = kalshi_winners_df.drop_duplicates(subset=['home_team', 'away_team'])\n",
    "flat_teams = pd.unique(unique_rows[['home_team', 'away_team']].values.ravel())\n",
    "kalshi_winners_teams = flat_teams.tolist()\n",
    "\n",
    "#get names from kalshi_totals_df\n",
    "def extract_teams_from_totals(title):\n",
    "    title = title.replace(\": Total Points\", \"\")\n",
    "    if \" at \" in title:\n",
    "        right, left = title.split(\" at \", 1)\n",
    "        left = re.sub(r'\\bSt\\.$', 'St', left.strip())\n",
    "        right = re.sub(r'\\bSt\\.$', 'St', right.strip())\n",
    "        return pd.Series([left, right])\n",
    "    return None\n",
    "\n",
    "kalshi_totals_df[['home_team', 'away_team']] = kalshi_totals_df['title'].apply(extract_teams_from_totals)\n",
    "unique_rows = kalshi_winners_df.drop_duplicates(subset=['home_team', 'away_team'])\n",
    "flat_teams = pd.unique(unique_rows[['home_team', 'away_team']].values.ravel())\n",
    "kalshi_totals_teams = flat_teams.tolist()\n",
    "\n",
    "#get names from kalshi_spreads_df\n",
    "def extract_team_from_spreads(title):\n",
    "    if \" wins by \" in title:\n",
    "        team = title.split(\" wins by \", 1)[0].strip()\n",
    "        team = re.sub(r'\\bSt\\.$', 'St', team)\n",
    "        return team\n",
    "    return None\n",
    "\n",
    "kalshi_spreads_df['team'] = kalshi_spreads_df['title'].apply(extract_team_from_spreads)\n",
    "unique_teams_spread = kalshi_spreads_df['team'].drop_duplicates()\n",
    "kalshi_spreads_teams = unique_teams_spread.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "e5460c4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fuzzy_match_kalshi_to_odds(kalshi_teams, odds_team_names):\n",
    "    matched_kalshi = []\n",
    "    matched_odds = []\n",
    "    candidates_dict = defaultdict(list)\n",
    "\n",
    "    kalshi_sorted = sorted(kalshi_teams, key=lambda x: x[0] if x else '')\n",
    "    remaining_odds = sorted(odds_team_names.tolist().copy())\n",
    "\n",
    "    for kalshi_name in kalshi_sorted:\n",
    "        candidates = []\n",
    "        for odds_name in remaining_odds:\n",
    "            if kalshi_name in odds_name:\n",
    "                candidates.append(odds_name)\n",
    "        if len(candidates) == 1:\n",
    "            candidates_dict[candidates[0]].append(kalshi_name)\n",
    "        elif len(candidates) > 1:\n",
    "            best_fit = candidates[0]\n",
    "            best_ratio = ratio(best_fit, kalshi_name)\n",
    "            for name in candidates:\n",
    "                curr_ratio = ratio(name, kalshi_name)\n",
    "                if curr_ratio > best_ratio:\n",
    "                    best_fit = name\n",
    "                    best_ratio = curr_ratio\n",
    "            candidates_dict[best_fit].append(kalshi_name)\n",
    "    \n",
    "    for odd, kalsh in candidates_dict.items():\n",
    "        best_fit = kalsh[0]\n",
    "        best_ratio = ratio(best_fit, odd)\n",
    "        if len(kalsh) > 1:\n",
    "            for name in kalsh:\n",
    "                curr_ratio = ratio(name, odd)\n",
    "                if curr_ratio > best_ratio:\n",
    "                    best_fit = name\n",
    "                    best_ratio = curr_ratio\n",
    "        matched_odds.append(odd)\n",
    "        matched_kalshi.append(best_fit)\n",
    "\n",
    "    return matched_kalshi, matched_odds\n",
    "\n",
    "\n",
    "# Winners / h2h\n",
    "odds_teams_winners = odds_winners_df['team'].unique()\n",
    "matched_kalshi_h2h, matched_odds_h2h = fuzzy_match_kalshi_to_odds(\n",
    "    kalshi_winners_teams,\n",
    "    odds_teams_winners\n",
    ")\n",
    "\n",
    "# Spreads\n",
    "odds_teams_spreads = odds_spreads_df['team'].unique()\n",
    "matched_kalshi_spreads, matched_odds_spreads = fuzzy_match_kalshi_to_odds(\n",
    "    kalshi_spreads_teams,\n",
    "    odds_teams_spreads\n",
    ")\n",
    "\n",
    "# Totals (match only Over/Under)\n",
    "totals_odds_df = odds_df[odds_df['market'] == 'totals']\n",
    "odds_totals_teams = pd.unique(totals_odds_df[['home_team', 'away_team']].values.ravel())\n",
    "matched_kalshi_totals, matched_odds_totals = fuzzy_match_kalshi_to_odds(\n",
    "    kalshi_totals_teams,\n",
    "    odds_totals_teams\n",
    ")\n",
    "\n",
    "matched_names = {\n",
    "    'h2h': {\n",
    "        'kalshi': matched_kalshi_h2h,\n",
    "        'odds': matched_odds_h2h\n",
    "    },\n",
    "    'spreads': {\n",
    "        'kalshi': matched_kalshi_spreads,\n",
    "        'odds': matched_odds_spreads\n",
    "    },\n",
    "    'totals': {\n",
    "        'kalshi': matched_kalshi_totals,\n",
    "        'odds': matched_odds_totals\n",
    "    }\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "697bf08d",
   "metadata": {},
   "outputs": [],
   "source": [
    "assert(len(matched_names['h2h']['kalshi']) == len(matched_names['h2h']['odds']))\n",
    "assert(len(matched_names['spreads']['kalshi']) == len(matched_names['spreads']['odds']))\n",
    "assert(len(matched_names['totals']['kalshi']) == len(matched_names['totals']['odds']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "dee1da03",
   "metadata": {},
   "outputs": [],
   "source": [
    "odds_winners_df = odds_winners_df[\n",
    "    odds_winners_df['home_team'].isin(matched_names['h2h']['odds']) |\n",
    "    odds_winners_df['away_team'].isin(matched_names['h2h']['odds'])\n",
    "].drop_duplicates(subset='team').sort_values(by='home_team').reset_index(drop=True)\n",
    "\n",
    "kalshi_winners_df = kalshi_winners_df[\n",
    "    kalshi_winners_df['home_team'].isin(matched_names['h2h']['kalshi']) |\n",
    "    kalshi_winners_df['away_team'].isin(matched_names['h2h']['kalshi'])\n",
    "].sort_values(by='home_team').reset_index(drop=True)\n",
    "\n",
    "odds_spreads_df = odds_spreads_df[odds_spreads_df['team'].isin(matched_names['spreads']['odds'])\n",
    "                                  ].sort_values(by='team').reset_index(drop=True)\n",
    "kalshi_spreads_df = kalshi_spreads_df[kalshi_spreads_df['team'].isin(matched_names['spreads']['kalshi'])\n",
    "                                      ].sort_values(by='team').reset_index(drop=True)\n",
    "\n",
    "odds_totals_df = odds_totals_df[\n",
    "    odds_totals_df['home_team'].isin(matched_names['totals']['odds']) |\n",
    "    odds_totals_df['away_team'].isin(matched_names['totals']['odds'])\n",
    "].sort_values(by='home_team').reset_index(drop=True)\n",
    "kalshi_totals_df = kalshi_totals_df[\n",
    "    (kalshi_totals_df['home_team'].isin(matched_names['totals']['kalshi'])) | \n",
    "    (kalshi_totals_df['away_team'].isin(matched_names['totals']['kalshi']))\n",
    "    ].sort_values(by='home_team').reset_index(drop=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "7b12de03",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Concatenate winners df\n",
    "\n",
    "# Specify the columns to extract\n",
    "kalshi_cols = ['ticker', 'yes_bid', 'yes_ask', 'no_bid', 'no_ask', 'home_team', 'away_team']\n",
    "odds_cols = ['market', 'start_time', 'team', 'home_team', 'away_team', 'avg_fair_prb']\n",
    "\n",
    "# Rename overlapping columns in odds to prevent clashes\n",
    "odds_subset = odds_winners_df[odds_cols].rename(columns={\n",
    "    'home_team': 'odds_home_team',\n",
    "    'away_team': 'odds_away_team'\n",
    "})\n",
    "\n",
    "kalshi_subset = kalshi_winners_df[kalshi_cols].rename(columns={\n",
    "    'home_team': 'kalshi_home_team',\n",
    "    'away_team': 'kalshi_away_team'\n",
    "})\n",
    "\n",
    "combined_rows = []\n",
    "len_matched = len(matched_names['h2h']['kalshi'])\n",
    "matched_names_h2h = matched_names['h2h']\n",
    "\n",
    "for i in range(len_matched):\n",
    "    odds_name = matched_names_h2h['odds'][i]\n",
    "    kalshi_name = matched_names_h2h['kalshi'][i]\n",
    "\n",
    "    # Find the corresponding odds row\n",
    "    odds_row = odds_subset.loc[odds_subset['team'] == odds_name]\n",
    "    assert len(odds_row) == 1, f\"Expected one row for {odds_name}, got {len(odds_row)}\"\n",
    "\n",
    "    # Find the two matching Kalshi rows\n",
    "    kalshi_rows = kalshi_subset.loc[\n",
    "        (kalshi_subset['kalshi_home_team'] == kalshi_name) |\n",
    "        (kalshi_subset['kalshi_away_team'] == kalshi_name)\n",
    "    ]\n",
    "    assert len(kalshi_rows) == 2, f\"Expected two rows for {kalshi_name}, got {len(kalshi_rows)}\"\n",
    "\n",
    "    # Extract rows\n",
    "    k1 = kalshi_rows.iloc[0]\n",
    "    k2 = kalshi_rows.iloc[1]\n",
    "    midprice1 = (k1['yes_bid'] + k1['yes_ask']) / 2\n",
    "    midprice2 = (k2['yes_bid'] + k2['yes_ask']) / 2\n",
    "\n",
    "    # Extract scalar fair probability\n",
    "    prb = odds_row['avg_fair_prb'].astype(float).item()\n",
    "\n",
    "    # Choose the row closer to the odds probability\n",
    "    if ((midprice1 - prb) ** 2) < ((midprice2 - prb) ** 2):\n",
    "        combined_row = pd.concat([k1, odds_row.iloc[0]])\n",
    "    else:\n",
    "        combined_row = pd.concat([k2, odds_row.iloc[0]])\n",
    "\n",
    "    combined_rows.append(combined_row)\n",
    "\n",
    "combined_winners_df = pd.DataFrame(combined_rows).sort_values(by='odds_home_team')\n",
    "combined_winners_df = combined_winners_df.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "579baf50",
   "metadata": {},
   "outputs": [],
   "source": [
    "EDGE = 0.01\n",
    "KELLY_UPPERBOUND = 1\n",
    "BANKROLL = 225.00\n",
    "Q1_WEIGHT = 1.00\n",
    "Q2_WEIGHT = 1.00\n",
    "Q3_WEIGHT = 1.00\n",
    "Q4_WEIGHT = 1.00\n",
    "\n",
    "midprice = (combined_winners_df['yes_bid'] + combined_winners_df['yes_ask']) / 2\n",
    "\n",
    "edge_winners_df = combined_winners_df.loc[\n",
    "    (combined_winners_df['avg_fair_prb'] >= midprice + EDGE) |\n",
    "    (combined_winners_df['avg_fair_prb'] <= midprice - EDGE)\n",
    "].reset_index(drop=True)\n",
    "\n",
    "edge_winners_df = edge_winners_df.loc[((edge_winners_df['avg_fair_prb'] > 0.15) & (edge_winners_df['avg_fair_prb'] < 0.49)) |\n",
    "                                      ((edge_winners_df['avg_fair_prb'] > 0.51) & (edge_winners_df['avg_fair_prb'] < 0.85)) ]\n",
    "\n",
    "midprice_yes = (edge_winners_df['yes_bid'] + edge_winners_df['yes_ask']) / 2\n",
    "midprice_no = (edge_winners_df['no_bid'] + edge_winners_df['no_ask']) / 2\n",
    "\n",
    "q_yes = edge_winners_df['avg_fair_prb']\n",
    "q_no = 1 - edge_winners_df['avg_fair_prb'] \n",
    "\n",
    "edge_winners_df['edge'] = np.where(q_yes > midprice_yes, q_yes - midprice_yes, q_no - midprice_no)\n",
    "\n",
    "edge_winners_df['buy_direction'] = np.where(q_yes > midprice_yes, \"yes\", \"no\")\n",
    "edge_winners_df['raw_kelly'] = np.where(q_yes > midprice_yes, edge_winners_df['edge'] / (1 - midprice_yes),\n",
    "                                        edge_winners_df['edge'] / (1 - midprice_no))\n",
    "\n",
    "total_kelly = edge_winners_df['raw_kelly'].sum() \n",
    "if total_kelly >= 1: \n",
    "    edge_winners_df['real_kelly'] = pd.DataFrame({\n",
    "        'original': edge_winners_df['raw_kelly'],\n",
    "        'normalized': (edge_winners_df['raw_kelly'] / total_kelly)\n",
    "    }).min(axis=1)\n",
    "\n",
    "# Define the real_kelly logic\n",
    "def scale_kelly(row):\n",
    "    k = row['raw_kelly']\n",
    "    p = row['avg_fair_prb']\n",
    "    \n",
    "    if k == 0 or pd.isna(k):\n",
    "        return 0\n",
    "    if 0.05 <= p < 0.25:\n",
    "        return min(Q1_WEIGHT * k, KELLY_UPPERBOUND)\n",
    "    elif 0.25 <= p < 0.5:\n",
    "        return min(Q2_WEIGHT * k, KELLY_UPPERBOUND)\n",
    "    elif 0.5 <= p < 0.75:\n",
    "        return min(Q3_WEIGHT * k, KELLY_UPPERBOUND)\n",
    "    elif 0.75 <= p < 0.95:\n",
    "        return min(Q4_WEIGHT * k, KELLY_UPPERBOUND)\n",
    "    else:\n",
    "        return 0 \n",
    "\n",
    "# Apply to the DataFrame\n",
    "edge_winners_df['real_kelly'] = edge_winners_df.apply(scale_kelly, axis=1)\n",
    "edge_winners_df['optimal_bet'] = edge_winners_df['real_kelly'] * BANKROLL\n",
    "\n",
    "q = edge_winners_df['avg_fair_prb']\n",
    "p = midprice_yes\n",
    "\n",
    "num_contracts = np.where(q > p, edge_winners_df['optimal_bet'] // edge_winners_df['yes_bid'], edge_winners_df['optimal_bet'] // edge_winners_df['no_bid'])\n",
    "edge_winners_df['num_contracts'] = num_contracts\n",
    "trading_cost = np.where(q > p, np.ceil(100*(0.0175 * num_contracts * edge_winners_df['yes_bid'] * (1 - edge_winners_df['yes_bid']))) / 100,\n",
    "                        np.ceil(100*(0.0175 * num_contracts * edge_winners_df['no_bid'] * (1 - edge_winners_df['no_bid']))) / 100)\n",
    "edge_winners_df['trading_cost'] = trading_cost\n",
    "profit = np.where(q > p, ((1 - edge_winners_df['yes_bid']) * num_contracts - trading_cost), ((1 - edge_winners_df['no_bid']) *  num_contracts - trading_cost))\n",
    "edge_winners_df['profit'] = profit\n",
    "edge_winners_df['ev'] = np.where(q > p, (profit * q_yes - (edge_winners_df['optimal_bet'] + trading_cost) * (1 - q_yes)).round(2), \n",
    "                                 (profit * q_no - (edge_winners_df['optimal_bet'] + trading_cost) * (1 - q_no)).round(2))\n",
    "filtered_winners_df = edge_winners_df.loc[edge_winners_df['ev'] > 0.1].reset_index(drop=True)\n",
    "\n",
    "s = filtered_winners_df['start_time'].astype(str)\n",
    "s = s.str.replace(r'\\s+[A-Z]{3}$', '', regex=True)\n",
    "dt = pd.to_datetime(s, errors='coerce')\n",
    "filtered_winners_df['start_time'] = dt.dt.tz_localize('America/Chicago')\n",
    "\n",
    "now = datetime.now(pytz.timezone('America/Chicago'))\n",
    "#filtered_winners_df = filtered_winners_df.loc[filtered_winners_df['start_time'] > now].sort_values('odds_home_team').reset_index(drop=True)\n",
    "\n",
    "dupe_mask = filtered_winners_df['kalshi_home_team'].duplicated(keep=False)\n",
    "dupes = filtered_winners_df[dupe_mask]\n",
    "uniques = filtered_winners_df[~dupe_mask]\n",
    "best_dupes = dupes.loc[dupes.groupby('kalshi_home_team')['ev'].idxmax()]\n",
    "filtered_winners_df = pd.concat([uniques, best_dupes], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "a2b99d5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "mask_kentucky = (\n",
    "    filtered_winners_df['odds_home_team'].str.contains('Kentucky', na=False) |\n",
    "    filtered_winners_df['odds_away_team'].str.contains('Kentucky', na=False)\n",
    ")\n",
    "mask_drop = mask_kentucky & (filtered_winners_df['buy_direction'] == \"yes\")\n",
    "\n",
    "filtered_winners_df = filtered_winners_df.loc[~mask_drop].reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "152e18b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "team_cols = ['kalshi_home_team', 'kalshi_away_team',\n",
    "             'odds_home_team', 'odds_away_team']\n",
    "\n",
    "teams_df = filtered_winners_df[team_cols].copy()\n",
    "\n",
    "filtered_winners_df = filtered_winners_df.drop(columns=['kalshi_home_team', 'kalshi_away_team']).reset_index(drop=True)\n",
    "filtered_winners_df[['edge', 'raw_kelly', 'real_kelly']] = filtered_winners_df[['edge', 'raw_kelly', 'real_kelly']].round(4) * 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "6e014e92",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ticker</th>\n",
       "      <th>yes_bid</th>\n",
       "      <th>yes_ask</th>\n",
       "      <th>no_bid</th>\n",
       "      <th>no_ask</th>\n",
       "      <th>market</th>\n",
       "      <th>start_time</th>\n",
       "      <th>team</th>\n",
       "      <th>odds_home_team</th>\n",
       "      <th>odds_away_team</th>\n",
       "      <th>avg_fair_prb</th>\n",
       "      <th>edge</th>\n",
       "      <th>buy_direction</th>\n",
       "      <th>raw_kelly</th>\n",
       "      <th>real_kelly</th>\n",
       "      <th>optimal_bet</th>\n",
       "      <th>num_contracts</th>\n",
       "      <th>trading_cost</th>\n",
       "      <th>profit</th>\n",
       "      <th>ev</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [ticker, yes_bid, yes_ask, no_bid, no_ask, market, start_time, team, odds_home_team, odds_away_team, avg_fair_prb, edge, buy_direction, raw_kelly, real_kelly, optimal_bet, num_contracts, trading_cost, profit, ev]\n",
       "Index: []"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filtered_winners_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "3542479d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nfl h2h portfolio summary:\n",
      "\n",
      "Max Loss: -0.00\n",
      "Max Profit: 0.00\n",
      "Portfolio EV: 0.00\n"
     ]
    }
   ],
   "source": [
    "total_loss = np.sum(filtered_winners_df['optimal_bet'])\n",
    "total_profit = np.sum(filtered_winners_df['profit'])\n",
    "total_ev = np.sum(filtered_winners_df['ev'])\n",
    "print(f\"{odds_sport} h2h portfolio summary:\\n\")\n",
    "print(f\"Max Loss: -{total_loss:.2f}\")\n",
    "print(f\"Max Profit: {total_profit:.2f}\")\n",
    "print(f\"Portfolio EV: {total_ev:.2f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "ae467564",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "\"['team', 'market'] not found in axis\"",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyError\u001b[39m                                  Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[67]\u001b[39m\u001b[32m, line 33\u001b[39m\n\u001b[32m     30\u001b[39m                 combined_row = pd.concat([kalshi_row, odds_row])\n\u001b[32m     31\u001b[39m                 combined_rows.append(combined_row)\n\u001b[32m---> \u001b[39m\u001b[32m33\u001b[39m combined_spreads_df = \u001b[43mpd\u001b[49m\u001b[43m.\u001b[49m\u001b[43mDataFrame\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcombined_rows\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[43mdrop\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcolumns\u001b[49m\u001b[43m=\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mteam\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mmarket\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m.rename(\n\u001b[32m     34\u001b[39m     columns={\u001b[33m'\u001b[39m\u001b[33modds_team\u001b[39m\u001b[33m'\u001b[39m: \u001b[33m'\u001b[39m\u001b[33mteam\u001b[39m\u001b[33m'\u001b[39m, \u001b[33m'\u001b[39m\u001b[33mpoints\u001b[39m\u001b[33m'\u001b[39m: \u001b[33m'\u001b[39m\u001b[33mkalshi_pts\u001b[39m\u001b[33m'\u001b[39m, \u001b[33m'\u001b[39m\u001b[33mpoint\u001b[39m\u001b[33m'\u001b[39m: \u001b[33m'\u001b[39m\u001b[33modds_pts\u001b[39m\u001b[33m'\u001b[39m}).drop_duplicates(subset=[\u001b[33m'\u001b[39m\u001b[33mticker\u001b[39m\u001b[33m'\u001b[39m, \u001b[33m'\u001b[39m\u001b[33mkalshi_pts\u001b[39m\u001b[33m'\u001b[39m, \u001b[33m'\u001b[39m\u001b[33modds_pts\u001b[39m\u001b[33m'\u001b[39m])                        \n\u001b[32m     35\u001b[39m combined_spreads_df = combined_spreads_df.reset_index(drop=\u001b[38;5;28;01mTrue\u001b[39;00m)                    \n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/kdata1/.venv/lib/python3.13/site-packages/pandas/core/frame.py:5603\u001b[39m, in \u001b[36mDataFrame.drop\u001b[39m\u001b[34m(self, labels, axis, index, columns, level, inplace, errors)\u001b[39m\n\u001b[32m   5455\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mdrop\u001b[39m(\n\u001b[32m   5456\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m   5457\u001b[39m     labels: IndexLabel | \u001b[38;5;28;01mNone\u001b[39;00m = \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[32m   (...)\u001b[39m\u001b[32m   5464\u001b[39m     errors: IgnoreRaise = \u001b[33m\"\u001b[39m\u001b[33mraise\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m   5465\u001b[39m ) -> DataFrame | \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m   5466\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m   5467\u001b[39m \u001b[33;03m    Drop specified labels from rows or columns.\u001b[39;00m\n\u001b[32m   5468\u001b[39m \n\u001b[32m   (...)\u001b[39m\u001b[32m   5601\u001b[39m \u001b[33;03m            weight  1.0     0.8\u001b[39;00m\n\u001b[32m   5602\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m5603\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[43mdrop\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   5604\u001b[39m \u001b[43m        \u001b[49m\u001b[43mlabels\u001b[49m\u001b[43m=\u001b[49m\u001b[43mlabels\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   5605\u001b[39m \u001b[43m        \u001b[49m\u001b[43maxis\u001b[49m\u001b[43m=\u001b[49m\u001b[43maxis\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   5606\u001b[39m \u001b[43m        \u001b[49m\u001b[43mindex\u001b[49m\u001b[43m=\u001b[49m\u001b[43mindex\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   5607\u001b[39m \u001b[43m        \u001b[49m\u001b[43mcolumns\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcolumns\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   5608\u001b[39m \u001b[43m        \u001b[49m\u001b[43mlevel\u001b[49m\u001b[43m=\u001b[49m\u001b[43mlevel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   5609\u001b[39m \u001b[43m        \u001b[49m\u001b[43minplace\u001b[49m\u001b[43m=\u001b[49m\u001b[43minplace\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   5610\u001b[39m \u001b[43m        \u001b[49m\u001b[43merrors\u001b[49m\u001b[43m=\u001b[49m\u001b[43merrors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   5611\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/kdata1/.venv/lib/python3.13/site-packages/pandas/core/generic.py:4810\u001b[39m, in \u001b[36mNDFrame.drop\u001b[39m\u001b[34m(self, labels, axis, index, columns, level, inplace, errors)\u001b[39m\n\u001b[32m   4808\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m axis, labels \u001b[38;5;129;01min\u001b[39;00m axes.items():\n\u001b[32m   4809\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m labels \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m4810\u001b[39m         obj = \u001b[43mobj\u001b[49m\u001b[43m.\u001b[49m\u001b[43m_drop_axis\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlabels\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlevel\u001b[49m\u001b[43m=\u001b[49m\u001b[43mlevel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43merrors\u001b[49m\u001b[43m=\u001b[49m\u001b[43merrors\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   4812\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m inplace:\n\u001b[32m   4813\u001b[39m     \u001b[38;5;28mself\u001b[39m._update_inplace(obj)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/kdata1/.venv/lib/python3.13/site-packages/pandas/core/generic.py:4852\u001b[39m, in \u001b[36mNDFrame._drop_axis\u001b[39m\u001b[34m(self, labels, axis, level, errors, only_slice)\u001b[39m\n\u001b[32m   4850\u001b[39m         new_axis = axis.drop(labels, level=level, errors=errors)\n\u001b[32m   4851\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m4852\u001b[39m         new_axis = \u001b[43maxis\u001b[49m\u001b[43m.\u001b[49m\u001b[43mdrop\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlabels\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43merrors\u001b[49m\u001b[43m=\u001b[49m\u001b[43merrors\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   4853\u001b[39m     indexer = axis.get_indexer(new_axis)\n\u001b[32m   4855\u001b[39m \u001b[38;5;66;03m# Case for non-unique axis\u001b[39;00m\n\u001b[32m   4856\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/kdata1/.venv/lib/python3.13/site-packages/pandas/core/indexes/base.py:7136\u001b[39m, in \u001b[36mIndex.drop\u001b[39m\u001b[34m(self, labels, errors)\u001b[39m\n\u001b[32m   7134\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m mask.any():\n\u001b[32m   7135\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m errors != \u001b[33m\"\u001b[39m\u001b[33mignore\u001b[39m\u001b[33m\"\u001b[39m:\n\u001b[32m-> \u001b[39m\u001b[32m7136\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mlabels[mask].tolist()\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m not found in axis\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m   7137\u001b[39m     indexer = indexer[~mask]\n\u001b[32m   7138\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m.delete(indexer)\n",
      "\u001b[31mKeyError\u001b[39m: \"['team', 'market'] not found in axis\""
     ]
    }
   ],
   "source": [
    "kalshi_cols = ['ticker', 'yes_bid', 'yes_ask', 'no_bid', 'no_ask', 'team', 'points', 'yes_spread', 'no_spread']\n",
    "odds_cols = ['market', 'start_time', 'team', 'home_team', 'away_team', 'avg_fair_prb', 'point']\n",
    "\n",
    "odds_subset = odds_spreads_df[odds_cols].rename(columns={\n",
    "    'home_team': 'odds_home_team',\n",
    "    'away_team': 'odds_away_team',\n",
    "    'team': 'odds_team'\n",
    "})\n",
    "\n",
    "kalshi_subset = kalshi_spreads_df[kalshi_cols].copy()\n",
    "kalshi_subset['midprice'] = (kalshi_subset['yes_bid'] + kalshi_subset['yes_ask']) / 2\n",
    "kalshi_subset = kalshi_subset.loc[kalshi_subset['yes_spread'] <= 0.05]\n",
    "\n",
    "combined_rows = []\n",
    "\n",
    "for _, kalshi_row in kalshi_subset.iterrows():\n",
    "    kalshi_team = kalshi_row['team']\n",
    "    for _, odds_row in odds_subset.iterrows():\n",
    "        odds_row = odds_row.copy()\n",
    "        odds_team = odds_row['odds_team']\n",
    "        if (kalshi_team in odds_team):\n",
    "            if ((abs(odds_row['point']) == kalshi_row['points']) & (odds_row['avg_fair_prb'] > kalshi_row['midprice'])) or (\n",
    "                (abs(odds_row['point']) > kalshi_row['points']) & (odds_row['avg_fair_prb'] >= kalshi_row['midprice'])):\n",
    "                odds_row['buy_direction'] = \"yes\"\n",
    "                combined_row = pd.concat([kalshi_row, odds_row])\n",
    "                combined_rows.append(combined_row)\n",
    "            elif ((abs(odds_row['point']) == kalshi_row['points']) & (odds_row['avg_fair_prb'] < kalshi_row['midprice'])) or (\n",
    "                (abs(odds_row['point']) < kalshi_row['points']) & (odds_row['avg_fair_prb'] <= kalshi_row['midprice'])):\n",
    "                odds_row['buy_direction'] = \"no\"\n",
    "                combined_row = pd.concat([kalshi_row, odds_row])\n",
    "                combined_rows.append(combined_row)\n",
    "\n",
    "combined_spreads_df = pd.DataFrame(combined_rows).drop(columns=['team', 'market']).rename(\n",
    "    columns={'odds_team': 'team', 'points': 'kalshi_pts', 'point': 'odds_pts'}).drop_duplicates(subset=['ticker', 'kalshi_pts', 'odds_pts'])                        \n",
    "combined_spreads_df = combined_spreads_df.reset_index(drop=True)                    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16225cb5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ticker</th>\n",
       "      <th>yes_bid</th>\n",
       "      <th>yes_ask</th>\n",
       "      <th>no_bid</th>\n",
       "      <th>no_ask</th>\n",
       "      <th>kalshi_home_team</th>\n",
       "      <th>kalshi_away_team</th>\n",
       "      <th>market</th>\n",
       "      <th>start_time</th>\n",
       "      <th>team</th>\n",
       "      <th>odds_home_team</th>\n",
       "      <th>odds_away_team</th>\n",
       "      <th>avg_fair_prb</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>KXNFLGAME-25DEC15MIAPIT-MIA</td>\n",
       "      <td>0.38</td>\n",
       "      <td>0.39</td>\n",
       "      <td>0.61</td>\n",
       "      <td>0.62</td>\n",
       "      <td>Pittsburgh</td>\n",
       "      <td>Miami</td>\n",
       "      <td>h2h</td>\n",
       "      <td>2025-12-15 19:15:00 CST</td>\n",
       "      <td>Miami Dolphins</td>\n",
       "      <td>Pittsburgh Steelers</td>\n",
       "      <td>Miami Dolphins</td>\n",
       "      <td>0.3754</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>KXNFLGAME-25DEC15MIAPIT-PIT</td>\n",
       "      <td>0.61</td>\n",
       "      <td>0.62</td>\n",
       "      <td>0.38</td>\n",
       "      <td>0.39</td>\n",
       "      <td>Pittsburgh</td>\n",
       "      <td>Miami</td>\n",
       "      <td>h2h</td>\n",
       "      <td>2025-12-15 19:15:00 CST</td>\n",
       "      <td>Pittsburgh Steelers</td>\n",
       "      <td>Pittsburgh Steelers</td>\n",
       "      <td>Miami Dolphins</td>\n",
       "      <td>0.6246</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                        ticker  yes_bid  yes_ask  no_bid  no_ask  \\\n",
       "0  KXNFLGAME-25DEC15MIAPIT-MIA     0.38     0.39    0.61    0.62   \n",
       "1  KXNFLGAME-25DEC15MIAPIT-PIT     0.61     0.62    0.38    0.39   \n",
       "\n",
       "  kalshi_home_team kalshi_away_team market               start_time  \\\n",
       "0       Pittsburgh            Miami    h2h  2025-12-15 19:15:00 CST   \n",
       "1       Pittsburgh            Miami    h2h  2025-12-15 19:15:00 CST   \n",
       "\n",
       "                  team       odds_home_team  odds_away_team  avg_fair_prb  \n",
       "0       Miami Dolphins  Pittsburgh Steelers  Miami Dolphins        0.3754  \n",
       "1  Pittsburgh Steelers  Pittsburgh Steelers  Miami Dolphins        0.6246  "
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "combined_winners_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f0fe69a",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'yes_bid'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyError\u001b[39m                                  Traceback (most recent call last)",
      "\u001b[36mFile \u001b[39m\u001b[32m~/kdata1/.venv/lib/python3.13/site-packages/pandas/core/indexes/base.py:3812\u001b[39m, in \u001b[36mIndex.get_loc\u001b[39m\u001b[34m(self, key)\u001b[39m\n\u001b[32m   3811\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m3812\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_engine\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcasted_key\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   3813\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n",
      "\u001b[36mFile \u001b[39m\u001b[32mpandas/_libs/index.pyx:167\u001b[39m, in \u001b[36mpandas._libs.index.IndexEngine.get_loc\u001b[39m\u001b[34m()\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mpandas/_libs/index.pyx:196\u001b[39m, in \u001b[36mpandas._libs.index.IndexEngine.get_loc\u001b[39m\u001b[34m()\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mpandas/_libs/hashtable_class_helper.pxi:7088\u001b[39m, in \u001b[36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[39m\u001b[34m()\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mpandas/_libs/hashtable_class_helper.pxi:7096\u001b[39m, in \u001b[36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[39m\u001b[34m()\u001b[39m\n",
      "\u001b[31mKeyError\u001b[39m: 'yes_bid'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[31mKeyError\u001b[39m                                  Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[52]\u001b[39m\u001b[32m, line 9\u001b[39m\n\u001b[32m      6\u001b[39m Q3_WEIGHT = \u001b[32m1.00\u001b[39m\n\u001b[32m      7\u001b[39m Q4_WEIGHT = \u001b[32m1.00\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m9\u001b[39m midprice = (\u001b[43mcombined_spreads_df\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43myes_bid\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m]\u001b[49m + combined_spreads_df[\u001b[33m'\u001b[39m\u001b[33myes_ask\u001b[39m\u001b[33m'\u001b[39m]) / \u001b[32m2\u001b[39m\n\u001b[32m     11\u001b[39m edge_spreads_df = combined_spreads_df.loc[\n\u001b[32m     12\u001b[39m     (combined_spreads_df[\u001b[33m'\u001b[39m\u001b[33mavg_fair_prb\u001b[39m\u001b[33m'\u001b[39m] >= midprice + EDGE) |\n\u001b[32m     13\u001b[39m     (combined_spreads_df[\u001b[33m'\u001b[39m\u001b[33mavg_fair_prb\u001b[39m\u001b[33m'\u001b[39m] <= midprice - EDGE)\n\u001b[32m     14\u001b[39m ].reset_index(drop=\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[32m     16\u001b[39m midprice_yes = (edge_spreads_df[\u001b[33m'\u001b[39m\u001b[33myes_bid\u001b[39m\u001b[33m'\u001b[39m] + edge_spreads_df[\u001b[33m'\u001b[39m\u001b[33myes_ask\u001b[39m\u001b[33m'\u001b[39m]) / \u001b[32m2\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/kdata1/.venv/lib/python3.13/site-packages/pandas/core/frame.py:4113\u001b[39m, in \u001b[36mDataFrame.__getitem__\u001b[39m\u001b[34m(self, key)\u001b[39m\n\u001b[32m   4111\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.columns.nlevels > \u001b[32m1\u001b[39m:\n\u001b[32m   4112\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._getitem_multilevel(key)\n\u001b[32m-> \u001b[39m\u001b[32m4113\u001b[39m indexer = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mcolumns\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   4114\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m is_integer(indexer):\n\u001b[32m   4115\u001b[39m     indexer = [indexer]\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/kdata1/.venv/lib/python3.13/site-packages/pandas/core/indexes/base.py:3819\u001b[39m, in \u001b[36mIndex.get_loc\u001b[39m\u001b[34m(self, key)\u001b[39m\n\u001b[32m   3814\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(casted_key, \u001b[38;5;28mslice\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m (\n\u001b[32m   3815\u001b[39m         \u001b[38;5;28misinstance\u001b[39m(casted_key, abc.Iterable)\n\u001b[32m   3816\u001b[39m         \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28many\u001b[39m(\u001b[38;5;28misinstance\u001b[39m(x, \u001b[38;5;28mslice\u001b[39m) \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m casted_key)\n\u001b[32m   3817\u001b[39m     ):\n\u001b[32m   3818\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m InvalidIndexError(key)\n\u001b[32m-> \u001b[39m\u001b[32m3819\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(key) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01merr\u001b[39;00m\n\u001b[32m   3820\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[32m   3821\u001b[39m     \u001b[38;5;66;03m# If we have a listlike key, _check_indexing_error will raise\u001b[39;00m\n\u001b[32m   3822\u001b[39m     \u001b[38;5;66;03m#  InvalidIndexError. Otherwise we fall through and re-raise\u001b[39;00m\n\u001b[32m   3823\u001b[39m     \u001b[38;5;66;03m#  the TypeError.\u001b[39;00m\n\u001b[32m   3824\u001b[39m     \u001b[38;5;28mself\u001b[39m._check_indexing_error(key)\n",
      "\u001b[31mKeyError\u001b[39m: 'yes_bid'"
     ]
    }
   ],
   "source": [
    "EDGE = 0.02\n",
    "KELLY_UPPERBOUND = 1\n",
    "BANKROLL = 75.00\n",
    "Q1_WEIGHT = 1.00\n",
    "Q2_WEIGHT = 1.00\n",
    "Q3_WEIGHT = 1.00\n",
    "Q4_WEIGHT = 1.00\n",
    "\n",
    "midprice = (combined_spreads_df['yes_bid'] + combined_spreads_df['yes_ask']) / 2\n",
    "\n",
    "edge_spreads_df = combined_spreads_df.loc[\n",
    "    (combined_spreads_df['avg_fair_prb'] >= midprice + EDGE) |\n",
    "    (combined_spreads_df['avg_fair_prb'] <= midprice - EDGE)\n",
    "].reset_index(drop=True)\n",
    "\n",
    "midprice_yes = (edge_spreads_df['yes_bid'] + edge_spreads_df['yes_ask']) / 2\n",
    "midprice_no = (edge_spreads_df['no_bid'] + edge_spreads_df['no_ask']) / 2\n",
    "\n",
    "q_yes = edge_spreads_df['avg_fair_prb']\n",
    "q_no = 1 - edge_spreads_df['avg_fair_prb'] \n",
    "\n",
    "edge_spreads_df['edge'] = np.where(q_yes > midprice_yes, q_yes - midprice_yes, q_no - midprice_no)\n",
    "\n",
    "edge_spreads_df['raw_kelly'] = np.where(q_yes > midprice_yes, edge_spreads_df['edge'] / (1 - midprice_yes),\n",
    "                                        edge_spreads_df['edge'] / (1 - midprice_no))\n",
    "\n",
    "total_kelly = edge_spreads_df['raw_kelly'].sum() \n",
    "if total_kelly >= 1: \n",
    "    edge_spreads_df['real_kelly'] = pd.DataFrame({\n",
    "        'original': edge_spreads_df['raw_kelly'],\n",
    "        'normalized': (edge_spreads_df['raw_kelly'] / total_kelly)\n",
    "    }).min(axis=1)\n",
    "\n",
    "# Define the real_kelly logic\n",
    "def scale_kelly(row):\n",
    "    k = row['raw_kelly']\n",
    "    p = row['avg_fair_prb']\n",
    "    \n",
    "    if k == 0 or pd.isna(k):\n",
    "        return 0\n",
    "    if 0.05 <= p < 0.25:\n",
    "        return min(Q1_WEIGHT * k, KELLY_UPPERBOUND)\n",
    "    elif 0.25 <= p < 0.5:\n",
    "        return min(Q2_WEIGHT * k, KELLY_UPPERBOUND)\n",
    "    elif 0.5 <= p < 0.75:\n",
    "        return min(Q3_WEIGHT * k, KELLY_UPPERBOUND)\n",
    "    elif 0.75 <= p < 0.95:\n",
    "        return min(Q4_WEIGHT * k, KELLY_UPPERBOUND)\n",
    "    else:\n",
    "        return 0 \n",
    "\n",
    "# Apply to the DataFrame\n",
    "edge_spreads_df['real_kelly'] = edge_spreads_df.apply(scale_kelly, axis=1)\n",
    "edge_spreads_df['optimal_bet'] = edge_spreads_df['real_kelly'] * BANKROLL\n",
    "\n",
    "q = edge_spreads_df['avg_fair_prb']\n",
    "p = midprice_yes\n",
    "\n",
    "num_contracts = np.where(q > p, edge_spreads_df['optimal_bet'] // edge_spreads_df['yes_bid'], edge_spreads_df['optimal_bet'] // edge_spreads_df['no_bid'])\n",
    "edge_spreads_df['num_contracts'] = num_contracts\n",
    "trading_cost = np.where(q > p, np.ceil(100*(0.0175 * num_contracts * edge_spreads_df['yes_bid'] * (1 - edge_spreads_df['yes_bid']))) / 100,\n",
    "                        np.ceil(100*(0.0175 * num_contracts * edge_spreads_df['no_bid'] * (1 - edge_spreads_df['no_bid']))) / 100)\n",
    "edge_spreads_df['trading_cost'] = trading_cost\n",
    "profit = np.where(q > p, ((1 - edge_spreads_df['yes_bid']) * num_contracts - trading_cost), ((1 - edge_spreads_df['no_bid']) *  num_contracts - trading_cost))\n",
    "edge_spreads_df['profit'] = profit\n",
    "edge_spreads_df['ev'] = np.where(q > p, (profit * q_yes - (edge_spreads_df['optimal_bet'] + trading_cost) * (1 - q_yes)).round(2), \n",
    "                                 (profit * q_no - (edge_spreads_df['optimal_bet'] + trading_cost) * (1 - q_no)).round(2))\n",
    "filtered_spreads_df = edge_spreads_df.loc[edge_spreads_df['ev'] > 0.10].reset_index(drop=True)\n",
    "\n",
    "s = filtered_spreads_df['start_time'].astype(str)\n",
    "s = s.str.replace(r'\\s+[A-Z]{3}$', '', regex=True)\n",
    "dt = pd.to_datetime(s, errors='coerce')\n",
    "filtered_spreads_df['start_time'] = dt.dt.tz_localize('America/Chicago')\n",
    "\n",
    "now = datetime.now(pytz.timezone('America/Chicago'))\n",
    "filtered_winners_df = filtered_winners_df.loc[filtered_winners_df['start_time'] > now].sort_values('odds_home_team').reset_index(drop=True)\n",
    "filtered_spreads_df = filtered_spreads_df.drop(columns=['start_time', 'odds_home_team', 'odds_away_team', 'yes_spread', 'no_spread'])\n",
    "filtered_spreads_df[['edge', 'raw_kelly', 'real_kelly']] = filtered_spreads_df[['edge', 'raw_kelly', 'real_kelly']].round(4) * 100"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb3d259e",
   "metadata": {},
   "source": [
    "filtered spreads teams matching algo needs to be fixed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d9175fe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ticker</th>\n",
       "      <th>yes_bid</th>\n",
       "      <th>yes_ask</th>\n",
       "      <th>no_bid</th>\n",
       "      <th>no_ask</th>\n",
       "      <th>kalshi_pts</th>\n",
       "      <th>midprice</th>\n",
       "      <th>team</th>\n",
       "      <th>avg_fair_prb</th>\n",
       "      <th>odds_pts</th>\n",
       "      <th>buy_direction</th>\n",
       "      <th>edge</th>\n",
       "      <th>raw_kelly</th>\n",
       "      <th>real_kelly</th>\n",
       "      <th>optimal_bet</th>\n",
       "      <th>num_contracts</th>\n",
       "      <th>trading_cost</th>\n",
       "      <th>profit</th>\n",
       "      <th>ev</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [ticker, yes_bid, yes_ask, no_bid, no_ask, kalshi_pts, midprice, team, avg_fair_prb, odds_pts, buy_direction, edge, raw_kelly, real_kelly, optimal_bet, num_contracts, trading_cost, profit, ev]\n",
       "Index: []"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filtered_spreads_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1a3e46b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nba spreads portfolio summary:\n",
      "\n",
      "Max Loss: -0.00\n",
      "Max Profit: 0.00\n",
      "Portfolio EV: 0.00\n"
     ]
    }
   ],
   "source": [
    "total_loss = np.sum(filtered_spreads_df['optimal_bet'])\n",
    "total_profit = np.sum(filtered_spreads_df['profit'])\n",
    "total_ev = np.sum(filtered_spreads_df['ev'])\n",
    "print(f\"{odds_sport} spreads portfolio summary:\\n\")\n",
    "print(f\"Max Loss: -{total_loss:.2f}\")\n",
    "print(f\"Max Profit: {total_profit:.2f}\")\n",
    "print(f\"Portfolio EV: {total_ev:.2f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4525fffc",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
